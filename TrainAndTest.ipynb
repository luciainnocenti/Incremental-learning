{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainAndTest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "30164995e4cd4e89b8a2bbbcf2b57c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5a34bb7bbf8240f98aab081725a499bc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9cd6ba4e5718423092842bb1a519087a",
              "IPY_MODEL_23561be012c94a64b3fbc4768149b3c3"
            ]
          }
        },
        "5a34bb7bbf8240f98aab081725a499bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cd6ba4e5718423092842bb1a519087a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d8189cafaa964447a914d8a9cce0adef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d13cc9e50854500b6d2dfa32b390461"
          }
        },
        "23561be012c94a64b3fbc4768149b3c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c6a00335327e4cfcad1688f8052db043",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169009152/? [00:20&lt;00:00, 33918163.69it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_39cfb9617f2e4915846b1515234b88ef"
          }
        },
        "d8189cafaa964447a914d8a9cce0adef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d13cc9e50854500b6d2dfa32b390461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6a00335327e4cfcad1688f8052db043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "39cfb9617f2e4915846b1515234b88ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciainnocenti/IncrementalLearning/blob/Lucia/TrainAndTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbtGDBU3QJaq",
        "colab_type": "text"
      },
      "source": [
        "# Import GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf0TmOM3NdFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import sys\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I0pKIVIM2KC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "a7eb6c62-f5b0-445c-84e5-584e15afeb41"
      },
      "source": [
        "if not os.path.isdir('./DatasetCIFAR'):\n",
        "  !git clone -b Lucia https://github.com/luciainnocenti/IncrementalLearning.git\n",
        "  !mv 'IncrementalLearning' 'DatasetCIFAR'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IncrementalLearning'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 611 (delta 48), reused 0 (delta 0), pack-reused 532\u001b[K\n",
            "Receiving objects: 100% (611/611), 396.86 KiB | 1.34 MiB/s, done.\n",
            "Resolving deltas: 100% (377/377), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLaS2laafBaG",
        "colab_type": "text"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liUP5Kc1DMbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from DatasetCIFAR.data_set import Dataset \n",
        "from DatasetCIFAR import ResNet\n",
        "from DatasetCIFAR import utils\n",
        "from DatasetCIFAR import params\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.nn import functional as F\n",
        "import random\n",
        "random.seed(params.SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_vlqOL7ehLC",
        "colab_type": "text"
      },
      "source": [
        "# Define Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWttFW3ljoMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resNet = ResNet.resnet32(num_classes=100)\n",
        "resNet = resNet.to(params.DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSmohsyVWFpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transformer = transforms.Compose([transforms.RandomCrop(size = 32, padding=4),\n",
        "                                         transforms.RandomHorizontalFlip(),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transformer = transforms.Compose([transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_cyhIzFej5-",
        "colab_type": "text"
      },
      "source": [
        "# Define DataSets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcBNohmiYBtP",
        "colab_type": "code",
        "outputId": "1c07d12b-e2b5-4444-b383-28637434b5b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "30164995e4cd4e89b8a2bbbcf2b57c6e",
            "5a34bb7bbf8240f98aab081725a499bc",
            "9cd6ba4e5718423092842bb1a519087a",
            "23561be012c94a64b3fbc4768149b3c3",
            "d8189cafaa964447a914d8a9cce0adef",
            "5d13cc9e50854500b6d2dfa32b390461",
            "c6a00335327e4cfcad1688f8052db043",
            "39cfb9617f2e4915846b1515234b88ef"
          ]
        }
      },
      "source": [
        "trainDS = Dataset(train=True, transform = train_transformer)\n",
        "testDS = Dataset(train=False, transform = test_transformer)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30164995e4cd4e89b8a2bbbcf2b57c6e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFxMUO_FQZRo",
        "colab_type": "code",
        "outputId": "12848adc-e094-4d30-87a6-6e94234383f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "train_splits = trainDS.splits\n",
        "test_splits = testDS.splits\n",
        "print(train_splits)\n",
        "print(test_splits)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[60.0, 34.0, 84.0, 67.0, 85.0, 44.0, 18.0, 48.0, 1.0, 47.0], [68.0, 37.0, 94.0, 75.0, 95.0, 50.0, 20.0, 54.0, 2.0, 53.0], [76.0, 40.0, 83.0, 56.0, 22.0, 61.0, 3.0, 59.0, 77.0, 41.0], [88.0, 45.0, 97.0, 64.0, 24.0, 70.0, 4.0, 29.0, 38.0, 23.0], [49.0, 26.0, 72.0, 55.0, 96.0, 32.0, 13.0, 35.0, 0.0, 33.0], [65.0, 30.0, 87.0, 71.0, 93.0, 43.0, 15.0, 51.0, 5.0, 46.0], [80.0, 39.0, 86.0, 62.0, 17.0, 66.0, 6.0, 63.0, 99.0, 16.0], [52.0, 21.0, 78.0, 57.0, 91.0, 28.0, 11.0, 31.0, 7.0, 82.0], [89.0, 12.0, 90.0, 74.0, 8.0, 10.0, 98.0, 9.0, 42.0, 25.0], [58.0, 79.0, 81.0, 69.0, 14.0, 36.0, 73.0, 19.0, 92.0, 27.0]]\n",
            "[[60.0, 34.0, 84.0, 67.0, 85.0, 44.0, 18.0, 48.0, 1.0, 47.0], [68.0, 37.0, 94.0, 75.0, 95.0, 50.0, 20.0, 54.0, 2.0, 53.0], [76.0, 40.0, 83.0, 56.0, 22.0, 61.0, 3.0, 59.0, 77.0, 41.0], [88.0, 45.0, 97.0, 64.0, 24.0, 70.0, 4.0, 29.0, 38.0, 23.0], [49.0, 26.0, 72.0, 55.0, 96.0, 32.0, 13.0, 35.0, 0.0, 33.0], [65.0, 30.0, 87.0, 71.0, 93.0, 43.0, 15.0, 51.0, 5.0, 46.0], [80.0, 39.0, 86.0, 62.0, 17.0, 66.0, 6.0, 63.0, 99.0, 16.0], [52.0, 21.0, 78.0, 57.0, 91.0, 28.0, 11.0, 31.0, 7.0, 82.0], [89.0, 12.0, 90.0, 74.0, 8.0, 10.0, 98.0, 9.0, 42.0, 25.0], [58.0, 79.0, 81.0, 69.0, 14.0, 36.0, 73.0, 19.0, 92.0, 27.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgAT2KQEersx",
        "colab_type": "text"
      },
      "source": [
        "# Useful plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1l7flYj4NJh",
        "colab_type": "text"
      },
      "source": [
        "The function plotEpoch plots, at the end of each task, how accuracy and loss change during the training phase. It show\n",
        "\n",
        "*   Validation and Training Accuracy\n",
        "*   Validation and Training Loss\n",
        "\n",
        "The function plotTask, for each task, how the accuracy on the validation set change when adding new tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr58kkHiIzZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotTask(pars_tasks):\n",
        "  import numpy as np\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  x_tasks =  np.linspace(10, 100, 10)\n",
        "\n",
        "  plt.plot(x_tasks, pars_tasks, label=['Accuracy', 'Loss'])\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.title('Accuracy over tasks')\n",
        "  plt.legend(['Accuracy', 'Loss'])\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iApKvCs942aS",
        "colab_type": "text"
      },
      "source": [
        "# Train and evaluation phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJse4JU7d9ck",
        "colab_type": "code",
        "outputId": "1b9e1a05-7f69-4e16-df20-89936b5a057b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pars_tasks = []\n",
        "test_indexes = []\n",
        "\n",
        "for task in range(0, 100, params.TASK_SIZE):\n",
        "  pars_tasks.insert(task, 0)\n",
        "\n",
        "for task in range(0, 100, params.TASK_SIZE):\n",
        "\n",
        "  train_indexes = trainDS.__getIndexesGroups__(task)\n",
        "  test_indexes = test_indexes + testDS.__getIndexesGroups__(task)\n",
        "\n",
        "  train_dataset = Subset(trainDS, train_indexes)\n",
        "  test_dataset = Subset(testDS, test_indexes)\n",
        "\n",
        "  train_loader = DataLoader( train_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE)\n",
        "  test_loader = DataLoader( test_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE )\n",
        "\n",
        "  if(task == 0):\n",
        "    torch.save(resNet, 'resNet_task{0}.pt'.format(task))\n",
        "  \n",
        "  \n",
        "\n",
        "  utils.trainfunction(task, train_loader, train_splits)\n",
        "  param = utils.evaluationTest(task, test_loader, test_splits)\n",
        "  pars_tasks[int(task/10)] = param #pars_task[i] = (accuracy, loss) at i-th task\t"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task = 0 \n",
            "train col =  [60 34 84 67 85 44 18 48  1 47]\n",
            "train col =  [[60 34 84 67 85 44 18 48  1 47]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "At step  0  and at epoch =  0  the loss is =  0.027755627408623695  and accuracy is =  0.168\n",
            "At step  0  and at epoch =  1  the loss is =  0.020824184641242027  and accuracy is =  0.4358\n",
            "At step  0  and at epoch =  2  the loss is =  0.018622998148202896  and accuracy is =  0.5266\n",
            "At step  0  and at epoch =  3  the loss is =  0.015013396739959717  and accuracy is =  0.5822\n",
            "At step  0  and at epoch =  4  the loss is =  0.011173092760145664  and accuracy is =  0.6436\n",
            "At step  0  and at epoch =  5  the loss is =  0.006309265270829201  and accuracy is =  0.6966\n",
            "At step  0  and at epoch =  6  the loss is =  0.007074774242937565  and accuracy is =  0.7226\n",
            "At step  0  and at epoch =  7  the loss is =  0.004297936335206032  and accuracy is =  0.7408\n",
            "At step  0  and at epoch =  8  the loss is =  0.004324791487306356  and accuracy is =  0.7544\n",
            "At step  0  and at epoch =  9  the loss is =  0.004960212390869856  and accuracy is =  0.7646\n",
            "At step  0  and at epoch =  10  the loss is =  0.0018350862665101886  and accuracy is =  0.7986\n",
            "At step  0  and at epoch =  11  the loss is =  0.003649979131296277  and accuracy is =  0.8162\n",
            "At step  0  and at epoch =  12  the loss is =  0.003008780302479863  and accuracy is =  0.8272\n",
            "At step  0  and at epoch =  13  the loss is =  0.0012473899405449629  and accuracy is =  0.8546\n",
            "At step  0  and at epoch =  14  the loss is =  0.0016407540533691645  and accuracy is =  0.8852\n",
            "At step  0  and at epoch =  15  the loss is =  0.0007162238471210003  and accuracy is =  0.9024\n",
            "At step  0  and at epoch =  16  the loss is =  0.0016738572157919407  and accuracy is =  0.8946\n",
            "At step  0  and at epoch =  17  the loss is =  0.00514680752530694  and accuracy is =  0.8942\n",
            "At step  0  and at epoch =  18  the loss is =  0.012802235782146454  and accuracy is =  0.8942\n",
            "At step  0  and at epoch =  19  the loss is =  0.0018568345112726092  and accuracy is =  0.8958\n",
            "At step  0  and at epoch =  20  the loss is =  0.0026043143589049578  and accuracy is =  0.938\n",
            "At step  0  and at epoch =  21  the loss is =  0.001725632231682539  and accuracy is =  0.9352\n",
            "At step  0  and at epoch =  22  the loss is =  0.003505655098706484  and accuracy is =  0.9476\n",
            "At step  0  and at epoch =  23  the loss is =  0.0011162026785314083  and accuracy is =  0.935\n",
            "At step  0  and at epoch =  24  the loss is =  0.0005601425073109567  and accuracy is =  0.9602\n",
            "At step  0  and at epoch =  25  the loss is =  0.0022256679367274046  and accuracy is =  0.9652\n",
            "At step  0  and at epoch =  26  the loss is =  0.005790315102785826  and accuracy is =  0.9484\n",
            "At step  0  and at epoch =  27  the loss is =  0.00211537629365921  and accuracy is =  0.964\n",
            "At step  0  and at epoch =  28  the loss is =  0.0012192338472232223  and accuracy is =  0.9734\n",
            "At step  0  and at epoch =  29  the loss is =  0.001772059127688408  and accuracy is =  0.9834\n",
            "At step  0  and at epoch =  30  the loss is =  0.0015872542280703783  and accuracy is =  0.9848\n",
            "At step  0  and at epoch =  31  the loss is =  0.00025588751304894686  and accuracy is =  0.9882\n",
            "At step  0  and at epoch =  32  the loss is =  0.00011652210378088057  and accuracy is =  0.9926\n",
            "At step  0  and at epoch =  33  the loss is =  0.000189077079994604  and accuracy is =  0.9936\n",
            "At step  0  and at epoch =  34  the loss is =  6.240539369173348e-05  and accuracy is =  0.9946\n",
            "At step  0  and at epoch =  35  the loss is =  5.820933438371867e-05  and accuracy is =  0.9982\n",
            "At step  0  and at epoch =  36  the loss is =  4.613198689185083e-05  and accuracy is =  0.9998\n",
            "At step  0  and at epoch =  37  the loss is =  4.401982369017787e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  38  the loss is =  4.431429988471791e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  39  the loss is =  4.475241803447716e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  40  the loss is =  4.5421780669130385e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  41  the loss is =  4.6274846681626514e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  42  the loss is =  4.7255012759706005e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  43  the loss is =  4.8327900003641844e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  44  the loss is =  4.947535489918664e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  45  the loss is =  5.067608071840368e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  46  the loss is =  5.192232129047625e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  47  the loss is =  5.3189825848676264e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  48  the loss is =  5.334563320502639e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  49  the loss is =  5.3589214076055214e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  50  the loss is =  5.3833238780498505e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  51  the loss is =  5.4078602261142805e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  52  the loss is =  5.432619946077466e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  53  the loss is =  5.457156294141896e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  54  the loss is =  5.482124470290728e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  55  the loss is =  5.507166497409344e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  56  the loss is =  5.532283103093505e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  57  the loss is =  5.557861368288286e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  58  the loss is =  5.583111851592548e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  59  the loss is =  5.6079457863233984e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  60  the loss is =  5.6329285143874586e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  61  the loss is =  5.657999645336531e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  62  the loss is =  5.6609787861816585e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  63  the loss is =  5.66614544368349e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  64  the loss is =  5.670984319294803e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  65  the loss is =  5.675449938280508e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  66  the loss is =  5.6807355576893315e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  67  the loss is =  5.685812357114628e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  68  the loss is =  5.690621037501842e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  69  the loss is =  5.695340223610401e-05  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "104\n",
            "Validation Loss: 0.012329310178756714 Validation Accuracy : 0.769\n",
            "task = 10 \n",
            "train col =  [68 37 94 75 95 50 20 54  2 53]\n",
            "train col =  [[68 37 94 75 95 50 20 54  2 53]]\n",
            "At step  10  and at epoch =  0  the loss is =  0.04355146363377571  and accuracy is =  0.4508\n",
            "At step  10  and at epoch =  1  the loss is =  0.026142077520489693  and accuracy is =  0.6932\n",
            "At step  10  and at epoch =  2  the loss is =  0.020688775926828384  and accuracy is =  0.7728\n",
            "At step  10  and at epoch =  3  the loss is =  0.020224010571837425  and accuracy is =  0.8278\n",
            "At step  10  and at epoch =  4  the loss is =  0.019322846084833145  and accuracy is =  0.8674\n",
            "At step  10  and at epoch =  5  the loss is =  0.012924958020448685  and accuracy is =  0.892\n",
            "At step  10  and at epoch =  6  the loss is =  0.01382341980934143  and accuracy is =  0.9186\n",
            "At step  10  and at epoch =  7  the loss is =  0.014022694900631905  and accuracy is =  0.9216\n",
            "At step  10  and at epoch =  8  the loss is =  0.013300757855176926  and accuracy is =  0.9404\n",
            "At step  10  and at epoch =  9  the loss is =  0.01228242740035057  and accuracy is =  0.9584\n",
            "At step  10  and at epoch =  10  the loss is =  0.01066489890217781  and accuracy is =  0.9646\n",
            "At step  10  and at epoch =  11  the loss is =  0.011361374519765377  and accuracy is =  0.975\n",
            "At step  10  and at epoch =  12  the loss is =  0.012190483510494232  and accuracy is =  0.9772\n",
            "At step  10  and at epoch =  13  the loss is =  0.01190961804240942  and accuracy is =  0.9732\n",
            "At step  10  and at epoch =  14  the loss is =  0.011537753976881504  and accuracy is =  0.973\n",
            "At step  10  and at epoch =  15  the loss is =  0.010380544699728489  and accuracy is =  0.9822\n",
            "At step  10  and at epoch =  16  the loss is =  0.01018431130796671  and accuracy is =  0.9884\n",
            "At step  10  and at epoch =  17  the loss is =  0.011725167743861675  and accuracy is =  0.9912\n",
            "At step  10  and at epoch =  18  the loss is =  0.011712360195815563  and accuracy is =  0.9946\n",
            "At step  10  and at epoch =  19  the loss is =  0.013594631105661392  and accuracy is =  0.9918\n",
            "At step  10  and at epoch =  20  the loss is =  0.01126342173665762  and accuracy is =  0.9948\n",
            "At step  10  and at epoch =  21  the loss is =  0.010074879974126816  and accuracy is =  0.9954\n",
            "At step  10  and at epoch =  22  the loss is =  0.010210515931248665  and accuracy is =  0.9996\n",
            "At step  10  and at epoch =  23  the loss is =  0.009204692207276821  and accuracy is =  0.9994\n",
            "At step  10  and at epoch =  24  the loss is =  0.00921771489083767  and accuracy is =  0.9994\n",
            "At step  10  and at epoch =  25  the loss is =  0.009312063455581665  and accuracy is =  0.9994\n",
            "At step  10  and at epoch =  26  the loss is =  0.00881534069776535  and accuracy is =  0.9992\n",
            "At step  10  and at epoch =  27  the loss is =  0.009041872806847095  and accuracy is =  0.9996\n",
            "At step  10  and at epoch =  28  the loss is =  0.009205952286720276  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  29  the loss is =  0.009499110281467438  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  30  the loss is =  0.009212268516421318  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  31  the loss is =  0.00972534529864788  and accuracy is =  0.9998\n",
            "At step  10  and at epoch =  32  the loss is =  0.009557507000863552  and accuracy is =  0.9998\n",
            "At step  10  and at epoch =  33  the loss is =  0.008843347430229187  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  34  the loss is =  0.008438828401267529  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  35  the loss is =  0.008458797819912434  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  36  the loss is =  0.008417141623795033  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  37  the loss is =  0.008347569033503532  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  38  the loss is =  0.008498688228428364  and accuracy is =  0.9998\n",
            "At step  10  and at epoch =  39  the loss is =  0.008637730032205582  and accuracy is =  0.9998\n",
            "At step  10  and at epoch =  40  the loss is =  0.00876385997980833  and accuracy is =  0.9998\n",
            "At step  10  and at epoch =  41  the loss is =  0.008859748020768166  and accuracy is =  0.9994\n",
            "At step  10  and at epoch =  42  the loss is =  0.008461513556540012  and accuracy is =  0.9998\n",
            "At step  10  and at epoch =  43  the loss is =  0.008477061986923218  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  44  the loss is =  0.008503754623234272  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  45  the loss is =  0.008644579909741879  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  46  the loss is =  0.008614864200353622  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  47  the loss is =  0.008623765781521797  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  48  the loss is =  0.008468406274914742  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  49  the loss is =  0.008253242820501328  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  50  the loss is =  0.008171219378709793  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  51  the loss is =  0.008133592084050179  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  52  the loss is =  0.00811395701020956  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  53  the loss is =  0.008102254010736942  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  54  the loss is =  0.008094217628240585  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  55  the loss is =  0.008087963797152042  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  56  the loss is =  0.008082768879830837  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  57  the loss is =  0.008078287355601788  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  58  the loss is =  0.008074295707046986  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  59  the loss is =  0.008070753887295723  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  60  the loss is =  0.008067598566412926  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  61  the loss is =  0.00806480459868908  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  62  the loss is =  0.00806385651230812  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  63  the loss is =  0.008063648827373981  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  64  the loss is =  0.008062774315476418  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  65  the loss is =  0.008062045089900494  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  66  the loss is =  0.008061378262937069  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  67  the loss is =  0.008060751482844353  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  68  the loss is =  0.008060166612267494  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  69  the loss is =  0.008059605956077576  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "80\n",
            "Validation Loss: 0.027554010972380638 Validation Accuracy : 0.5635\n",
            "task = 20 \n",
            "train col =  [76 40 83 56 22 61  3 59 77 41]\n",
            "train col =  [[76 40 83 56 22 61  3 59 77 41]]\n",
            "At step  20  and at epoch =  0  the loss is =  0.06283660978078842  and accuracy is =  0.3804\n",
            "At step  20  and at epoch =  1  the loss is =  0.05037232115864754  and accuracy is =  0.5386\n",
            "At step  20  and at epoch =  2  the loss is =  0.045675087720155716  and accuracy is =  0.634\n",
            "At step  20  and at epoch =  3  the loss is =  0.03927537426352501  and accuracy is =  0.7208\n",
            "At step  20  and at epoch =  4  the loss is =  0.034868042916059494  and accuracy is =  0.8014\n",
            "At step  20  and at epoch =  5  the loss is =  0.03661898151040077  and accuracy is =  0.8464\n",
            "At step  20  and at epoch =  6  the loss is =  0.03458487614989281  and accuracy is =  0.8548\n",
            "At step  20  and at epoch =  7  the loss is =  0.03311941772699356  and accuracy is =  0.8602\n",
            "At step  20  and at epoch =  8  the loss is =  0.026949547231197357  and accuracy is =  0.8752\n",
            "At step  20  and at epoch =  9  the loss is =  0.023562218993902206  and accuracy is =  0.9152\n",
            "At step  20  and at epoch =  10  the loss is =  0.022687768563628197  and accuracy is =  0.9254\n",
            "At step  20  and at epoch =  11  the loss is =  0.022472653537988663  and accuracy is =  0.9296\n",
            "At step  20  and at epoch =  12  the loss is =  0.023054754361510277  and accuracy is =  0.9454\n",
            "At step  20  and at epoch =  13  the loss is =  0.022072413936257362  and accuracy is =  0.9532\n",
            "At step  20  and at epoch =  14  the loss is =  0.021293088793754578  and accuracy is =  0.9752\n",
            "At step  20  and at epoch =  15  the loss is =  0.02079758048057556  and accuracy is =  0.9872\n",
            "At step  20  and at epoch =  16  the loss is =  0.020336013287305832  and accuracy is =  0.9888\n",
            "At step  20  and at epoch =  17  the loss is =  0.020325474441051483  and accuracy is =  0.9912\n",
            "At step  20  and at epoch =  18  the loss is =  0.019439220428466797  and accuracy is =  0.9948\n",
            "At step  20  and at epoch =  19  the loss is =  0.018903791904449463  and accuracy is =  0.996\n",
            "At step  20  and at epoch =  20  the loss is =  0.019412729889154434  and accuracy is =  0.997\n",
            "At step  20  and at epoch =  21  the loss is =  0.01992674171924591  and accuracy is =  0.998\n",
            "At step  20  and at epoch =  22  the loss is =  0.019974729046225548  and accuracy is =  0.9974\n",
            "At step  20  and at epoch =  23  the loss is =  0.020640380680561066  and accuracy is =  0.996\n",
            "At step  20  and at epoch =  24  the loss is =  0.021475333720445633  and accuracy is =  0.9972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ptf2qZjFbWNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotTask(pars_tasks)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}