{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainAndTest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "785f3a66fa3a481b8c346a8a663f122d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4839c48cc0b54f5ea80975c20a960020",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6890ea3dda1b42a09a41ed8a2da9fda3",
              "IPY_MODEL_a32ce2b8019543ba998a7ea365a169de"
            ]
          }
        },
        "4839c48cc0b54f5ea80975c20a960020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6890ea3dda1b42a09a41ed8a2da9fda3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d82eee65daf64b12a8bd9ec5dfd32a8c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71d43d1c7a5a4ab18ee407ae7d249318"
          }
        },
        "a32ce2b8019543ba998a7ea365a169de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_83f311d7a70d41fbbf71b0309076e7b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169009152/? [00:20&lt;00:00, 32579570.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51f2e57347f541a5a842e87940b759f5"
          }
        },
        "d82eee65daf64b12a8bd9ec5dfd32a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71d43d1c7a5a4ab18ee407ae7d249318": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83f311d7a70d41fbbf71b0309076e7b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51f2e57347f541a5a842e87940b759f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciainnocenti/IncrementalLearning/blob/Lucia/TrainAndTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbtGDBU3QJaq",
        "colab_type": "text"
      },
      "source": [
        "# Import GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf0TmOM3NdFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import sys\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I0pKIVIM2KC",
        "colab_type": "code",
        "outputId": "e337fc11-fafa-4eee-e48e-de66cfb573ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "if not os.path.isdir('./DatasetCIFAR'):\n",
        "  !git clone -b Lucia https://github.com/luciainnocenti/IncrementalLearning.git\n",
        "  !mv 'IncrementalLearning' 'DatasetCIFAR'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IncrementalLearning'...\n",
            "remote: Enumerating objects: 174, done.\u001b[K\n",
            "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (173/173), done.\u001b[K\n",
            "remote: Total 504 (delta 107), reused 0 (delta 0), pack-reused 330\u001b[K\n",
            "Receiving objects: 100% (504/504), 330.12 KiB | 1.13 MiB/s, done.\n",
            "Resolving deltas: 100% (306/306), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLaS2laafBaG",
        "colab_type": "text"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liUP5Kc1DMbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from DatasetCIFAR.data_set import Dataset \n",
        "from DatasetCIFAR import ResNet\n",
        "from DatasetCIFAR import utils\n",
        "from DatasetCIFAR import params\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.nn import functional as F\n",
        "import random\n",
        "random.seed(params.SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_vlqOL7ehLC",
        "colab_type": "text"
      },
      "source": [
        "# Define Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWttFW3ljoMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resNet = ResNet.resnet32(num_classes=100)\n",
        "resNet = resNet.to(params.DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSmohsyVWFpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet_transformer = transforms.Compose([transforms.Resize(32), \n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_cyhIzFej5-",
        "colab_type": "text"
      },
      "source": [
        "# Define DataSets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcBNohmiYBtP",
        "colab_type": "code",
        "outputId": "23223d8f-a58a-4e28-e090-c247ab852b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "785f3a66fa3a481b8c346a8a663f122d",
            "4839c48cc0b54f5ea80975c20a960020",
            "6890ea3dda1b42a09a41ed8a2da9fda3",
            "a32ce2b8019543ba998a7ea365a169de",
            "d82eee65daf64b12a8bd9ec5dfd32a8c",
            "71d43d1c7a5a4ab18ee407ae7d249318",
            "83f311d7a70d41fbbf71b0309076e7b2",
            "51f2e57347f541a5a842e87940b759f5"
          ]
        }
      },
      "source": [
        "trainDS = Dataset(train=True, transform = resnet_transformer)\n",
        "testDS = Dataset(train=False, transform = resnet_transformer)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "785f3a66fa3a481b8c346a8a663f122d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFxMUO_FQZRo",
        "colab_type": "code",
        "outputId": "f1977c00-d437-4e5d-d057-f47842652962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "train_splits = trainDS.splits\n",
        "test_splits = testDS.splits\n",
        "print(train_splits)\n",
        "print(test_splits)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[49.0, 97.0, 53.0, 5.0, 33.0, 65.0, 62.0, 51.0, 38.0, 61.0], [55.0, 59.0, 6.0, 35.0, 74.0, 71.0, 57.0, 41.0, 70.0, 48.0], [64.0, 69.0, 7.0, 37.0, 84.0, 81.0, 67.0, 44.0, 80.0, 56.0], [75.0, 79.0, 8.0, 40.0, 94.0, 91.0, 77.0, 87.0, 76.0, 98.0], [90.0, 28.0, 82.0, 93.0, 30.0, 2.0, 20.0, 42.0, 39.0, 29.0], [34.0, 96.0, 43.0, 3.0, 22.0, 54.0, 52.0, 36.0, 25.0, 50.0], [58.0, 63.0, 4.0, 24.0, 83.0, 78.0, 60.0, 31.0, 73.0, 17.0], [92.0, 21.0, 86.0, 23.0, 1.0, 15.0, 32.0, 27.0, 95.0, 16.0], [46.0, 47.0, 66.0, 12.0, 19.0, 10.0, 26.0, 72.0, 11.0, 9.0], [18.0, 89.0, 0.0, 68.0, 14.0, 13.0, 45.0, 99.0, 88.0, 85.0]]\n",
            "[[49.0, 97.0, 53.0, 5.0, 33.0, 65.0, 62.0, 51.0, 38.0, 61.0], [55.0, 59.0, 6.0, 35.0, 74.0, 71.0, 57.0, 41.0, 70.0, 48.0], [64.0, 69.0, 7.0, 37.0, 84.0, 81.0, 67.0, 44.0, 80.0, 56.0], [75.0, 79.0, 8.0, 40.0, 94.0, 91.0, 77.0, 87.0, 76.0, 98.0], [90.0, 28.0, 82.0, 93.0, 30.0, 2.0, 20.0, 42.0, 39.0, 29.0], [34.0, 96.0, 43.0, 3.0, 22.0, 54.0, 52.0, 36.0, 25.0, 50.0], [58.0, 63.0, 4.0, 24.0, 83.0, 78.0, 60.0, 31.0, 73.0, 17.0], [92.0, 21.0, 86.0, 23.0, 1.0, 15.0, 32.0, 27.0, 95.0, 16.0], [46.0, 47.0, 66.0, 12.0, 19.0, 10.0, 26.0, 72.0, 11.0, 9.0], [18.0, 89.0, 0.0, 68.0, 14.0, 13.0, 45.0, 99.0, 88.0, 85.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgAT2KQEersx",
        "colab_type": "text"
      },
      "source": [
        "# Useful plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1l7flYj4NJh",
        "colab_type": "text"
      },
      "source": [
        "The function plotEpoch plots, at the end of each task, how accuracy and loss change during the training phase. It show\n",
        "\n",
        "*   Validation and Training Accuracy\n",
        "*   Validation and Training Loss\n",
        "\n",
        "The function plotTask, for each task, how the accuracy on the validation set change when adding new tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr58kkHiIzZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotTask(pars_tasks):\n",
        "  import numpy as np\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  x_tasks =  np.linspace(10, 100, 10)\n",
        "\n",
        "  plt.plot(x_tasks, pars_tasks, label=['Accuracy', 'Loss'])\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.title('Accuracy over tasks')\n",
        "  plt.legend(['Accuracy', 'Loss'])\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iApKvCs942aS",
        "colab_type": "text"
      },
      "source": [
        "# Train and evaluation phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJse4JU7d9ck",
        "colab_type": "code",
        "outputId": "f9b53d2a-b550-4c69-e5d9-6c555c352178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pars_tasks = []\n",
        "test_indexes = []\n",
        "\n",
        "for task in range(0, 100, params.TASK_SIZE):\n",
        "  pars_tasks.insert(task, 0)\n",
        "\n",
        "for task in range(0, 100, params.TASK_SIZE):\n",
        "\n",
        "  train_indexes = trainDS.__getIndexesGroups__(task)\n",
        "  test_indexes = test_indexes + testDS.__getIndexesGroups__(task)\n",
        "\n",
        "  train_dataset = Subset(trainDS, train_indexes)\n",
        "  test_dataset = Subset(testDS, test_indexes)\n",
        "\n",
        "  train_loader = DataLoader( train_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE)\n",
        "  test_loader = DataLoader( test_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE )\n",
        "\n",
        "  if(task == 0):\n",
        "    torch.save(resNet, 'resNet_task{0}.pt'.format(task))\n",
        "  \n",
        "  \n",
        "\n",
        "  utils.trainfunction(task, train_loader, train_splits)\n",
        "  param = utils.evaluationTest(task, test_loader, test_splits) #evaluate test set at step task\n",
        "  pars_tasks[int(task/10)] = param #pars_task[i] = (accuracy, loss) at i-th task\t\n",
        "\n",
        "train_splits = trainDS.splits\n",
        "test_splits = testDS.splits"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task = 0 \n",
            "train col =  [49 97 53  5 33 65 62 51 38 61]\n",
            "train col =  [[49 97 53  5 33 65 62 51 38 61]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "At step  0  and at epoch =  0  the loss is =  0.03280014917254448  and accuracy is =  0.187\n",
            "At step  0  and at epoch =  1  the loss is =  0.024784564971923828  and accuracy is =  0.3706\n",
            "At step  0  and at epoch =  2  the loss is =  0.02203490398824215  and accuracy is =  0.4426\n",
            "At step  0  and at epoch =  3  the loss is =  0.020293526351451874  and accuracy is =  0.4686\n",
            "At step  0  and at epoch =  4  the loss is =  0.01857619360089302  and accuracy is =  0.4872\n",
            "At step  0  and at epoch =  5  the loss is =  0.016605162993073463  and accuracy is =  0.5038\n",
            "At step  0  and at epoch =  6  the loss is =  0.014777321368455887  and accuracy is =  0.5232\n",
            "At step  0  and at epoch =  7  the loss is =  0.012871798127889633  and accuracy is =  0.5414\n",
            "At step  0  and at epoch =  8  the loss is =  0.011306476779282093  and accuracy is =  0.5588\n",
            "At step  0  and at epoch =  9  the loss is =  0.009963972494006157  and accuracy is =  0.577\n",
            "At step  0  and at epoch =  10  the loss is =  0.00834728218615055  and accuracy is =  0.5998\n",
            "At step  0  and at epoch =  11  the loss is =  0.007628270890563726  and accuracy is =  0.6142\n",
            "At step  0  and at epoch =  12  the loss is =  0.006284269504249096  and accuracy is =  0.6286\n",
            "At step  0  and at epoch =  13  the loss is =  0.0054825120605528355  and accuracy is =  0.64\n",
            "At step  0  and at epoch =  14  the loss is =  0.00498775253072381  and accuracy is =  0.653\n",
            "At step  0  and at epoch =  15  the loss is =  0.004472240339964628  and accuracy is =  0.672\n",
            "At step  0  and at epoch =  16  the loss is =  0.0042083654552698135  and accuracy is =  0.6876\n",
            "At step  0  and at epoch =  17  the loss is =  0.004609184805303812  and accuracy is =  0.701\n",
            "At step  0  and at epoch =  18  the loss is =  0.003945314325392246  and accuracy is =  0.7116\n",
            "At step  0  and at epoch =  19  the loss is =  0.004323925357311964  and accuracy is =  0.7342\n",
            "At step  0  and at epoch =  20  the loss is =  0.0036905829329043627  and accuracy is =  0.7306\n",
            "At step  0  and at epoch =  21  the loss is =  0.0029411506839096546  and accuracy is =  0.7454\n",
            "At step  0  and at epoch =  22  the loss is =  0.0031086166854947805  and accuracy is =  0.7764\n",
            "At step  0  and at epoch =  23  the loss is =  0.0026967651210725307  and accuracy is =  0.8024\n",
            "At step  0  and at epoch =  24  the loss is =  0.002238728106021881  and accuracy is =  0.8014\n",
            "At step  0  and at epoch =  25  the loss is =  0.002604982117190957  and accuracy is =  0.8028\n",
            "At step  0  and at epoch =  26  the loss is =  0.0021821625996381044  and accuracy is =  0.8186\n",
            "At step  0  and at epoch =  27  the loss is =  0.0016166581772267818  and accuracy is =  0.8392\n",
            "At step  0  and at epoch =  28  the loss is =  0.0021011827047914267  and accuracy is =  0.848\n",
            "At step  0  and at epoch =  29  the loss is =  0.0016490679699927568  and accuracy is =  0.8674\n",
            "At step  0  and at epoch =  30  the loss is =  0.001984925242140889  and accuracy is =  0.8736\n",
            "At step  0  and at epoch =  31  the loss is =  0.0013832015683874488  and accuracy is =  0.8878\n",
            "At step  0  and at epoch =  32  the loss is =  0.00286165252327919  and accuracy is =  0.8906\n",
            "At step  0  and at epoch =  33  the loss is =  0.0014872699975967407  and accuracy is =  0.891\n",
            "At step  0  and at epoch =  34  the loss is =  0.0010777701390907168  and accuracy is =  0.936\n",
            "At step  0  and at epoch =  35  the loss is =  0.0008233692497014999  and accuracy is =  0.9578\n",
            "At step  0  and at epoch =  36  the loss is =  0.0007979631191119552  and accuracy is =  0.961\n",
            "At step  0  and at epoch =  37  the loss is =  0.0006746434373781085  and accuracy is =  0.9432\n",
            "At step  0  and at epoch =  38  the loss is =  0.0006730727618560195  and accuracy is =  0.9798\n",
            "At step  0  and at epoch =  39  the loss is =  0.0004420980694703758  and accuracy is =  0.9922\n",
            "At step  0  and at epoch =  40  the loss is =  0.00035583481076173484  and accuracy is =  0.9964\n",
            "At step  0  and at epoch =  41  the loss is =  0.0003186801332049072  and accuracy is =  0.999\n",
            "At step  0  and at epoch =  42  the loss is =  0.00027764300466515124  and accuracy is =  0.9992\n",
            "At step  0  and at epoch =  43  the loss is =  0.00025269153411500156  and accuracy is =  0.9998\n",
            "At step  0  and at epoch =  44  the loss is =  0.00023127830354496837  and accuracy is =  0.9998\n",
            "At step  0  and at epoch =  45  the loss is =  0.00021552125690504909  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  46  the loss is =  0.00020131655037403107  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  47  the loss is =  0.00019032531417906284  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  48  the loss is =  0.00019571940356399864  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  49  the loss is =  0.00019252592755947262  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  50  the loss is =  0.00018893634842243046  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  51  the loss is =  0.00018578316667117178  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  52  the loss is =  0.000182783420314081  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  53  the loss is =  0.0001800169557100162  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  54  the loss is =  0.00017736453446559608  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  55  the loss is =  0.00017476659559179097  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  56  the loss is =  0.00017246924107894301  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  57  the loss is =  0.0001702379813650623  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  58  the loss is =  0.00016807339852675796  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  59  the loss is =  0.00016606242570560426  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  60  the loss is =  0.0001640491100260988  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  61  the loss is =  0.00016213893832173198  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  62  the loss is =  0.00015982610057108104  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  63  the loss is =  0.00015996921865735203  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  64  the loss is =  0.00015990175597835332  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  65  the loss is =  0.00015970587264746428  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  66  the loss is =  0.00015939179866109043  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  67  the loss is =  0.0001590361207490787  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  68  the loss is =  0.00015867820184212178  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  69  the loss is =  0.00015832859207876027  and accuracy is =  1.0\n",
            "[49 97 53  5 33 65 62 51 38 61]\n",
            "Validation Loss: 0.3442791998386383 Validation Accuracy : 0.59\n",
            "task = 10 \n",
            "train col =  [55 59  6 35 74 71 57 41 70 48]\n",
            "train col =  [[55 59  6 35 74 71 57 41 70 48]]\n",
            "At step  10  and at epoch =  0  the loss is =  0.04756062105298042  and accuracy is =  0.3084\n",
            "At step  10  and at epoch =  1  the loss is =  0.044371698051691055  and accuracy is =  0.4046\n",
            "At step  10  and at epoch =  2  the loss is =  0.03031180240213871  and accuracy is =  0.462\n",
            "At step  10  and at epoch =  3  the loss is =  0.025025269016623497  and accuracy is =  0.498\n",
            "At step  10  and at epoch =  4  the loss is =  0.022860560566186905  and accuracy is =  0.5318\n",
            "At step  10  and at epoch =  5  the loss is =  0.02132944017648697  and accuracy is =  0.5628\n",
            "At step  10  and at epoch =  6  the loss is =  0.01969555765390396  and accuracy is =  0.5956\n",
            "At step  10  and at epoch =  7  the loss is =  0.020928937941789627  and accuracy is =  0.6222\n",
            "At step  10  and at epoch =  8  the loss is =  0.020657619461417198  and accuracy is =  0.6466\n",
            "At step  10  and at epoch =  9  the loss is =  0.018676619976758957  and accuracy is =  0.671\n",
            "At step  10  and at epoch =  10  the loss is =  0.018910620361566544  and accuracy is =  0.697\n",
            "At step  10  and at epoch =  11  the loss is =  0.01774962618947029  and accuracy is =  0.7128\n",
            "At step  10  and at epoch =  12  the loss is =  0.016617905348539352  and accuracy is =  0.7402\n",
            "At step  10  and at epoch =  13  the loss is =  0.015144153498113155  and accuracy is =  0.7484\n",
            "At step  10  and at epoch =  14  the loss is =  0.016320375725626945  and accuracy is =  0.7698\n",
            "At step  10  and at epoch =  15  the loss is =  0.014845788478851318  and accuracy is =  0.791\n",
            "At step  10  and at epoch =  16  the loss is =  0.013673637993633747  and accuracy is =  0.8236\n",
            "At step  10  and at epoch =  17  the loss is =  0.013070808723568916  and accuracy is =  0.8348\n",
            "At step  10  and at epoch =  18  the loss is =  0.01342881191521883  and accuracy is =  0.849\n",
            "At step  10  and at epoch =  19  the loss is =  0.013145106844604015  and accuracy is =  0.8622\n",
            "At step  10  and at epoch =  20  the loss is =  0.01340244710445404  and accuracy is =  0.8816\n",
            "At step  10  and at epoch =  21  the loss is =  0.01326762605458498  and accuracy is =  0.882\n",
            "At step  10  and at epoch =  22  the loss is =  0.012188402935862541  and accuracy is =  0.9022\n",
            "At step  10  and at epoch =  23  the loss is =  0.011812725104391575  and accuracy is =  0.9182\n",
            "At step  10  and at epoch =  24  the loss is =  0.013107853010296822  and accuracy is =  0.9336\n",
            "At step  10  and at epoch =  25  the loss is =  0.013054038397967815  and accuracy is =  0.9396\n",
            "At step  10  and at epoch =  26  the loss is =  0.011606377549469471  and accuracy is =  0.9572\n",
            "At step  10  and at epoch =  27  the loss is =  0.010917812585830688  and accuracy is =  0.9664\n",
            "At step  10  and at epoch =  28  the loss is =  0.009923802688717842  and accuracy is =  0.9732\n",
            "At step  10  and at epoch =  29  the loss is =  0.009971496649086475  and accuracy is =  0.98\n",
            "At step  10  and at epoch =  30  the loss is =  0.010250282473862171  and accuracy is =  0.986\n",
            "At step  10  and at epoch =  31  the loss is =  0.00999031774699688  and accuracy is =  0.9896\n",
            "At step  10  and at epoch =  32  the loss is =  0.010165872052311897  and accuracy is =  0.9916\n",
            "At step  10  and at epoch =  33  the loss is =  0.01050521619617939  and accuracy is =  0.9944\n",
            "At step  10  and at epoch =  34  the loss is =  0.010319296270608902  and accuracy is =  0.9934\n",
            "At step  10  and at epoch =  35  the loss is =  0.01028317678719759  and accuracy is =  0.9886\n",
            "At step  10  and at epoch =  36  the loss is =  0.010409305803477764  and accuracy is =  0.987\n",
            "At step  10  and at epoch =  37  the loss is =  0.011088802479207516  and accuracy is =  0.9694\n",
            "At step  10  and at epoch =  38  the loss is =  0.010489307343959808  and accuracy is =  0.9676\n",
            "At step  10  and at epoch =  39  the loss is =  0.009985332377254963  and accuracy is =  0.9948\n",
            "At step  10  and at epoch =  40  the loss is =  0.010037347674369812  and accuracy is =  0.9978\n",
            "At step  10  and at epoch =  41  the loss is =  0.009953483007848263  and accuracy is =  0.9988\n",
            "At step  10  and at epoch =  42  the loss is =  0.010282125324010849  and accuracy is =  0.9996\n",
            "At step  10  and at epoch =  43  the loss is =  0.009931517764925957  and accuracy is =  0.999\n",
            "At step  10  and at epoch =  44  the loss is =  0.010328191332519054  and accuracy is =  0.9994\n",
            "At step  10  and at epoch =  45  the loss is =  0.010597005486488342  and accuracy is =  0.9996\n",
            "At step  10  and at epoch =  46  the loss is =  0.009937687776982784  and accuracy is =  0.9998\n",
            "At step  10  and at epoch =  47  the loss is =  0.009257358498871326  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  48  the loss is =  0.009719215333461761  and accuracy is =  0.9996\n",
            "At step  10  and at epoch =  49  the loss is =  0.00886307843029499  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  50  the loss is =  0.008806616067886353  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  51  the loss is =  0.00879670213907957  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  52  the loss is =  0.008791291154921055  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  53  the loss is =  0.008786698803305626  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  54  the loss is =  0.008782505989074707  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  55  the loss is =  0.00877874344587326  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  56  the loss is =  0.008775385096669197  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  57  the loss is =  0.008771910332143307  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  58  the loss is =  0.008768809959292412  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  59  the loss is =  0.008765697479248047  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  60  the loss is =  0.008762707933783531  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  61  the loss is =  0.008759835734963417  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  62  the loss is =  0.008760770782828331  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  63  the loss is =  0.008761891163885593  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  64  the loss is =  0.008761103264987469  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  65  the loss is =  0.008760109543800354  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  66  the loss is =  0.008759214542806149  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  67  the loss is =  0.008758348412811756  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  68  the loss is =  0.008757591247558594  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  69  the loss is =  0.008756839670240879  and accuracy is =  1.0\n",
            "[49 97 53  5 33 65 62 51 38 61 55 59  6 35 74 71 57 41 70 48]\n",
            "Validation Loss: 0.2396860122680664 Validation Accuracy : 0.3975\n",
            "task = 20 \n",
            "train col =  [64 69  7 37 84 81 67 44 80 56]\n",
            "train col =  [[64 69  7 37 84 81 67 44 80 56]]\n",
            "At step  20  and at epoch =  0  the loss is =  0.07182497531175613  and accuracy is =  0.2464\n",
            "At step  20  and at epoch =  1  the loss is =  0.07896430045366287  and accuracy is =  0.3364\n",
            "At step  20  and at epoch =  2  the loss is =  0.06064360961318016  and accuracy is =  0.3842\n",
            "At step  20  and at epoch =  3  the loss is =  0.053983788937330246  and accuracy is =  0.4154\n",
            "At step  20  and at epoch =  4  the loss is =  0.04867963865399361  and accuracy is =  0.4442\n",
            "At step  20  and at epoch =  5  the loss is =  0.04047630354762077  and accuracy is =  0.4706\n",
            "At step  20  and at epoch =  6  the loss is =  0.03661227971315384  and accuracy is =  0.4918\n",
            "At step  20  and at epoch =  7  the loss is =  0.035591088235378265  and accuracy is =  0.5218\n",
            "At step  20  and at epoch =  8  the loss is =  0.033090077340602875  and accuracy is =  0.5466\n",
            "At step  20  and at epoch =  9  the loss is =  0.03235359117388725  and accuracy is =  0.5736\n",
            "At step  20  and at epoch =  10  the loss is =  0.03393389657139778  and accuracy is =  0.5858\n",
            "At step  20  and at epoch =  11  the loss is =  0.031024307012557983  and accuracy is =  0.613\n",
            "At step  20  and at epoch =  12  the loss is =  0.02969958260655403  and accuracy is =  0.6378\n",
            "At step  20  and at epoch =  13  the loss is =  0.030786216259002686  and accuracy is =  0.6544\n",
            "At step  20  and at epoch =  14  the loss is =  0.02889268659055233  and accuracy is =  0.6766\n",
            "At step  20  and at epoch =  15  the loss is =  0.027677036821842194  and accuracy is =  0.6992\n",
            "At step  20  and at epoch =  16  the loss is =  0.02681334875524044  and accuracy is =  0.7358\n",
            "At step  20  and at epoch =  17  the loss is =  0.024641403928399086  and accuracy is =  0.7574\n",
            "At step  20  and at epoch =  18  the loss is =  0.023071136325597763  and accuracy is =  0.7728\n",
            "At step  20  and at epoch =  19  the loss is =  0.023432912304997444  and accuracy is =  0.799\n",
            "At step  20  and at epoch =  20  the loss is =  0.023012293502688408  and accuracy is =  0.8226\n",
            "At step  20  and at epoch =  21  the loss is =  0.02265668660402298  and accuracy is =  0.8398\n",
            "At step  20  and at epoch =  22  the loss is =  0.023256458342075348  and accuracy is =  0.8488\n",
            "At step  20  and at epoch =  23  the loss is =  0.02172151580452919  and accuracy is =  0.8834\n",
            "At step  20  and at epoch =  24  the loss is =  0.021962406113743782  and accuracy is =  0.8916\n",
            "At step  20  and at epoch =  25  the loss is =  0.021926814690232277  and accuracy is =  0.9122\n",
            "At step  20  and at epoch =  26  the loss is =  0.022210530936717987  and accuracy is =  0.9224\n",
            "At step  20  and at epoch =  27  the loss is =  0.022169079631567  and accuracy is =  0.9358\n",
            "At step  20  and at epoch =  28  the loss is =  0.02053973637521267  and accuracy is =  0.9516\n",
            "At step  20  and at epoch =  29  the loss is =  0.020167212933301926  and accuracy is =  0.9632\n",
            "At step  20  and at epoch =  30  the loss is =  0.02027251198887825  and accuracy is =  0.9688\n",
            "At step  20  and at epoch =  31  the loss is =  0.020716018974781036  and accuracy is =  0.9724\n",
            "At step  20  and at epoch =  32  the loss is =  0.019459035247564316  and accuracy is =  0.986\n",
            "At step  20  and at epoch =  33  the loss is =  0.01923602819442749  and accuracy is =  0.9896\n",
            "At step  20  and at epoch =  34  the loss is =  0.019197531044483185  and accuracy is =  0.9924\n",
            "At step  20  and at epoch =  35  the loss is =  0.01956360973417759  and accuracy is =  0.9932\n",
            "At step  20  and at epoch =  36  the loss is =  0.020184587687253952  and accuracy is =  0.9936\n",
            "At step  20  and at epoch =  37  the loss is =  0.019362522289156914  and accuracy is =  0.995\n",
            "At step  20  and at epoch =  38  the loss is =  0.019591543823480606  and accuracy is =  0.9978\n",
            "At step  20  and at epoch =  39  the loss is =  0.019889861345291138  and accuracy is =  0.9976\n",
            "At step  20  and at epoch =  40  the loss is =  0.018824871629476547  and accuracy is =  0.9988\n",
            "At step  20  and at epoch =  41  the loss is =  0.01811038888990879  and accuracy is =  0.999\n",
            "At step  20  and at epoch =  42  the loss is =  0.017923938110470772  and accuracy is =  0.9996\n",
            "At step  20  and at epoch =  43  the loss is =  0.017741143703460693  and accuracy is =  0.9994\n",
            "At step  20  and at epoch =  44  the loss is =  0.01799115538597107  and accuracy is =  0.9994\n",
            "At step  20  and at epoch =  45  the loss is =  0.018298054113984108  and accuracy is =  0.9992\n",
            "At step  20  and at epoch =  46  the loss is =  0.01884126104414463  and accuracy is =  0.9998\n",
            "At step  20  and at epoch =  47  the loss is =  0.018457485362887383  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  48  the loss is =  0.02117381989955902  and accuracy is =  0.9998\n",
            "At step  20  and at epoch =  49  the loss is =  0.018053526058793068  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  50  the loss is =  0.017486650496721268  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  51  the loss is =  0.01731996424496174  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  52  the loss is =  0.017251774668693542  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  53  the loss is =  0.017221488058567047  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  54  the loss is =  0.01720340922474861  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  55  the loss is =  0.01719163917005062  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  56  the loss is =  0.0171824861317873  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  57  the loss is =  0.017174730077385902  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  58  the loss is =  0.01716751419007778  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  59  the loss is =  0.01716075837612152  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  60  the loss is =  0.017154237255454063  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  61  the loss is =  0.017148250713944435  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  62  the loss is =  0.017139356583356857  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  63  the loss is =  0.01713905856013298  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  64  the loss is =  0.017137911170721054  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  65  the loss is =  0.017136622220277786  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  66  the loss is =  0.017135363072156906  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  67  the loss is =  0.017134232446551323  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  68  the loss is =  0.017133111134171486  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  69  the loss is =  0.01713203266263008  and accuracy is =  1.0\n",
            "[49 97 53  5 33 65 62 51 38 61 55 59  6 35 74 71 57 41 70 48 64 69  7 37\n",
            " 84 81 67 44 80 56]\n",
            "Validation Loss: 0.20727205276489258 Validation Accuracy : 0.25966666666666666\n",
            "task = 30 \n",
            "train col =  [75 79  8 40 94 91 77 87 76 98]\n",
            "train col =  [[75 79  8 40 94 91 77 87 76 98]]\n",
            "At step  30  and at epoch =  0  the loss is =  0.07660753279924393  and accuracy is =  0.2812\n",
            "At step  30  and at epoch =  1  the loss is =  0.0786205381155014  and accuracy is =  0.3966\n",
            "At step  30  and at epoch =  2  the loss is =  0.07151775062084198  and accuracy is =  0.4466\n",
            "At step  30  and at epoch =  3  the loss is =  0.06629381328821182  and accuracy is =  0.4718\n",
            "At step  30  and at epoch =  4  the loss is =  0.057396888732910156  and accuracy is =  0.509\n",
            "At step  30  and at epoch =  5  the loss is =  0.059305042028427124  and accuracy is =  0.5366\n",
            "At step  30  and at epoch =  6  the loss is =  0.05396457388997078  and accuracy is =  0.5716\n",
            "At step  30  and at epoch =  7  the loss is =  0.04996807873249054  and accuracy is =  0.593\n",
            "At step  30  and at epoch =  8  the loss is =  0.04773491248488426  and accuracy is =  0.6298\n",
            "At step  30  and at epoch =  9  the loss is =  0.045827459543943405  and accuracy is =  0.6562\n",
            "At step  30  and at epoch =  10  the loss is =  0.0415230467915535  and accuracy is =  0.6876\n",
            "At step  30  and at epoch =  11  the loss is =  0.04063735529780388  and accuracy is =  0.7112\n",
            "At step  30  and at epoch =  12  the loss is =  0.043065834790468216  and accuracy is =  0.7376\n",
            "At step  30  and at epoch =  13  the loss is =  0.04601427912712097  and accuracy is =  0.754\n",
            "At step  30  and at epoch =  14  the loss is =  0.04048330336809158  and accuracy is =  0.7826\n",
            "At step  30  and at epoch =  15  the loss is =  0.04032743722200394  and accuracy is =  0.809\n",
            "At step  30  and at epoch =  16  the loss is =  0.03994717821478844  and accuracy is =  0.8328\n",
            "At step  30  and at epoch =  17  the loss is =  0.03886635601520538  and accuracy is =  0.8544\n",
            "At step  30  and at epoch =  18  the loss is =  0.036382995545864105  and accuracy is =  0.8682\n",
            "At step  30  and at epoch =  19  the loss is =  0.03551970422267914  and accuracy is =  0.8842\n",
            "At step  30  and at epoch =  20  the loss is =  0.03453659266233444  and accuracy is =  0.9132\n",
            "At step  30  and at epoch =  21  the loss is =  0.033648375421762466  and accuracy is =  0.9278\n",
            "At step  30  and at epoch =  22  the loss is =  0.03399370610713959  and accuracy is =  0.935\n",
            "At step  30  and at epoch =  23  the loss is =  0.03331432491540909  and accuracy is =  0.947\n",
            "At step  30  and at epoch =  24  the loss is =  0.033928416669368744  and accuracy is =  0.9528\n",
            "At step  30  and at epoch =  25  the loss is =  0.03325577452778816  and accuracy is =  0.9658\n",
            "At step  30  and at epoch =  26  the loss is =  0.03349406272172928  and accuracy is =  0.9672\n",
            "At step  30  and at epoch =  27  the loss is =  0.03272425755858421  and accuracy is =  0.9804\n",
            "At step  30  and at epoch =  28  the loss is =  0.032699327915906906  and accuracy is =  0.9862\n",
            "At step  30  and at epoch =  29  the loss is =  0.031436093151569366  and accuracy is =  0.9874\n",
            "At step  30  and at epoch =  30  the loss is =  0.031377214938402176  and accuracy is =  0.9924\n",
            "At step  30  and at epoch =  31  the loss is =  0.03151592239737511  and accuracy is =  0.993\n",
            "At step  30  and at epoch =  32  the loss is =  0.03171896934509277  and accuracy is =  0.9956\n",
            "At step  30  and at epoch =  33  the loss is =  0.032202742993831635  and accuracy is =  0.9968\n",
            "At step  30  and at epoch =  34  the loss is =  0.03342796862125397  and accuracy is =  0.9974\n",
            "At step  30  and at epoch =  35  the loss is =  0.0321846604347229  and accuracy is =  0.9966\n",
            "At step  30  and at epoch =  36  the loss is =  0.03171772137284279  and accuracy is =  0.9978\n",
            "At step  30  and at epoch =  37  the loss is =  0.031141089275479317  and accuracy is =  0.9972\n",
            "At step  30  and at epoch =  38  the loss is =  0.03122813068330288  and accuracy is =  0.9984\n",
            "At step  30  and at epoch =  39  the loss is =  0.031095294281840324  and accuracy is =  0.9986\n",
            "At step  30  and at epoch =  40  the loss is =  0.03131501004099846  and accuracy is =  0.9988\n",
            "At step  30  and at epoch =  41  the loss is =  0.0314321331679821  and accuracy is =  0.999\n",
            "At step  30  and at epoch =  42  the loss is =  0.03183363378047943  and accuracy is =  0.999\n",
            "At step  30  and at epoch =  43  the loss is =  0.031760986894369125  and accuracy is =  0.9986\n",
            "At step  30  and at epoch =  44  the loss is =  0.032236456871032715  and accuracy is =  0.9994\n",
            "At step  30  and at epoch =  45  the loss is =  0.031209785491228104  and accuracy is =  0.9994\n",
            "At step  30  and at epoch =  46  the loss is =  0.031279306858778  and accuracy is =  0.9994\n",
            "At step  30  and at epoch =  47  the loss is =  0.030699092894792557  and accuracy is =  0.9996\n",
            "At step  30  and at epoch =  48  the loss is =  0.03249034285545349  and accuracy is =  0.9994\n",
            "At step  30  and at epoch =  49  the loss is =  0.030426647514104843  and accuracy is =  0.9996\n",
            "At step  30  and at epoch =  50  the loss is =  0.02996310219168663  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  51  the loss is =  0.029834110289812088  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  52  the loss is =  0.029788212850689888  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  53  the loss is =  0.02976629137992859  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  54  the loss is =  0.029752470552921295  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  55  the loss is =  0.02974170632660389  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  56  the loss is =  0.02973281405866146  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  57  the loss is =  0.02972486987709999  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  58  the loss is =  0.029717490077018738  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  59  the loss is =  0.029710788279771805  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  60  the loss is =  0.02970435470342636  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  61  the loss is =  0.029698198661208153  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  62  the loss is =  0.029700249433517456  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  63  the loss is =  0.02970012091100216  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  64  the loss is =  0.02969757653772831  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  65  the loss is =  0.029694966971874237  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  66  the loss is =  0.02969249151647091  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  67  the loss is =  0.02969033643603325  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  68  the loss is =  0.02968832477927208  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  69  the loss is =  0.02968650683760643  and accuracy is =  0.9998\n",
            "[49 97 53  5 33 65 62 51 38 61 55 59  6 35 74 71 57 41 70 48 64 69  7 37\n",
            " 84 81 67 44 80 56 75 79  8 40 94 91 77 87 76 98]\n",
            "Validation Loss: 0.1371731013059616 Validation Accuracy : 0.237\n",
            "task = 40 \n",
            "train col =  [90 28 82 93 30  2 20 42 39 29]\n",
            "train col =  [[90 28 82 93 30  2 20 42 39 29]]\n",
            "At step  40  and at epoch =  0  the loss is =  0.08465220034122467  and accuracy is =  0.301\n",
            "At step  40  and at epoch =  1  the loss is =  0.10048264265060425  and accuracy is =  0.4604\n",
            "At step  40  and at epoch =  2  the loss is =  0.08443878591060638  and accuracy is =  0.5104\n",
            "At step  40  and at epoch =  3  the loss is =  0.08302625268697739  and accuracy is =  0.5502\n",
            "At step  40  and at epoch =  4  the loss is =  0.0722450464963913  and accuracy is =  0.5746\n",
            "At step  40  and at epoch =  5  the loss is =  0.07005246728658676  and accuracy is =  0.5988\n",
            "At step  40  and at epoch =  6  the loss is =  0.06908860802650452  and accuracy is =  0.624\n",
            "At step  40  and at epoch =  7  the loss is =  0.06285953521728516  and accuracy is =  0.6492\n",
            "At step  40  and at epoch =  8  the loss is =  0.06083099544048309  and accuracy is =  0.6796\n",
            "At step  40  and at epoch =  9  the loss is =  0.06057823449373245  and accuracy is =  0.697\n",
            "At step  40  and at epoch =  10  the loss is =  0.05743512883782387  and accuracy is =  0.7252\n",
            "At step  40  and at epoch =  11  the loss is =  0.0577872060239315  and accuracy is =  0.7494\n",
            "At step  40  and at epoch =  12  the loss is =  0.05881147086620331  and accuracy is =  0.7652\n",
            "At step  40  and at epoch =  13  the loss is =  0.05477754399180412  and accuracy is =  0.7892\n",
            "At step  40  and at epoch =  14  the loss is =  0.05713190510869026  and accuracy is =  0.8136\n",
            "At step  40  and at epoch =  15  the loss is =  0.05178593471646309  and accuracy is =  0.8348\n",
            "At step  40  and at epoch =  16  the loss is =  0.051517922431230545  and accuracy is =  0.8466\n",
            "At step  40  and at epoch =  17  the loss is =  0.05087069049477577  and accuracy is =  0.8634\n",
            "At step  40  and at epoch =  18  the loss is =  0.05224272608757019  and accuracy is =  0.879\n",
            "At step  40  and at epoch =  19  the loss is =  0.051390960812568665  and accuracy is =  0.9072\n",
            "At step  40  and at epoch =  20  the loss is =  0.050571221858263016  and accuracy is =  0.915\n",
            "At step  40  and at epoch =  21  the loss is =  0.04685250297188759  and accuracy is =  0.9268\n",
            "At step  40  and at epoch =  22  the loss is =  0.0461190827190876  and accuracy is =  0.9404\n",
            "At step  40  and at epoch =  23  the loss is =  0.046889256685972214  and accuracy is =  0.9542\n",
            "At step  40  and at epoch =  24  the loss is =  0.04998299479484558  and accuracy is =  0.9608\n",
            "At step  40  and at epoch =  25  the loss is =  0.05101722478866577  and accuracy is =  0.9628\n",
            "At step  40  and at epoch =  26  the loss is =  0.047400329262018204  and accuracy is =  0.963\n",
            "At step  40  and at epoch =  27  the loss is =  0.04590429365634918  and accuracy is =  0.9778\n",
            "At step  40  and at epoch =  28  the loss is =  0.044302064925432205  and accuracy is =  0.9866\n",
            "At step  40  and at epoch =  29  the loss is =  0.04343259707093239  and accuracy is =  0.9912\n",
            "At step  40  and at epoch =  30  the loss is =  0.0432538166642189  and accuracy is =  0.9892\n",
            "At step  40  and at epoch =  31  the loss is =  0.04412069171667099  and accuracy is =  0.9924\n",
            "At step  40  and at epoch =  32  the loss is =  0.0443594716489315  and accuracy is =  0.9922\n",
            "At step  40  and at epoch =  33  the loss is =  0.044485483318567276  and accuracy is =  0.9938\n",
            "At step  40  and at epoch =  34  the loss is =  0.04474066197872162  and accuracy is =  0.9944\n",
            "At step  40  and at epoch =  35  the loss is =  0.04451526701450348  and accuracy is =  0.9872\n",
            "At step  40  and at epoch =  36  the loss is =  0.043923452496528625  and accuracy is =  0.9922\n",
            "At step  40  and at epoch =  37  the loss is =  0.04431045427918434  and accuracy is =  0.9964\n",
            "At step  40  and at epoch =  38  the loss is =  0.04384825751185417  and accuracy is =  0.9992\n",
            "At step  40  and at epoch =  39  the loss is =  0.04278639703989029  and accuracy is =  0.9986\n",
            "At step  40  and at epoch =  40  the loss is =  0.04245293140411377  and accuracy is =  0.9994\n",
            "At step  40  and at epoch =  41  the loss is =  0.04217345267534256  and accuracy is =  0.9992\n",
            "At step  40  and at epoch =  42  the loss is =  0.04215535894036293  and accuracy is =  0.9992\n",
            "At step  40  and at epoch =  43  the loss is =  0.042036671191453934  and accuracy is =  0.9996\n",
            "At step  40  and at epoch =  44  the loss is =  0.04223283380270004  and accuracy is =  0.999\n",
            "At step  40  and at epoch =  45  the loss is =  0.04251158609986305  and accuracy is =  0.9998\n",
            "At step  40  and at epoch =  46  the loss is =  0.04278327897191048  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  47  the loss is =  0.04238246753811836  and accuracy is =  0.9992\n",
            "At step  40  and at epoch =  48  the loss is =  0.04406888782978058  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  49  the loss is =  0.041722334921360016  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  50  the loss is =  0.04125351831316948  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  51  the loss is =  0.041117046028375626  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  52  the loss is =  0.04106900468468666  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  53  the loss is =  0.041044991463422775  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  54  the loss is =  0.04102791100740433  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  55  the loss is =  0.0410146526992321  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  56  the loss is =  0.041002873331308365  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  57  the loss is =  0.0409918949007988  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  58  the loss is =  0.040981244295835495  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  59  the loss is =  0.04097149893641472  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  60  the loss is =  0.04096227139234543  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  61  the loss is =  0.040953073650598526  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  62  the loss is =  0.04093863442540169  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  63  the loss is =  0.040938347578048706  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  64  the loss is =  0.04093678295612335  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  65  the loss is =  0.040935028344392776  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  66  the loss is =  0.04093329980969429  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  67  the loss is =  0.040931571274995804  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  68  the loss is =  0.0409298837184906  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  69  the loss is =  0.0409281924366951  and accuracy is =  1.0\n",
            "[49 97 53  5 33 65 62 51 38 61 55 59  6 35 74 71 57 41 70 48 64 69  7 37\n",
            " 84 81 67 44 80 56 75 79  8 40 94 91 77 87 76 98 90 28 82 93 30  2 20 42\n",
            " 39 29]\n",
            "Validation Loss: 0.16539989411830902 Validation Accuracy : 0.2114\n",
            "task = 50 \n",
            "train col =  [34 96 43  3 22 54 52 36 25 50]\n",
            "train col =  [[34 96 43  3 22 54 52 36 25 50]]\n",
            "At step  50  and at epoch =  0  the loss is =  0.09306241571903229  and accuracy is =  0.3006\n",
            "At step  50  and at epoch =  1  the loss is =  0.10889595746994019  and accuracy is =  0.4224\n",
            "At step  50  and at epoch =  2  the loss is =  0.09830132871866226  and accuracy is =  0.4688\n",
            "At step  50  and at epoch =  3  the loss is =  0.08405749499797821  and accuracy is =  0.495\n",
            "At step  50  and at epoch =  4  the loss is =  0.08417720347642899  and accuracy is =  0.5254\n",
            "At step  50  and at epoch =  5  the loss is =  0.08744002133607864  and accuracy is =  0.545\n",
            "At step  50  and at epoch =  6  the loss is =  0.07905939966440201  and accuracy is =  0.574\n",
            "At step  50  and at epoch =  7  the loss is =  0.07118590921163559  and accuracy is =  0.595\n",
            "At step  50  and at epoch =  8  the loss is =  0.06677491962909698  and accuracy is =  0.625\n",
            "At step  50  and at epoch =  9  the loss is =  0.06620049476623535  and accuracy is =  0.6484\n",
            "At step  50  and at epoch =  10  the loss is =  0.06759559363126755  and accuracy is =  0.664\n",
            "At step  50  and at epoch =  11  the loss is =  0.06659845262765884  and accuracy is =  0.6804\n",
            "At step  50  and at epoch =  12  the loss is =  0.06326066702604294  and accuracy is =  0.7098\n",
            "At step  50  and at epoch =  13  the loss is =  0.06312219053506851  and accuracy is =  0.7362\n",
            "At step  50  and at epoch =  14  the loss is =  0.06248793378472328  and accuracy is =  0.7562\n",
            "At step  50  and at epoch =  15  the loss is =  0.06230849027633667  and accuracy is =  0.7676\n",
            "At step  50  and at epoch =  16  the loss is =  0.06514378637075424  and accuracy is =  0.7884\n",
            "At step  50  and at epoch =  17  the loss is =  0.06279284507036209  and accuracy is =  0.8068\n",
            "At step  50  and at epoch =  18  the loss is =  0.06162402033805847  and accuracy is =  0.8256\n",
            "At step  50  and at epoch =  19  the loss is =  0.06026798114180565  and accuracy is =  0.8448\n",
            "At step  50  and at epoch =  20  the loss is =  0.059467848390340805  and accuracy is =  0.8666\n",
            "At step  50  and at epoch =  21  the loss is =  0.06026738882064819  and accuracy is =  0.8688\n",
            "At step  50  and at epoch =  22  the loss is =  0.059438880532979965  and accuracy is =  0.8894\n",
            "At step  50  and at epoch =  23  the loss is =  0.059364575892686844  and accuracy is =  0.9092\n",
            "At step  50  and at epoch =  24  the loss is =  0.058264024555683136  and accuracy is =  0.9178\n",
            "At step  50  and at epoch =  25  the loss is =  0.05784418806433678  and accuracy is =  0.9376\n",
            "At step  50  and at epoch =  26  the loss is =  0.05680539831519127  and accuracy is =  0.9472\n",
            "At step  50  and at epoch =  27  the loss is =  0.05748854577541351  and accuracy is =  0.9528\n",
            "At step  50  and at epoch =  28  the loss is =  0.056421488523483276  and accuracy is =  0.9556\n",
            "At step  50  and at epoch =  29  the loss is =  0.0563531294465065  and accuracy is =  0.9694\n",
            "At step  50  and at epoch =  30  the loss is =  0.056713275611400604  and accuracy is =  0.9732\n",
            "At step  50  and at epoch =  31  the loss is =  0.056356389075517654  and accuracy is =  0.9778\n",
            "At step  50  and at epoch =  32  the loss is =  0.05543641000986099  and accuracy is =  0.9846\n",
            "At step  50  and at epoch =  33  the loss is =  0.05449547991156578  and accuracy is =  0.9928\n",
            "At step  50  and at epoch =  34  the loss is =  0.054043691605329514  and accuracy is =  0.9938\n",
            "At step  50  and at epoch =  35  the loss is =  0.05426604673266411  and accuracy is =  0.995\n",
            "At step  50  and at epoch =  36  the loss is =  0.05459819361567497  and accuracy is =  0.9952\n",
            "At step  50  and at epoch =  37  the loss is =  0.054320838302373886  and accuracy is =  0.9944\n",
            "At step  50  and at epoch =  38  the loss is =  0.053805138915777206  and accuracy is =  0.9932\n",
            "At step  50  and at epoch =  39  the loss is =  0.05357256904244423  and accuracy is =  0.997\n",
            "At step  50  and at epoch =  40  the loss is =  0.05287560448050499  and accuracy is =  0.9978\n",
            "At step  50  and at epoch =  41  the loss is =  0.05287015810608864  and accuracy is =  0.9982\n",
            "At step  50  and at epoch =  42  the loss is =  0.05266896262764931  and accuracy is =  0.9988\n",
            "At step  50  and at epoch =  43  the loss is =  0.05268458276987076  and accuracy is =  0.999\n",
            "At step  50  and at epoch =  44  the loss is =  0.05275825783610344  and accuracy is =  0.9994\n",
            "At step  50  and at epoch =  45  the loss is =  0.05274712294340134  and accuracy is =  0.9988\n",
            "At step  50  and at epoch =  46  the loss is =  0.052924420684576035  and accuracy is =  0.9986\n",
            "At step  50  and at epoch =  47  the loss is =  0.05257575213909149  and accuracy is =  0.9996\n",
            "At step  50  and at epoch =  48  the loss is =  0.05403665453195572  and accuracy is =  0.9996\n",
            "At step  50  and at epoch =  49  the loss is =  0.05160054937005043  and accuracy is =  0.9998\n",
            "At step  50  and at epoch =  50  the loss is =  0.051356542855501175  and accuracy is =  0.9998\n",
            "At step  50  and at epoch =  51  the loss is =  0.05130527541041374  and accuracy is =  0.9998\n",
            "At step  50  and at epoch =  52  the loss is =  0.05128447338938713  and accuracy is =  0.9998\n",
            "At step  50  and at epoch =  53  the loss is =  0.051271289587020874  and accuracy is =  0.9998\n",
            "At step  50  and at epoch =  54  the loss is =  0.05125964432954788  and accuracy is =  0.9998\n",
            "At step  50  and at epoch =  55  the loss is =  0.05124972388148308  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  56  the loss is =  0.05124017968773842  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  57  the loss is =  0.05123110115528107  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  58  the loss is =  0.051222436130046844  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  59  the loss is =  0.05121425911784172  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  60  the loss is =  0.051206205040216446  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  61  the loss is =  0.05119838938117027  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  62  the loss is =  0.05118345096707344  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  63  the loss is =  0.05118374153971672  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  64  the loss is =  0.051182206720113754  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  65  the loss is =  0.05118038132786751  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  66  the loss is =  0.05117848888039589  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  67  the loss is =  0.051176633685827255  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  68  the loss is =  0.051174867898225784  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  69  the loss is =  0.051173124462366104  and accuracy is =  1.0\n",
            "[49 97 53  5 33 65 62 51 38 61 55 59  6 35 74 71 57 41 70 48 64 69  7 37\n",
            " 84 81 67 44 80 56 75 79  8 40 94 91 77 87 76 98 90 28 82 93 30  2 20 42\n",
            " 39 29 34 96 43  3 22 54 52 36 25 50]\n",
            "Validation Loss: 0.17010760307312012 Validation Accuracy : 0.17733333333333334\n",
            "task = 60 \n",
            "train col =  [58 63  4 24 83 78 60 31 73 17]\n",
            "train col =  [[58 63  4 24 83 78 60 31 73 17]]\n",
            "At step  60  and at epoch =  0  the loss is =  0.09330004453659058  and accuracy is =  0.4296\n",
            "At step  60  and at epoch =  1  the loss is =  0.12295092642307281  and accuracy is =  0.5722\n",
            "At step  60  and at epoch =  2  the loss is =  0.10109292715787888  and accuracy is =  0.6248\n",
            "At step  60  and at epoch =  3  the loss is =  0.09188812226057053  and accuracy is =  0.6504\n",
            "At step  60  and at epoch =  4  the loss is =  0.09001325070858002  and accuracy is =  0.674\n",
            "At step  60  and at epoch =  5  the loss is =  0.08533788472414017  and accuracy is =  0.7014\n",
            "At step  60  and at epoch =  6  the loss is =  0.08083578199148178  and accuracy is =  0.7252\n",
            "At step  60  and at epoch =  7  the loss is =  0.08117227256298065  and accuracy is =  0.7392\n",
            "At step  60  and at epoch =  8  the loss is =  0.07804916054010391  and accuracy is =  0.7666\n",
            "At step  60  and at epoch =  9  the loss is =  0.07846053689718246  and accuracy is =  0.7868\n",
            "At step  60  and at epoch =  10  the loss is =  0.07823771238327026  and accuracy is =  0.8002\n",
            "At step  60  and at epoch =  11  the loss is =  0.07973650842905045  and accuracy is =  0.821\n",
            "At step  60  and at epoch =  12  the loss is =  0.07409106194972992  and accuracy is =  0.8356\n",
            "At step  60  and at epoch =  13  the loss is =  0.07352598756551743  and accuracy is =  0.8512\n",
            "At step  60  and at epoch =  14  the loss is =  0.0732094794511795  and accuracy is =  0.8676\n",
            "At step  60  and at epoch =  15  the loss is =  0.07364907115697861  and accuracy is =  0.8906\n",
            "At step  60  and at epoch =  16  the loss is =  0.07464376091957092  and accuracy is =  0.901\n",
            "At step  60  and at epoch =  17  the loss is =  0.07530523091554642  and accuracy is =  0.913\n",
            "At step  60  and at epoch =  18  the loss is =  0.07434907555580139  and accuracy is =  0.9242\n",
            "At step  60  and at epoch =  19  the loss is =  0.07889038324356079  and accuracy is =  0.9304\n",
            "At step  60  and at epoch =  20  the loss is =  0.0762801319360733  and accuracy is =  0.9398\n",
            "At step  60  and at epoch =  21  the loss is =  0.07306075096130371  and accuracy is =  0.9532\n",
            "At step  60  and at epoch =  22  the loss is =  0.07218844443559647  and accuracy is =  0.9626\n",
            "At step  60  and at epoch =  23  the loss is =  0.0723690465092659  and accuracy is =  0.9696\n",
            "At step  60  and at epoch =  24  the loss is =  0.0710313469171524  and accuracy is =  0.979\n",
            "At step  60  and at epoch =  25  the loss is =  0.07096007466316223  and accuracy is =  0.9808\n",
            "At step  60  and at epoch =  26  the loss is =  0.07045376300811768  and accuracy is =  0.9844\n",
            "At step  60  and at epoch =  27  the loss is =  0.07167190313339233  and accuracy is =  0.9856\n",
            "At step  60  and at epoch =  28  the loss is =  0.07083573937416077  and accuracy is =  0.987\n",
            "At step  60  and at epoch =  29  the loss is =  0.06987769156694412  and accuracy is =  0.9912\n",
            "At step  60  and at epoch =  30  the loss is =  0.06835336238145828  and accuracy is =  0.9936\n",
            "At step  60  and at epoch =  31  the loss is =  0.06781748682260513  and accuracy is =  0.994\n",
            "At step  60  and at epoch =  32  the loss is =  0.06782437860965729  and accuracy is =  0.9944\n",
            "At step  60  and at epoch =  33  the loss is =  0.06807177513837814  and accuracy is =  0.9964\n",
            "At step  60  and at epoch =  34  the loss is =  0.06810032576322556  and accuracy is =  0.997\n",
            "At step  60  and at epoch =  35  the loss is =  0.06869912892580032  and accuracy is =  0.9976\n",
            "At step  60  and at epoch =  36  the loss is =  0.06854642182588577  and accuracy is =  0.997\n",
            "At step  60  and at epoch =  37  the loss is =  0.06983580440282822  and accuracy is =  0.9972\n",
            "At step  60  and at epoch =  38  the loss is =  0.07013339549303055  and accuracy is =  0.997\n",
            "At step  60  and at epoch =  39  the loss is =  0.06795580685138702  and accuracy is =  0.9986\n",
            "At step  60  and at epoch =  40  the loss is =  0.06814918667078018  and accuracy is =  0.9982\n",
            "At step  60  and at epoch =  41  the loss is =  0.06865896284580231  and accuracy is =  0.9984\n",
            "At step  60  and at epoch =  42  the loss is =  0.06862198561429977  and accuracy is =  0.9988\n",
            "At step  60  and at epoch =  43  the loss is =  0.06853890419006348  and accuracy is =  0.999\n",
            "At step  60  and at epoch =  44  the loss is =  0.06821493059396744  and accuracy is =  0.9988\n",
            "At step  60  and at epoch =  45  the loss is =  0.0681280568242073  and accuracy is =  0.9996\n",
            "At step  60  and at epoch =  46  the loss is =  0.06779994815587997  and accuracy is =  0.9992\n",
            "At step  60  and at epoch =  47  the loss is =  0.06755177676677704  and accuracy is =  0.9996\n",
            "At step  60  and at epoch =  48  the loss is =  0.0700383186340332  and accuracy is =  0.9996\n",
            "At step  60  and at epoch =  49  the loss is =  0.06669504195451736  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  50  the loss is =  0.0663594901561737  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  51  the loss is =  0.06629589200019836  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  52  the loss is =  0.06627331674098969  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  53  the loss is =  0.06626012921333313  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  54  the loss is =  0.06625007838010788  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  55  the loss is =  0.06624139845371246  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  56  the loss is =  0.06623360514640808  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  57  the loss is =  0.06622622162103653  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  58  the loss is =  0.06621906161308289  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  59  the loss is =  0.06621228158473969  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  60  the loss is =  0.06620578467845917  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  61  the loss is =  0.06619967520236969  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  62  the loss is =  0.06618766486644745  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  63  the loss is =  0.06618763506412506  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  64  the loss is =  0.0661858469247818  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  65  the loss is =  0.06618402153253555  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  66  the loss is =  0.06618235260248184  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  67  the loss is =  0.06618073582649231  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  68  the loss is =  0.06617922335863113  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  69  the loss is =  0.06617775559425354  and accuracy is =  1.0\n",
            "[49 97 53  5 33 65 62 51 38 61 55 59  6 35 74 71 57 41 70 48 64 69  7 37\n",
            " 84 81 67 44 80 56 75 79  8 40 94 91 77 87 76 98 90 28 82 93 30  2 20 42\n",
            " 39 29 34 96 43  3 22 54 52 36 25 50 58 63  4 24 83 78 60 31 73 17]\n",
            "Validation Loss: 0.15662303566932678 Validation Accuracy : 0.1657142857142857\n",
            "task = 70 \n",
            "train col =  [92 21 86 23  1 15 32 27 95 16]\n",
            "train col =  [[92 21 86 23  1 15 32 27 95 16]]\n",
            "At step  70  and at epoch =  0  the loss is =  0.10470863431692123  and accuracy is =  0.3572\n",
            "At step  70  and at epoch =  1  the loss is =  0.1401154100894928  and accuracy is =  0.5178\n",
            "At step  70  and at epoch =  2  the loss is =  0.13814087212085724  and accuracy is =  0.559\n",
            "At step  70  and at epoch =  3  the loss is =  0.11342601478099823  and accuracy is =  0.5902\n",
            "At step  70  and at epoch =  4  the loss is =  0.09557897597551346  and accuracy is =  0.6228\n",
            "At step  70  and at epoch =  5  the loss is =  0.0911196768283844  and accuracy is =  0.646\n",
            "At step  70  and at epoch =  6  the loss is =  0.09006944298744202  and accuracy is =  0.6666\n",
            "At step  70  and at epoch =  7  the loss is =  0.09319812804460526  and accuracy is =  0.6824\n",
            "At step  70  and at epoch =  8  the loss is =  0.0890478789806366  and accuracy is =  0.699\n",
            "At step  70  and at epoch =  9  the loss is =  0.08556050807237625  and accuracy is =  0.719\n",
            "At step  70  and at epoch =  10  the loss is =  0.08611459285020828  and accuracy is =  0.7396\n",
            "At step  70  and at epoch =  11  the loss is =  0.08198890835046768  and accuracy is =  0.7628\n",
            "At step  70  and at epoch =  12  the loss is =  0.0823795422911644  and accuracy is =  0.7796\n",
            "At step  70  and at epoch =  13  the loss is =  0.08070944249629974  and accuracy is =  0.7934\n",
            "At step  70  and at epoch =  14  the loss is =  0.08179572224617004  and accuracy is =  0.8112\n",
            "At step  70  and at epoch =  15  the loss is =  0.08232133835554123  and accuracy is =  0.834\n",
            "At step  70  and at epoch =  16  the loss is =  0.08376666903495789  and accuracy is =  0.8478\n",
            "At step  70  and at epoch =  17  the loss is =  0.08102042227983475  and accuracy is =  0.864\n",
            "At step  70  and at epoch =  18  the loss is =  0.07995343208312988  and accuracy is =  0.876\n",
            "At step  70  and at epoch =  19  the loss is =  0.07863303273916245  and accuracy is =  0.8946\n",
            "At step  70  and at epoch =  20  the loss is =  0.07826577126979828  and accuracy is =  0.9072\n",
            "At step  70  and at epoch =  21  the loss is =  0.07809775322675705  and accuracy is =  0.9164\n",
            "At step  70  and at epoch =  22  the loss is =  0.07778696715831757  and accuracy is =  0.9286\n",
            "At step  70  and at epoch =  23  the loss is =  0.07673422992229462  and accuracy is =  0.938\n",
            "At step  70  and at epoch =  24  the loss is =  0.07735986262559891  and accuracy is =  0.9526\n",
            "At step  70  and at epoch =  25  the loss is =  0.07718101143836975  and accuracy is =  0.954\n",
            "At step  70  and at epoch =  26  the loss is =  0.07853776216506958  and accuracy is =  0.9644\n",
            "At step  70  and at epoch =  27  the loss is =  0.07653900235891342  and accuracy is =  0.9654\n",
            "At step  70  and at epoch =  28  the loss is =  0.07670973986387253  and accuracy is =  0.9728\n",
            "At step  70  and at epoch =  29  the loss is =  0.0780981257557869  and accuracy is =  0.9776\n",
            "At step  70  and at epoch =  30  the loss is =  0.07706473022699356  and accuracy is =  0.9804\n",
            "At step  70  and at epoch =  31  the loss is =  0.07867942750453949  and accuracy is =  0.984\n",
            "At step  70  and at epoch =  32  the loss is =  0.07711400091648102  and accuracy is =  0.9834\n",
            "At step  70  and at epoch =  33  the loss is =  0.07522580772638321  and accuracy is =  0.9876\n",
            "At step  70  and at epoch =  34  the loss is =  0.07503583282232285  and accuracy is =  0.9912\n",
            "At step  70  and at epoch =  35  the loss is =  0.07493602484464645  and accuracy is =  0.9918\n",
            "At step  70  and at epoch =  36  the loss is =  0.07518046349287033  and accuracy is =  0.9942\n",
            "At step  70  and at epoch =  37  the loss is =  0.07471034675836563  and accuracy is =  0.9946\n",
            "At step  70  and at epoch =  38  the loss is =  0.07513973116874695  and accuracy is =  0.9966\n",
            "At step  70  and at epoch =  39  the loss is =  0.07497529685497284  and accuracy is =  0.996\n",
            "At step  70  and at epoch =  40  the loss is =  0.07554791122674942  and accuracy is =  0.9956\n",
            "At step  70  and at epoch =  41  the loss is =  0.07404821366071701  and accuracy is =  0.9976\n",
            "At step  70  and at epoch =  42  the loss is =  0.07367993146181107  and accuracy is =  0.9972\n",
            "At step  70  and at epoch =  43  the loss is =  0.07332874834537506  and accuracy is =  0.9984\n",
            "At step  70  and at epoch =  44  the loss is =  0.07327207922935486  and accuracy is =  0.998\n",
            "At step  70  and at epoch =  45  the loss is =  0.07335080206394196  and accuracy is =  0.9988\n",
            "At step  70  and at epoch =  46  the loss is =  0.07383944094181061  and accuracy is =  0.999\n",
            "At step  70  and at epoch =  47  the loss is =  0.07318699359893799  and accuracy is =  0.9988\n",
            "At step  70  and at epoch =  48  the loss is =  0.07579565048217773  and accuracy is =  0.999\n",
            "At step  70  and at epoch =  49  the loss is =  0.07246555387973785  and accuracy is =  0.9992\n",
            "At step  70  and at epoch =  50  the loss is =  0.07211299240589142  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  51  the loss is =  0.07202538102865219  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  52  the loss is =  0.07199206948280334  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  53  the loss is =  0.07197373360395432  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  54  the loss is =  0.07196026295423508  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  55  the loss is =  0.07194902002811432  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  56  the loss is =  0.07193905860185623  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  57  the loss is =  0.0719299390912056  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  58  the loss is =  0.07192149758338928  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  59  the loss is =  0.07191307097673416  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  60  the loss is =  0.07190493494272232  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  61  the loss is =  0.07189703732728958  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  62  the loss is =  0.07187683135271072  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  63  the loss is =  0.07187740504741669  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  64  the loss is =  0.07187610119581223  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  65  the loss is =  0.07187455892562866  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  66  the loss is =  0.07187296450138092  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  67  the loss is =  0.07187139242887497  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  68  the loss is =  0.07186980545520782  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  69  the loss is =  0.07186827808618546  and accuracy is =  0.9998\n",
            "[49 97 53  5 33 65 62 51 38 61 55 59  6 35 74 71 57 41 70 48 64 69  7 37\n",
            " 84 81 67 44 80 56 75 79  8 40 94 91 77 87 76 98 90 28 82 93 30  2 20 42\n",
            " 39 29 34 96 43  3 22 54 52 36 25 50 58 63  4 24 83 78 60 31 73 17 92 21\n",
            " 86 23  1 15 32 27 95 16]\n",
            "Validation Loss: 0.1497681885957718 Validation Accuracy : 0.162375\n",
            "task = 80 \n",
            "train col =  [46 47 66 12 19 10 26 72 11  9]\n",
            "train col =  [[46 47 66 12 19 10 26 72 11  9]]\n",
            "At step  80  and at epoch =  0  the loss is =  0.12078143656253815  and accuracy is =  0.3036\n",
            "At step  80  and at epoch =  1  the loss is =  0.1644248515367508  and accuracy is =  0.4108\n",
            "At step  80  and at epoch =  2  the loss is =  0.15657323598861694  and accuracy is =  0.4616\n",
            "At step  80  and at epoch =  3  the loss is =  0.14136964082717896  and accuracy is =  0.4798\n",
            "At step  80  and at epoch =  4  the loss is =  0.1225818395614624  and accuracy is =  0.5068\n",
            "At step  80  and at epoch =  5  the loss is =  0.11368356645107269  and accuracy is =  0.5244\n",
            "At step  80  and at epoch =  6  the loss is =  0.11024690419435501  and accuracy is =  0.554\n",
            "At step  80  and at epoch =  7  the loss is =  0.10734537243843079  and accuracy is =  0.5674\n",
            "At step  80  and at epoch =  8  the loss is =  0.1042470708489418  and accuracy is =  0.5898\n",
            "At step  80  and at epoch =  9  the loss is =  0.09998634457588196  and accuracy is =  0.6022\n",
            "At step  80  and at epoch =  10  the loss is =  0.10017094016075134  and accuracy is =  0.6282\n",
            "At step  80  and at epoch =  11  the loss is =  0.09835304319858551  and accuracy is =  0.653\n",
            "At step  80  and at epoch =  12  the loss is =  0.096062570810318  and accuracy is =  0.67\n",
            "At step  80  and at epoch =  13  the loss is =  0.09731510281562805  and accuracy is =  0.684\n",
            "At step  80  and at epoch =  14  the loss is =  0.0958569124341011  and accuracy is =  0.7086\n",
            "At step  80  and at epoch =  15  the loss is =  0.09423010796308517  and accuracy is =  0.73\n",
            "At step  80  and at epoch =  16  the loss is =  0.0918421745300293  and accuracy is =  0.751\n",
            "At step  80  and at epoch =  17  the loss is =  0.09092110395431519  and accuracy is =  0.7754\n",
            "At step  80  and at epoch =  18  the loss is =  0.09103033691644669  and accuracy is =  0.7902\n",
            "At step  80  and at epoch =  19  the loss is =  0.09093544632196426  and accuracy is =  0.809\n",
            "At step  80  and at epoch =  20  the loss is =  0.09016688913106918  and accuracy is =  0.8384\n",
            "At step  80  and at epoch =  21  the loss is =  0.08965945988893509  and accuracy is =  0.848\n",
            "At step  80  and at epoch =  22  the loss is =  0.089022196829319  and accuracy is =  0.867\n",
            "At step  80  and at epoch =  23  the loss is =  0.08934686332941055  and accuracy is =  0.893\n",
            "At step  80  and at epoch =  24  the loss is =  0.09032271057367325  and accuracy is =  0.9044\n",
            "At step  80  and at epoch =  25  the loss is =  0.09540515393018723  and accuracy is =  0.9012\n",
            "At step  80  and at epoch =  26  the loss is =  0.09757202118635178  and accuracy is =  0.9132\n",
            "At step  80  and at epoch =  27  the loss is =  0.09361261129379272  and accuracy is =  0.927\n",
            "At step  80  and at epoch =  28  the loss is =  0.08764024823904037  and accuracy is =  0.9414\n",
            "At step  80  and at epoch =  29  the loss is =  0.08529666066169739  and accuracy is =  0.9508\n",
            "At step  80  and at epoch =  30  the loss is =  0.08520028740167618  and accuracy is =  0.9604\n",
            "At step  80  and at epoch =  31  the loss is =  0.08523934334516525  and accuracy is =  0.9624\n",
            "At step  80  and at epoch =  32  the loss is =  0.08607370406389236  and accuracy is =  0.9668\n",
            "At step  80  and at epoch =  33  the loss is =  0.08617740124464035  and accuracy is =  0.9792\n",
            "At step  80  and at epoch =  34  the loss is =  0.08630718290805817  and accuracy is =  0.9802\n",
            "At step  80  and at epoch =  35  the loss is =  0.08617241680622101  and accuracy is =  0.9798\n",
            "At step  80  and at epoch =  36  the loss is =  0.08483397960662842  and accuracy is =  0.9844\n",
            "At step  80  and at epoch =  37  the loss is =  0.08416854590177536  and accuracy is =  0.9862\n",
            "At step  80  and at epoch =  38  the loss is =  0.08387859165668488  and accuracy is =  0.9926\n",
            "At step  80  and at epoch =  39  the loss is =  0.08486898243427277  and accuracy is =  0.9926\n",
            "At step  80  and at epoch =  40  the loss is =  0.08484193682670593  and accuracy is =  0.9928\n",
            "At step  80  and at epoch =  41  the loss is =  0.08392202109098434  and accuracy is =  0.9948\n",
            "At step  80  and at epoch =  42  the loss is =  0.08267324417829514  and accuracy is =  0.9948\n",
            "At step  80  and at epoch =  43  the loss is =  0.08271968364715576  and accuracy is =  0.9972\n",
            "At step  80  and at epoch =  44  the loss is =  0.08306194096803665  and accuracy is =  0.9954\n",
            "At step  80  and at epoch =  45  the loss is =  0.08381610363721848  and accuracy is =  0.9972\n",
            "At step  80  and at epoch =  46  the loss is =  0.08394159376621246  and accuracy is =  0.9968\n",
            "At step  80  and at epoch =  47  the loss is =  0.08487705141305923  and accuracy is =  0.9984\n",
            "At step  80  and at epoch =  48  the loss is =  0.09170888364315033  and accuracy is =  0.9972\n",
            "At step  80  and at epoch =  49  the loss is =  0.08330217003822327  and accuracy is =  0.999\n",
            "At step  80  and at epoch =  50  the loss is =  0.08203783631324768  and accuracy is =  0.9994\n",
            "At step  80  and at epoch =  51  the loss is =  0.08161479979753494  and accuracy is =  0.9996\n",
            "At step  80  and at epoch =  52  the loss is =  0.08144766837358475  and accuracy is =  0.9996\n",
            "At step  80  and at epoch =  53  the loss is =  0.0813651829957962  and accuracy is =  0.9996\n",
            "At step  80  and at epoch =  54  the loss is =  0.08131570369005203  and accuracy is =  0.9996\n",
            "At step  80  and at epoch =  55  the loss is =  0.08128102123737335  and accuracy is =  0.9996\n",
            "At step  80  and at epoch =  56  the loss is =  0.08125373721122742  and accuracy is =  0.9996\n",
            "At step  80  and at epoch =  57  the loss is =  0.08123055100440979  and accuracy is =  0.9996\n",
            "At step  80  and at epoch =  58  the loss is =  0.0812101885676384  and accuracy is =  0.9998\n",
            "At step  80  and at epoch =  59  the loss is =  0.081191785633564  and accuracy is =  0.9998\n",
            "At step  80  and at epoch =  60  the loss is =  0.0811745822429657  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  61  the loss is =  0.08115864545106888  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  62  the loss is =  0.081121064722538  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  63  the loss is =  0.0811208114027977  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  64  the loss is =  0.08111914247274399  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  65  the loss is =  0.08111711591482162  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  66  the loss is =  0.08111484348773956  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  67  the loss is =  0.08111252635717392  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  68  the loss is =  0.08111011981964111  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  69  the loss is =  0.08110763132572174  and accuracy is =  1.0\n",
            "[49 97 53  5 33 65 62 51 38 61 55 59  6 35 74 71 57 41 70 48 64 69  7 37\n",
            " 84 81 67 44 80 56 75 79  8 40 94 91 77 87 76 98 90 28 82 93 30  2 20 42\n",
            " 39 29 34 96 43  3 22 54 52 36 25 50 58 63  4 24 83 78 60 31 73 17 92 21\n",
            " 86 23  1 15 32 27 95 16 46 47 66 12 19 10 26 72 11  9]\n",
            "Validation Loss: 0.13733237981796265 Validation Accuracy : 0.1381111111111111\n",
            "task = 90 \n",
            "train col =  [18 89  0 68 14 13 45 99 88 85]\n",
            "train col =  [[18 89  0 68 14 13 45 99 88 85]]\n",
            "At step  90  and at epoch =  0  the loss is =  0.13488256931304932  and accuracy is =  0.3236\n",
            "At step  90  and at epoch =  1  the loss is =  0.17363537847995758  and accuracy is =  0.4678\n",
            "At step  90  and at epoch =  2  the loss is =  0.18066783249378204  and accuracy is =  0.5148\n",
            "At step  90  and at epoch =  3  the loss is =  0.14508256316184998  and accuracy is =  0.5474\n",
            "At step  90  and at epoch =  4  the loss is =  0.13632209599018097  and accuracy is =  0.5702\n",
            "At step  90  and at epoch =  5  the loss is =  0.13380451500415802  and accuracy is =  0.5928\n",
            "At step  90  and at epoch =  6  the loss is =  0.1293785125017166  and accuracy is =  0.6164\n",
            "At step  90  and at epoch =  7  the loss is =  0.12029141932725906  and accuracy is =  0.6304\n",
            "At step  90  and at epoch =  8  the loss is =  0.11736779659986496  and accuracy is =  0.6532\n",
            "At step  90  and at epoch =  9  the loss is =  0.11373373121023178  and accuracy is =  0.6724\n",
            "At step  90  and at epoch =  10  the loss is =  0.11294778436422348  and accuracy is =  0.693\n",
            "At step  90  and at epoch =  11  the loss is =  0.11260978132486343  and accuracy is =  0.7144\n",
            "At step  90  and at epoch =  12  the loss is =  0.11330115795135498  and accuracy is =  0.7322\n",
            "At step  90  and at epoch =  13  the loss is =  0.11614470928907394  and accuracy is =  0.751\n",
            "At step  90  and at epoch =  14  the loss is =  0.11383520066738129  and accuracy is =  0.766\n",
            "At step  90  and at epoch =  15  the loss is =  0.11229663342237473  and accuracy is =  0.785\n",
            "At step  90  and at epoch =  16  the loss is =  0.11073555797338486  and accuracy is =  0.8058\n",
            "At step  90  and at epoch =  17  the loss is =  0.11104510724544525  and accuracy is =  0.8234\n",
            "At step  90  and at epoch =  18  the loss is =  0.1110326424241066  and accuracy is =  0.8432\n",
            "At step  90  and at epoch =  19  the loss is =  0.1104244589805603  and accuracy is =  0.8532\n",
            "At step  90  and at epoch =  20  the loss is =  0.10914115607738495  and accuracy is =  0.876\n",
            "At step  90  and at epoch =  21  the loss is =  0.10639552772045135  and accuracy is =  0.8876\n",
            "At step  90  and at epoch =  22  the loss is =  0.10466475039720535  and accuracy is =  0.8976\n",
            "At step  90  and at epoch =  23  the loss is =  0.10454768687486649  and accuracy is =  0.9134\n",
            "At step  90  and at epoch =  24  the loss is =  0.1038450300693512  and accuracy is =  0.9274\n",
            "At step  90  and at epoch =  25  the loss is =  0.10367569327354431  and accuracy is =  0.9394\n",
            "At step  90  and at epoch =  26  the loss is =  0.1039859727025032  and accuracy is =  0.9434\n",
            "At step  90  and at epoch =  27  the loss is =  0.10452030599117279  and accuracy is =  0.953\n",
            "At step  90  and at epoch =  28  the loss is =  0.1061519980430603  and accuracy is =  0.959\n",
            "At step  90  and at epoch =  29  the loss is =  0.10494013875722885  and accuracy is =  0.9676\n",
            "At step  90  and at epoch =  30  the loss is =  0.10550504177808762  and accuracy is =  0.9708\n",
            "At step  90  and at epoch =  31  the loss is =  0.10508053749799728  and accuracy is =  0.9734\n",
            "At step  90  and at epoch =  32  the loss is =  0.10599406808614731  and accuracy is =  0.9794\n",
            "At step  90  and at epoch =  33  the loss is =  0.10420119762420654  and accuracy is =  0.9834\n",
            "At step  90  and at epoch =  34  the loss is =  0.10397204756736755  and accuracy is =  0.9858\n",
            "At step  90  and at epoch =  35  the loss is =  0.10268207639455795  and accuracy is =  0.9878\n",
            "At step  90  and at epoch =  36  the loss is =  0.10349182784557343  and accuracy is =  0.9894\n",
            "At step  90  and at epoch =  37  the loss is =  0.10406753420829773  and accuracy is =  0.9938\n",
            "At step  90  and at epoch =  38  the loss is =  0.10589942336082458  and accuracy is =  0.9938\n",
            "At step  90  and at epoch =  39  the loss is =  0.10264009237289429  and accuracy is =  0.996\n",
            "At step  90  and at epoch =  40  the loss is =  0.10161635279655457  and accuracy is =  0.9952\n",
            "At step  90  and at epoch =  41  the loss is =  0.10221726447343826  and accuracy is =  0.997\n",
            "At step  90  and at epoch =  42  the loss is =  0.10247932374477386  and accuracy is =  0.9964\n",
            "At step  90  and at epoch =  43  the loss is =  0.10209489613771439  and accuracy is =  0.9982\n",
            "At step  90  and at epoch =  44  the loss is =  0.10137641429901123  and accuracy is =  0.9982\n",
            "At step  90  and at epoch =  45  the loss is =  0.10148627310991287  and accuracy is =  0.9988\n",
            "At step  90  and at epoch =  46  the loss is =  0.10110259056091309  and accuracy is =  0.998\n",
            "At step  90  and at epoch =  47  the loss is =  0.10081741213798523  and accuracy is =  0.999\n",
            "At step  90  and at epoch =  48  the loss is =  0.10381589829921722  and accuracy is =  0.9992\n",
            "At step  90  and at epoch =  49  the loss is =  0.0997006893157959  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  50  the loss is =  0.09916967153549194  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  51  the loss is =  0.09899862110614777  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  52  the loss is =  0.09893075376749039  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  53  the loss is =  0.09889756888151169  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  54  the loss is =  0.09887536615133286  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  55  the loss is =  0.0988583043217659  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  56  the loss is =  0.0988430380821228  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  57  the loss is =  0.09882892668247223  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  58  the loss is =  0.09881572425365448  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  59  the loss is =  0.09880304336547852  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  60  the loss is =  0.09879079461097717  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  61  the loss is =  0.09877894073724747  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  62  the loss is =  0.0987449437379837  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  63  the loss is =  0.09874705225229263  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  64  the loss is =  0.09874658286571503  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  65  the loss is =  0.09874530881643295  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  66  the loss is =  0.09874368458986282  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  67  the loss is =  0.09874188899993896  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  68  the loss is =  0.09874001890420914  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  69  the loss is =  0.09873808920383453  and accuracy is =  0.9998\n",
            "[49 97 53  5 33 65 62 51 38 61 55 59  6 35 74 71 57 41 70 48 64 69  7 37\n",
            " 84 81 67 44 80 56 75 79  8 40 94 91 77 87 76 98 90 28 82 93 30  2 20 42\n",
            " 39 29 34 96 43  3 22 54 52 36 25 50 58 63  4 24 83 78 60 31 73 17 92 21\n",
            " 86 23  1 15 32 27 95 16 46 47 66 12 19 10 26 72 11  9 18 89  0 68 14 13\n",
            " 45 99 88 85]\n",
            "Validation Loss: 0.12499269098043442 Validation Accuracy : 0.1285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIn7zSiOIxkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "b2be877f-ca22-4e4e-edf8-00f8822d5a96"
      },
      "source": [
        "train_loader.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-845fa6b79289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'shape'"
          ]
        }
      ]
    }
  ]
}