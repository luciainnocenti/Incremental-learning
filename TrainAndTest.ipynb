{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainAndTest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ba23d98d3078420895a77b0b847526f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb9ad41d2a6f44d9bd5624c00c259182",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d232d8c8d4fd4cf4960810b984ea6c91",
              "IPY_MODEL_2631fb85e9b54ac48244743e55000f6f"
            ]
          }
        },
        "fb9ad41d2a6f44d9bd5624c00c259182": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d232d8c8d4fd4cf4960810b984ea6c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0f7f00bc596d4b3f9ae3539dfa0deb00",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7cb4462448d34712ac8753b40a0b5907"
          }
        },
        "2631fb85e9b54ac48244743e55000f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b67cdfa59ada40abb6106abb526d3e0e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169009152/? [00:07&lt;00:00, 22837073.71it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9482090998b744e6bd416791fc58d237"
          }
        },
        "0f7f00bc596d4b3f9ae3539dfa0deb00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7cb4462448d34712ac8753b40a0b5907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b67cdfa59ada40abb6106abb526d3e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9482090998b744e6bd416791fc58d237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciainnocenti/IncrementalLearning/blob/Lucia/TrainAndTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbtGDBU3QJaq",
        "colab_type": "text"
      },
      "source": [
        "# Import GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf0TmOM3NdFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import sys\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I0pKIVIM2KC",
        "colab_type": "code",
        "outputId": "986d3df3-3a14-4cd2-e5ae-d8b217952458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "if not os.path.isdir('./DatasetCIFAR'):\n",
        "  !git clone -b Lucia https://github.com/luciainnocenti/IncrementalLearning.git\n",
        "  !mv 'IncrementalLearning' 'DatasetCIFAR'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IncrementalLearning'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 595 (delta 38), reused 0 (delta 0), pack-reused 532\u001b[K\n",
            "Receiving objects: 100% (595/595), 371.99 KiB | 10.05 MiB/s, done.\n",
            "Resolving deltas: 100% (367/367), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLaS2laafBaG",
        "colab_type": "text"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liUP5Kc1DMbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from DatasetCIFAR.data_set import Dataset \n",
        "from DatasetCIFAR import ResNet\n",
        "from DatasetCIFAR import utils\n",
        "from DatasetCIFAR import params\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.nn import functional as F\n",
        "import random\n",
        "random.seed(params.SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_vlqOL7ehLC",
        "colab_type": "text"
      },
      "source": [
        "# Define Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWttFW3ljoMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resNet = ResNet.resnet32(num_classes=100)\n",
        "resNet = resNet.to(params.DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSmohsyVWFpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet_transformer = transforms.Compose([transforms.Resize(32), \n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_cyhIzFej5-",
        "colab_type": "text"
      },
      "source": [
        "# Define DataSets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcBNohmiYBtP",
        "colab_type": "code",
        "outputId": "139d18ac-c671-41b8-dd51-6e5aad0a7991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "ba23d98d3078420895a77b0b847526f7",
            "fb9ad41d2a6f44d9bd5624c00c259182",
            "d232d8c8d4fd4cf4960810b984ea6c91",
            "2631fb85e9b54ac48244743e55000f6f",
            "0f7f00bc596d4b3f9ae3539dfa0deb00",
            "7cb4462448d34712ac8753b40a0b5907",
            "b67cdfa59ada40abb6106abb526d3e0e",
            "9482090998b744e6bd416791fc58d237"
          ]
        }
      },
      "source": [
        "trainDS = Dataset(train=True, transform = resnet_transformer)\n",
        "testDS = Dataset(train=False, transform = resnet_transformer)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba23d98d3078420895a77b0b847526f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFxMUO_FQZRo",
        "colab_type": "code",
        "outputId": "952428b4-48b1-4e0d-f38d-e17bc6a191ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "train_splits = trainDS.splits\n",
        "test_splits = testDS.splits\n",
        "print(train_splits)\n",
        "print(test_splits)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[73.0, 21.0, 80.0, 29.0, 35.0, 61.0, 83.0, 68.0, 67.0, 23.0], [82.0, 22.0, 90.0, 32.0, 39.0, 66.0, 93.0, 76.0, 75.0, 25.0], [92.0, 24.0, 36.0, 43.0, 74.0, 86.0, 85.0, 27.0, 79.0, 49.0], [26.0, 40.0, 47.0, 88.0, 30.0, 94.0, 54.0, 96.0, 56.0, 45.0], [55.0, 10.0, 60.0, 14.0, 84.0, 87.0, 17.0, 46.0, 62.0, 52.0], [65.0, 11.0, 72.0, 16.0, 20.0, 53.0, 77.0, 63.0, 59.0, 12.0], [95.0, 13.0, 28.0, 34.0, 70.0, 89.0, 81.0, 15.0, 41.0, 91.0], [48.0, 5.0, 51.0, 7.0, 8.0, 38.0, 97.0, 44.0, 42.0, 98.0], [58.0, 33.0, 37.0, 64.0, 19.0, 69.0, 50.0, 78.0, 2.0, 18.0], [31.0, 3.0, 4.0, 71.0, 57.0, 9.0, 1.0, 6.0, 99.0, 0.0]]\n",
            "[[73.0, 21.0, 80.0, 29.0, 35.0, 61.0, 83.0, 68.0, 67.0, 23.0], [82.0, 22.0, 90.0, 32.0, 39.0, 66.0, 93.0, 76.0, 75.0, 25.0], [92.0, 24.0, 36.0, 43.0, 74.0, 86.0, 85.0, 27.0, 79.0, 49.0], [26.0, 40.0, 47.0, 88.0, 30.0, 94.0, 54.0, 96.0, 56.0, 45.0], [55.0, 10.0, 60.0, 14.0, 84.0, 87.0, 17.0, 46.0, 62.0, 52.0], [65.0, 11.0, 72.0, 16.0, 20.0, 53.0, 77.0, 63.0, 59.0, 12.0], [95.0, 13.0, 28.0, 34.0, 70.0, 89.0, 81.0, 15.0, 41.0, 91.0], [48.0, 5.0, 51.0, 7.0, 8.0, 38.0, 97.0, 44.0, 42.0, 98.0], [58.0, 33.0, 37.0, 64.0, 19.0, 69.0, 50.0, 78.0, 2.0, 18.0], [31.0, 3.0, 4.0, 71.0, 57.0, 9.0, 1.0, 6.0, 99.0, 0.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgAT2KQEersx",
        "colab_type": "text"
      },
      "source": [
        "# Useful plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1l7flYj4NJh",
        "colab_type": "text"
      },
      "source": [
        "The function plotEpoch plots, at the end of each task, how accuracy and loss change during the training phase. It show\n",
        "\n",
        "*   Validation and Training Accuracy\n",
        "*   Validation and Training Loss\n",
        "\n",
        "The function plotTask, for each task, how the accuracy on the validation set change when adding new tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr58kkHiIzZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotTask(pars_tasks):\n",
        "  import numpy as np\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  x_tasks =  np.linspace(10, 100, 10)\n",
        "\n",
        "  plt.plot(x_tasks, pars_tasks, label=['Accuracy', 'Loss'])\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.title('Accuracy over tasks')\n",
        "  plt.legend(['Accuracy', 'Loss'])\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iApKvCs942aS",
        "colab_type": "text"
      },
      "source": [
        "# Train and evaluation phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJse4JU7d9ck",
        "colab_type": "code",
        "outputId": "57bfd532-e826-4a23-9a62-08f0af528214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pars_tasks = []\n",
        "test_indexes = []\n",
        "\n",
        "for task in range(0, 100, params.TASK_SIZE):\n",
        "  pars_tasks.insert(task, 0)\n",
        "\n",
        "for task in range(0, 100, params.TASK_SIZE):\n",
        "\n",
        "  train_indexes = trainDS.__getIndexesGroups__(task)\n",
        "  test_indexes = test_indexes + testDS.__getIndexesGroups__(task)\n",
        "\n",
        "  train_dataset = Subset(trainDS, train_indexes)\n",
        "  test_dataset = Subset(testDS, test_indexes)\n",
        "\n",
        "  train_loader = DataLoader( train_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE)\n",
        "  test_loader = DataLoader( test_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE )\n",
        "\n",
        "  if(task == 0):\n",
        "    torch.save(resNet, 'resNet_task{0}.pt'.format(task))\n",
        "  \n",
        "  \n",
        "\n",
        "  utils.trainfunction(task, train_loader, train_splits)\n",
        "  param = utils.evaluationTest(task, test_loader, test_splits)\n",
        "  #pars_tasks[int(task/10)] = param #pars_task[i] = (accuracy, loss) at i-th task\t"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "task = 0 \n",
            "train col =  [73 21 80 29 35 61 83 68 67 23]\n",
            "train col =  [[73 21 80 29 35 61 83 68 67 23]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "At step  0  and at epoch =  0  the loss is =  0.029100513085722923  and accuracy is =  0.245\n",
            "At step  0  and at epoch =  1  the loss is =  0.023476263508200645  and accuracy is =  0.5048\n",
            "At step  0  and at epoch =  2  the loss is =  0.01897246018052101  and accuracy is =  0.5844\n",
            "At step  0  and at epoch =  3  the loss is =  0.012359010986983776  and accuracy is =  0.634\n",
            "At step  0  and at epoch =  4  the loss is =  0.01004356611520052  and accuracy is =  0.6638\n",
            "At step  0  and at epoch =  5  the loss is =  0.007556399330496788  and accuracy is =  0.6954\n",
            "At step  0  and at epoch =  6  the loss is =  0.004670365247875452  and accuracy is =  0.7248\n",
            "At step  0  and at epoch =  7  the loss is =  0.005485564470291138  and accuracy is =  0.7458\n",
            "At step  0  and at epoch =  8  the loss is =  0.004269532393664122  and accuracy is =  0.7448\n",
            "At step  0  and at epoch =  9  the loss is =  0.003003898309543729  and accuracy is =  0.777\n",
            "At step  0  and at epoch =  10  the loss is =  0.00259784166701138  and accuracy is =  0.8\n",
            "At step  0  and at epoch =  11  the loss is =  0.0025202238466590643  and accuracy is =  0.821\n",
            "At step  0  and at epoch =  12  the loss is =  0.0024708923883736134  and accuracy is =  0.825\n",
            "At step  0  and at epoch =  13  the loss is =  0.0034847825299948454  and accuracy is =  0.8368\n",
            "At step  0  and at epoch =  14  the loss is =  0.0032958495430648327  and accuracy is =  0.87\n",
            "At step  0  and at epoch =  15  the loss is =  0.0016474389703944325  and accuracy is =  0.8694\n",
            "At step  0  and at epoch =  16  the loss is =  0.0017690240638330579  and accuracy is =  0.8844\n",
            "At step  0  and at epoch =  17  the loss is =  0.0010107919806614518  and accuracy is =  0.9082\n",
            "At step  0  and at epoch =  18  the loss is =  0.0018913476960733533  and accuracy is =  0.9118\n",
            "At step  0  and at epoch =  19  the loss is =  0.0019967027474194765  and accuracy is =  0.9322\n",
            "At step  0  and at epoch =  20  the loss is =  0.0008784942328929901  and accuracy is =  0.9306\n",
            "At step  0  and at epoch =  21  the loss is =  0.0015161624178290367  and accuracy is =  0.9316\n",
            "At step  0  and at epoch =  22  the loss is =  0.0007650089683011174  and accuracy is =  0.9444\n",
            "At step  0  and at epoch =  23  the loss is =  0.00043624392128549516  and accuracy is =  0.9602\n",
            "At step  0  and at epoch =  24  the loss is =  0.001836207346059382  and accuracy is =  0.9632\n",
            "At step  0  and at epoch =  25  the loss is =  0.0046255639754235744  and accuracy is =  0.9456\n",
            "At step  0  and at epoch =  26  the loss is =  0.0026863941457122564  and accuracy is =  0.9516\n",
            "At step  0  and at epoch =  27  the loss is =  0.0025067105889320374  and accuracy is =  0.9698\n",
            "At step  0  and at epoch =  28  the loss is =  0.0029733488336205482  and accuracy is =  0.963\n",
            "At step  0  and at epoch =  29  the loss is =  0.0005945753073319793  and accuracy is =  0.953\n",
            "At step  0  and at epoch =  30  the loss is =  0.0005216285935603082  and accuracy is =  0.9644\n",
            "At step  0  and at epoch =  31  the loss is =  0.0003413169761188328  and accuracy is =  0.97\n",
            "At step  0  and at epoch =  32  the loss is =  0.00031389525975100696  and accuracy is =  0.9802\n",
            "At step  0  and at epoch =  33  the loss is =  0.0003970907418988645  and accuracy is =  0.9816\n",
            "At step  0  and at epoch =  34  the loss is =  0.0013252233620733023  and accuracy is =  0.9814\n",
            "At step  0  and at epoch =  35  the loss is =  0.0002382919192314148  and accuracy is =  0.984\n",
            "At step  0  and at epoch =  36  the loss is =  0.00017350671987514943  and accuracy is =  0.9896\n",
            "At step  0  and at epoch =  37  the loss is =  0.0002789944119285792  and accuracy is =  0.9908\n",
            "At step  0  and at epoch =  38  the loss is =  0.00021802035917062312  and accuracy is =  0.9938\n",
            "At step  0  and at epoch =  39  the loss is =  0.00019521001377142966  and accuracy is =  0.9976\n",
            "At step  0  and at epoch =  40  the loss is =  0.00020256089919712394  and accuracy is =  0.9996\n",
            "At step  0  and at epoch =  41  the loss is =  0.00011880700913025066  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  42  the loss is =  0.00010367022332502529  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  43  the loss is =  0.00010287254553986713  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  44  the loss is =  0.00010212886991212144  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  45  the loss is =  0.00010202161502093077  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  46  the loss is =  0.00010231263877358288  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  47  the loss is =  0.00010282594303134829  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  48  the loss is =  0.0001024640878313221  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  49  the loss is =  0.000102571451861877  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  50  the loss is =  0.00010269183258060366  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  51  the loss is =  0.000102816047728993  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  52  the loss is =  0.00010295273386873305  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  53  the loss is =  0.00010309120261808857  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  54  the loss is =  0.00010323621972929686  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  55  the loss is =  0.00010339325672248378  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  56  the loss is =  0.0001035538298310712  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  57  the loss is =  0.00010371871030656621  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  58  the loss is =  0.00010388374357717112  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  59  the loss is =  0.00010405083594378084  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  60  the loss is =  0.00010422775085316971  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  61  the loss is =  0.00010439784819027409  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  62  the loss is =  0.00010435000149300322  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  63  the loss is =  0.00010438155004521832  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  64  the loss is =  0.0001044150412781164  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  65  the loss is =  0.00010444763029227033  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  66  the loss is =  0.00010448036482557654  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  67  the loss is =  0.00010451564594404772  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  68  the loss is =  0.0001045516473823227  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  69  the loss is =  0.00010458633187226951  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "104\n",
            "Validation Loss: 0.01645120233297348 Validation Accuracy : 0.75\n",
            "task = 10 \n",
            "train col =  [82 22 90 32 39 66 93 76 75 25]\n",
            "train col =  [[82 22 90 32 39 66 93 76 75 25]]\n",
            "At step  10  and at epoch =  0  the loss is =  0.04734349250793457  and accuracy is =  0.2978\n",
            "At step  10  and at epoch =  1  the loss is =  0.03178897872567177  and accuracy is =  0.5014\n",
            "At step  10  and at epoch =  2  the loss is =  0.023770008236169815  and accuracy is =  0.584\n",
            "At step  10  and at epoch =  3  the loss is =  0.019097937270998955  and accuracy is =  0.6506\n",
            "At step  10  and at epoch =  4  the loss is =  0.014981995336711407  and accuracy is =  0.7328\n",
            "At step  10  and at epoch =  5  the loss is =  0.017365092411637306  and accuracy is =  0.7784\n",
            "At step  10  and at epoch =  6  the loss is =  0.013734545558691025  and accuracy is =  0.7934\n",
            "At step  10  and at epoch =  7  the loss is =  0.010456608608365059  and accuracy is =  0.827\n",
            "At step  10  and at epoch =  8  the loss is =  0.01245991699397564  and accuracy is =  0.8408\n",
            "At step  10  and at epoch =  9  the loss is =  0.010191652923822403  and accuracy is =  0.8622\n",
            "At step  10  and at epoch =  10  the loss is =  0.00916422437876463  and accuracy is =  0.9092\n",
            "At step  10  and at epoch =  11  the loss is =  0.0077645075507462025  and accuracy is =  0.9254\n",
            "At step  10  and at epoch =  12  the loss is =  0.008711344562470913  and accuracy is =  0.934\n",
            "At step  10  and at epoch =  13  the loss is =  0.006715471390634775  and accuracy is =  0.94\n",
            "At step  10  and at epoch =  14  the loss is =  0.006225483492016792  and accuracy is =  0.952\n",
            "At step  10  and at epoch =  15  the loss is =  0.006508035119622946  and accuracy is =  0.9584\n",
            "At step  10  and at epoch =  16  the loss is =  0.006589855998754501  and accuracy is =  0.9654\n",
            "At step  10  and at epoch =  17  the loss is =  0.00643670791760087  and accuracy is =  0.9596\n",
            "At step  10  and at epoch =  18  the loss is =  0.005996753927320242  and accuracy is =  0.9754\n",
            "At step  10  and at epoch =  19  the loss is =  0.0060490453615784645  and accuracy is =  0.9816\n",
            "At step  10  and at epoch =  20  the loss is =  0.0057144141755998135  and accuracy is =  0.9832\n",
            "At step  10  and at epoch =  21  the loss is =  0.0057379500940442085  and accuracy is =  0.985\n",
            "At step  10  and at epoch =  22  the loss is =  0.006550331134349108  and accuracy is =  0.9872\n",
            "At step  10  and at epoch =  23  the loss is =  0.01359475776553154  and accuracy is =  0.9904\n",
            "At step  10  and at epoch =  24  the loss is =  0.00623294385150075  and accuracy is =  0.9864\n",
            "At step  10  and at epoch =  25  the loss is =  0.006882341578602791  and accuracy is =  0.9914\n",
            "At step  10  and at epoch =  26  the loss is =  0.008336110971868038  and accuracy is =  0.9954\n",
            "At step  10  and at epoch =  27  the loss is =  0.019509918987751007  and accuracy is =  0.9956\n",
            "At step  10  and at epoch =  28  the loss is =  0.015148205682635307  and accuracy is =  0.9724\n",
            "At step  10  and at epoch =  29  the loss is =  0.0062172566540539265  and accuracy is =  0.9824\n",
            "At step  10  and at epoch =  30  the loss is =  0.0052393171936273575  and accuracy is =  0.9896\n",
            "At step  10  and at epoch =  31  the loss is =  0.005466884933412075  and accuracy is =  0.9978\n",
            "At step  10  and at epoch =  32  the loss is =  0.005187175236642361  and accuracy is =  0.9996\n",
            "At step  10  and at epoch =  33  the loss is =  0.005208859220147133  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  34  the loss is =  0.005027954466640949  and accuracy is =  0.9998\n",
            "At step  10  and at epoch =  35  the loss is =  0.0052020070143043995  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  36  the loss is =  0.0050408849492669106  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  37  the loss is =  0.004994544666260481  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  38  the loss is =  0.005028971936553717  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  39  the loss is =  0.005155268590897322  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  40  the loss is =  0.005071295890957117  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  41  the loss is =  0.0050172326155006886  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  42  the loss is =  0.00498471362516284  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  43  the loss is =  0.004983669612556696  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  44  the loss is =  0.004950021859258413  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  45  the loss is =  0.0051237791776657104  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  46  the loss is =  0.005343669559806585  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  47  the loss is =  0.0050588129088282585  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  48  the loss is =  0.004962158855050802  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  49  the loss is =  0.004897254519164562  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  50  the loss is =  0.004866580944508314  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  51  the loss is =  0.00484960712492466  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  52  the loss is =  0.004837938584387302  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  53  the loss is =  0.004828831646591425  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  54  the loss is =  0.004821249283850193  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  55  the loss is =  0.0048148068599402905  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  56  the loss is =  0.00480909738689661  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  57  the loss is =  0.004804070107638836  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  58  the loss is =  0.0047995587810873985  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  59  the loss is =  0.004795426968485117  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  60  the loss is =  0.004791613202542067  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  61  the loss is =  0.004788126330822706  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  62  the loss is =  0.00478545343503356  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  63  the loss is =  0.004784518387168646  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  64  the loss is =  0.004783709533512592  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  65  the loss is =  0.0047830077819526196  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  66  the loss is =  0.0047823539935052395  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  67  the loss is =  0.004781705792993307  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  68  the loss is =  0.004781077615916729  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  69  the loss is =  0.004780466668307781  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "80\n",
            "Validation Loss: 0.04221876710653305 Validation Accuracy : 0.507\n",
            "task = 20 \n",
            "train col =  [92 24 36 43 74 86 85 27 79 49]\n",
            "train col =  [[92 24 36 43 74 86 85 27 79 49]]\n",
            "At step  20  and at epoch =  0  the loss is =  0.05494540184736252  and accuracy is =  0.4178\n",
            "At step  20  and at epoch =  1  the loss is =  0.04747362062335014  and accuracy is =  0.6046\n",
            "At step  20  and at epoch =  2  the loss is =  0.03654325753450394  and accuracy is =  0.6836\n",
            "At step  20  and at epoch =  3  the loss is =  0.03146960213780403  and accuracy is =  0.7368\n",
            "At step  20  and at epoch =  4  the loss is =  0.0317499041557312  and accuracy is =  0.803\n",
            "At step  20  and at epoch =  5  the loss is =  0.03139857202768326  and accuracy is =  0.8474\n",
            "At step  20  and at epoch =  6  the loss is =  0.02707037888467312  and accuracy is =  0.8824\n",
            "At step  20  and at epoch =  7  the loss is =  0.02436905726790428  and accuracy is =  0.9068\n",
            "At step  20  and at epoch =  8  the loss is =  0.024014579132199287  and accuracy is =  0.9134\n",
            "At step  20  and at epoch =  9  the loss is =  0.023753566667437553  and accuracy is =  0.9258\n",
            "At step  20  and at epoch =  10  the loss is =  0.025003015995025635  and accuracy is =  0.936\n",
            "At step  20  and at epoch =  11  the loss is =  0.027003144845366478  and accuracy is =  0.937\n",
            "At step  20  and at epoch =  12  the loss is =  0.027341412380337715  and accuracy is =  0.9502\n",
            "At step  20  and at epoch =  13  the loss is =  0.023493196815252304  and accuracy is =  0.9664\n",
            "At step  20  and at epoch =  14  the loss is =  0.022802552208304405  and accuracy is =  0.9754\n",
            "At step  20  and at epoch =  15  the loss is =  0.02267674170434475  and accuracy is =  0.9812\n",
            "At step  20  and at epoch =  16  the loss is =  0.02247951179742813  and accuracy is =  0.9884\n",
            "At step  20  and at epoch =  17  the loss is =  0.021279659122228622  and accuracy is =  0.989\n",
            "At step  20  and at epoch =  18  the loss is =  0.01953640580177307  and accuracy is =  0.9914\n",
            "At step  20  and at epoch =  19  the loss is =  0.019908856600522995  and accuracy is =  0.9962\n",
            "At step  20  and at epoch =  20  the loss is =  0.0208289735019207  and accuracy is =  0.9952\n",
            "At step  20  and at epoch =  21  the loss is =  0.01989586465060711  and accuracy is =  0.998\n",
            "At step  20  and at epoch =  22  the loss is =  0.01939450390636921  and accuracy is =  0.9996\n",
            "At step  20  and at epoch =  23  the loss is =  0.019815964624285698  and accuracy is =  0.9986\n",
            "At step  20  and at epoch =  24  the loss is =  0.02146201580762863  and accuracy is =  0.9994\n",
            "At step  20  and at epoch =  25  the loss is =  0.019490864127874374  and accuracy is =  0.9998\n",
            "At step  20  and at epoch =  26  the loss is =  0.01998879946768284  and accuracy is =  0.9998\n",
            "At step  20  and at epoch =  27  the loss is =  0.020618125796318054  and accuracy is =  0.9998\n",
            "At step  20  and at epoch =  28  the loss is =  0.019714100286364555  and accuracy is =  0.9982\n",
            "At step  20  and at epoch =  29  the loss is =  0.018495755270123482  and accuracy is =  0.9986\n",
            "At step  20  and at epoch =  30  the loss is =  0.018533047288656235  and accuracy is =  0.9998\n",
            "At step  20  and at epoch =  31  the loss is =  0.01852591149508953  and accuracy is =  0.9996\n",
            "At step  20  and at epoch =  32  the loss is =  0.018976857885718346  and accuracy is =  0.9998\n",
            "At step  20  and at epoch =  33  the loss is =  0.019615206867456436  and accuracy is =  0.9994\n",
            "At step  20  and at epoch =  34  the loss is =  0.019793955609202385  and accuracy is =  0.9996\n",
            "At step  20  and at epoch =  35  the loss is =  0.0181793961673975  and accuracy is =  0.9998\n",
            "At step  20  and at epoch =  36  the loss is =  0.01870720647275448  and accuracy is =  0.9998\n",
            "At step  20  and at epoch =  37  the loss is =  0.018625924363732338  and accuracy is =  0.9994\n",
            "At step  20  and at epoch =  38  the loss is =  0.018740249797701836  and accuracy is =  0.9998\n",
            "At step  20  and at epoch =  39  the loss is =  0.018742019310593605  and accuracy is =  0.9998\n",
            "At step  20  and at epoch =  40  the loss is =  0.018022220581769943  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  41  the loss is =  0.018042754381895065  and accuracy is =  0.9998\n",
            "At step  20  and at epoch =  42  the loss is =  0.018452486023306847  and accuracy is =  0.9998\n",
            "At step  20  and at epoch =  43  the loss is =  0.01818862557411194  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  44  the loss is =  0.018390977755188942  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  45  the loss is =  0.018867598846554756  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  46  the loss is =  0.01869937777519226  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  47  the loss is =  0.018617989495396614  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  48  the loss is =  0.017892854288220406  and accuracy is =  0.9996\n",
            "At step  20  and at epoch =  49  the loss is =  0.017632916569709778  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  50  the loss is =  0.017495209351181984  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  51  the loss is =  0.017421988770365715  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  52  the loss is =  0.01737785153090954  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  53  the loss is =  0.01734805665910244  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  54  the loss is =  0.017327159643173218  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  55  the loss is =  0.017311405390501022  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  56  the loss is =  0.017299233004450798  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  57  the loss is =  0.017289211973547935  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  58  the loss is =  0.01728067360818386  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  59  the loss is =  0.017273107543587685  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  60  the loss is =  0.017266536131501198  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  61  the loss is =  0.017260707914829254  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  62  the loss is =  0.017263654619455338  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  63  the loss is =  0.01726170815527439  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  64  the loss is =  0.01725989393889904  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  65  the loss is =  0.017258495092391968  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  66  the loss is =  0.01725720427930355  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  67  the loss is =  0.017256014049053192  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  68  the loss is =  0.017254890874028206  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  69  the loss is =  0.01725381799042225  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "56\n",
            "Validation Loss: 0.035229962319135666 Validation Accuracy : 0.365\n",
            "task = 30 \n",
            "train col =  [26 40 47 88 30 94 54 96 56 45]\n",
            "train col =  [[26 40 47 88 30 94 54 96 56 45]]\n",
            "At step  30  and at epoch =  0  the loss is =  0.0762668326497078  and accuracy is =  0.4014\n",
            "At step  30  and at epoch =  1  the loss is =  0.05657092109322548  and accuracy is =  0.5812\n",
            "At step  30  and at epoch =  2  the loss is =  0.055412620306015015  and accuracy is =  0.6636\n",
            "At step  30  and at epoch =  3  the loss is =  0.04567764699459076  and accuracy is =  0.7292\n",
            "At step  30  and at epoch =  4  the loss is =  0.0387076735496521  and accuracy is =  0.7982\n",
            "At step  30  and at epoch =  5  the loss is =  0.04649485647678375  and accuracy is =  0.8526\n",
            "At step  30  and at epoch =  6  the loss is =  0.046193283051252365  and accuracy is =  0.8616\n",
            "At step  30  and at epoch =  7  the loss is =  0.038261428475379944  and accuracy is =  0.8782\n",
            "At step  30  and at epoch =  8  the loss is =  0.03945964202284813  and accuracy is =  0.9008\n",
            "At step  30  and at epoch =  9  the loss is =  0.03486381843686104  and accuracy is =  0.9286\n",
            "At step  30  and at epoch =  10  the loss is =  0.03210367634892464  and accuracy is =  0.9458\n",
            "At step  30  and at epoch =  11  the loss is =  0.03174569457769394  and accuracy is =  0.9572\n",
            "At step  30  and at epoch =  12  the loss is =  0.030738510191440582  and accuracy is =  0.9566\n",
            "At step  30  and at epoch =  13  the loss is =  0.030177995562553406  and accuracy is =  0.9662\n",
            "At step  30  and at epoch =  14  the loss is =  0.030513595789670944  and accuracy is =  0.98\n",
            "At step  30  and at epoch =  15  the loss is =  0.030507376417517662  and accuracy is =  0.988\n",
            "At step  30  and at epoch =  16  the loss is =  0.028834804892539978  and accuracy is =  0.991\n",
            "At step  30  and at epoch =  17  the loss is =  0.029543332755565643  and accuracy is =  0.995\n",
            "At step  30  and at epoch =  18  the loss is =  0.031220735982060432  and accuracy is =  0.9962\n",
            "At step  30  and at epoch =  19  the loss is =  0.032055653631687164  and accuracy is =  0.9962\n",
            "At step  30  and at epoch =  20  the loss is =  0.030272576957941055  and accuracy is =  0.998\n",
            "At step  30  and at epoch =  21  the loss is =  0.029711002483963966  and accuracy is =  0.9984\n",
            "At step  30  and at epoch =  22  the loss is =  0.02877289056777954  and accuracy is =  0.9996\n",
            "At step  30  and at epoch =  23  the loss is =  0.028137875720858574  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  24  the loss is =  0.02790583297610283  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  25  the loss is =  0.028521956875920296  and accuracy is =  0.9992\n",
            "At step  30  and at epoch =  26  the loss is =  0.02949177473783493  and accuracy is =  0.9984\n",
            "At step  30  and at epoch =  27  the loss is =  0.030770881101489067  and accuracy is =  0.997\n",
            "At step  30  and at epoch =  28  the loss is =  0.030198492109775543  and accuracy is =  0.9948\n",
            "At step  30  and at epoch =  29  the loss is =  0.028803283348679543  and accuracy is =  0.9956\n",
            "At step  30  and at epoch =  30  the loss is =  0.028476547449827194  and accuracy is =  0.999\n",
            "At step  30  and at epoch =  31  the loss is =  0.02838977798819542  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  32  the loss is =  0.029000338166952133  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  33  the loss is =  0.028433913365006447  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  34  the loss is =  0.029116924852132797  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  35  the loss is =  0.028367504477500916  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  36  the loss is =  0.028996700420975685  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  37  the loss is =  0.028752245008945465  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  38  the loss is =  0.027940908446907997  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  39  the loss is =  0.027928577736020088  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  40  the loss is =  0.027641605585813522  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  41  the loss is =  0.02743602730333805  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  42  the loss is =  0.027468537911772728  and accuracy is =  0.9996\n",
            "At step  30  and at epoch =  43  the loss is =  0.027539895847439766  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  44  the loss is =  0.02751091867685318  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  45  the loss is =  0.02767735905945301  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  46  the loss is =  0.028211748227477074  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  47  the loss is =  0.027952145785093307  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  48  the loss is =  0.027246877551078796  and accuracy is =  0.9996\n",
            "At step  30  and at epoch =  49  the loss is =  0.026624156162142754  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  50  the loss is =  0.026518626138567924  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  51  the loss is =  0.02645927295088768  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  52  the loss is =  0.02642004005610943  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  53  the loss is =  0.0263914093375206  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  54  the loss is =  0.026368772611021996  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  55  the loss is =  0.02634933963418007  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  56  the loss is =  0.026332465931773186  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  57  the loss is =  0.026317305862903595  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  58  the loss is =  0.026303565129637718  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  59  the loss is =  0.026291154325008392  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  60  the loss is =  0.02627955935895443  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  61  the loss is =  0.026269011199474335  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  62  the loss is =  0.026204943656921387  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  63  the loss is =  0.026203660294413567  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  64  the loss is =  0.02619851753115654  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  65  the loss is =  0.026194708421826363  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  66  the loss is =  0.0261912252753973  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  67  the loss is =  0.026188120245933533  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  68  the loss is =  0.02618531696498394  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  69  the loss is =  0.02618272788822651  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "32\n",
            "Validation Loss: 0.05871621146798134 Validation Accuracy : 0.3075\n",
            "task = 40 \n",
            "train col =  [55 10 60 14 84 87 17 46 62 52]\n",
            "train col =  [[55 10 60 14 84 87 17 46 62 52]]\n",
            "At step  40  and at epoch =  0  the loss is =  0.07171694934368134  and accuracy is =  0.5292\n",
            "At step  40  and at epoch =  1  the loss is =  0.056989800184965134  and accuracy is =  0.6992\n",
            "At step  40  and at epoch =  2  the loss is =  0.05956529453396797  and accuracy is =  0.7766\n",
            "At step  40  and at epoch =  3  the loss is =  0.05988847464323044  and accuracy is =  0.8326\n",
            "At step  40  and at epoch =  4  the loss is =  0.04890155792236328  and accuracy is =  0.8826\n",
            "At step  40  and at epoch =  5  the loss is =  0.04884972423315048  and accuracy is =  0.9254\n",
            "At step  40  and at epoch =  6  the loss is =  0.04705555737018585  and accuracy is =  0.9402\n",
            "At step  40  and at epoch =  7  the loss is =  0.04314154386520386  and accuracy is =  0.9516\n",
            "At step  40  and at epoch =  8  the loss is =  0.04218553379178047  and accuracy is =  0.9578\n",
            "At step  40  and at epoch =  9  the loss is =  0.04096100851893425  and accuracy is =  0.971\n",
            "At step  40  and at epoch =  10  the loss is =  0.039966609328985214  and accuracy is =  0.9772\n",
            "At step  40  and at epoch =  11  the loss is =  0.04081234708428383  and accuracy is =  0.9832\n",
            "At step  40  and at epoch =  12  the loss is =  0.03937675803899765  and accuracy is =  0.985\n",
            "At step  40  and at epoch =  13  the loss is =  0.038401760160923004  and accuracy is =  0.992\n",
            "At step  40  and at epoch =  14  the loss is =  0.038224849849939346  and accuracy is =  0.9964\n",
            "At step  40  and at epoch =  15  the loss is =  0.03910249099135399  and accuracy is =  0.9976\n",
            "At step  40  and at epoch =  16  the loss is =  0.04101274907588959  and accuracy is =  0.9986\n",
            "At step  40  and at epoch =  17  the loss is =  0.04081369936466217  and accuracy is =  0.9994\n",
            "At step  40  and at epoch =  18  the loss is =  0.040998343378305435  and accuracy is =  0.999\n",
            "At step  40  and at epoch =  19  the loss is =  0.0404093936085701  and accuracy is =  0.9994\n",
            "At step  40  and at epoch =  20  the loss is =  0.03794533759355545  and accuracy is =  0.9996\n",
            "At step  40  and at epoch =  21  the loss is =  0.037318840622901917  and accuracy is =  0.9996\n",
            "At step  40  and at epoch =  22  the loss is =  0.03707161918282509  and accuracy is =  0.9994\n",
            "At step  40  and at epoch =  23  the loss is =  0.03733528032898903  and accuracy is =  0.999\n",
            "At step  40  and at epoch =  24  the loss is =  0.03846430033445358  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  25  the loss is =  0.03845610469579697  and accuracy is =  0.9998\n",
            "At step  40  and at epoch =  26  the loss is =  0.03888357803225517  and accuracy is =  0.9998\n",
            "At step  40  and at epoch =  27  the loss is =  0.03822280466556549  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  28  the loss is =  0.03833963721990585  and accuracy is =  0.9996\n",
            "At step  40  and at epoch =  29  the loss is =  0.03805918991565704  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  30  the loss is =  0.03866692632436752  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  31  the loss is =  0.037263091653585434  and accuracy is =  0.9996\n",
            "At step  40  and at epoch =  32  the loss is =  0.03710237517952919  and accuracy is =  0.9994\n",
            "At step  40  and at epoch =  33  the loss is =  0.03704981133341789  and accuracy is =  0.9994\n",
            "At step  40  and at epoch =  34  the loss is =  0.03819945082068443  and accuracy is =  0.9998\n",
            "At step  40  and at epoch =  35  the loss is =  0.03706346079707146  and accuracy is =  0.9998\n",
            "At step  40  and at epoch =  36  the loss is =  0.037569306790828705  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  37  the loss is =  0.037525299936532974  and accuracy is =  0.9994\n",
            "At step  40  and at epoch =  38  the loss is =  0.03800481930375099  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  39  the loss is =  0.037899818271398544  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  40  the loss is =  0.03738102316856384  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  41  the loss is =  0.03666362166404724  and accuracy is =  0.9998\n",
            "At step  40  and at epoch =  42  the loss is =  0.037235476076602936  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  43  the loss is =  0.037145402282476425  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  44  the loss is =  0.03744334354996681  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  45  the loss is =  0.037816371768713  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  46  the loss is =  0.03794897720217705  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  47  the loss is =  0.03692185878753662  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  48  the loss is =  0.036324962973594666  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  49  the loss is =  0.035909418016672134  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  50  the loss is =  0.03572776913642883  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  51  the loss is =  0.03563232719898224  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  52  the loss is =  0.03557368740439415  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  53  the loss is =  0.035535309463739395  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  54  the loss is =  0.035508088767528534  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  55  the loss is =  0.035486798733472824  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  56  the loss is =  0.035469572991132736  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  57  the loss is =  0.03545480966567993  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  58  the loss is =  0.03544185683131218  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  59  the loss is =  0.035430457442998886  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  60  the loss is =  0.03542051091790199  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  61  the loss is =  0.035411495715379715  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  62  the loss is =  0.03544098138809204  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  63  the loss is =  0.035417333245277405  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  64  the loss is =  0.03540928661823273  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  65  the loss is =  0.03540326654911041  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  66  the loss is =  0.0353986993432045  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  67  the loss is =  0.035395022481679916  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  68  the loss is =  0.03539196774363518  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  69  the loss is =  0.03538932278752327  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "8\n",
            "Validation Loss: 0.0581618957221508 Validation Accuracy : 0.2678\n",
            "task = 50 \n",
            "train col =  [65 11 72 16 20 53 77 63 59 12]\n",
            "train col =  [[65 11 72 16 20 53 77 63 59 12]]\n",
            "At step  50  and at epoch =  0  the loss is =  0.08619724214076996  and accuracy is =  0.4504\n",
            "At step  50  and at epoch =  1  the loss is =  0.07593639940023422  and accuracy is =  0.6146\n",
            "At step  50  and at epoch =  2  the loss is =  0.069395050406456  and accuracy is =  0.694\n",
            "At step  50  and at epoch =  3  the loss is =  0.06548336893320084  and accuracy is =  0.7616\n",
            "At step  50  and at epoch =  4  the loss is =  0.06585858017206192  and accuracy is =  0.8164\n",
            "At step  50  and at epoch =  5  the loss is =  0.06158406659960747  and accuracy is =  0.8642\n",
            "At step  50  and at epoch =  6  the loss is =  0.05959552153944969  and accuracy is =  0.8806\n",
            "At step  50  and at epoch =  7  the loss is =  0.06393768638372421  and accuracy is =  0.8972\n",
            "At step  50  and at epoch =  8  the loss is =  0.06784095615148544  and accuracy is =  0.9238\n",
            "At step  50  and at epoch =  9  the loss is =  0.060591332614421844  and accuracy is =  0.9288\n",
            "At step  50  and at epoch =  10  the loss is =  0.0549982525408268  and accuracy is =  0.9648\n",
            "At step  50  and at epoch =  11  the loss is =  0.0542813241481781  and accuracy is =  0.9786\n",
            "At step  50  and at epoch =  12  the loss is =  0.053739745169878006  and accuracy is =  0.9804\n",
            "At step  50  and at epoch =  13  the loss is =  0.055391959846019745  and accuracy is =  0.9822\n",
            "At step  50  and at epoch =  14  the loss is =  0.05412367358803749  and accuracy is =  0.9798\n",
            "At step  50  and at epoch =  15  the loss is =  0.051496729254722595  and accuracy is =  0.9854\n",
            "At step  50  and at epoch =  16  the loss is =  0.05272233858704567  and accuracy is =  0.9926\n",
            "At step  50  and at epoch =  17  the loss is =  0.05546313151717186  and accuracy is =  0.996\n",
            "At step  50  and at epoch =  18  the loss is =  0.05600050836801529  and accuracy is =  0.997\n",
            "At step  50  and at epoch =  19  the loss is =  0.05149291083216667  and accuracy is =  0.9974\n",
            "At step  50  and at epoch =  20  the loss is =  0.05036931484937668  and accuracy is =  0.9996\n",
            "At step  50  and at epoch =  21  the loss is =  0.05031674727797508  and accuracy is =  0.9998\n",
            "At step  50  and at epoch =  22  the loss is =  0.04956060275435448  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  23  the loss is =  0.04954437166452408  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  24  the loss is =  0.04976366460323334  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  25  the loss is =  0.05014951527118683  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  26  the loss is =  0.051151227205991745  and accuracy is =  0.9994\n",
            "At step  50  and at epoch =  27  the loss is =  0.05055931955575943  and accuracy is =  0.9998\n",
            "At step  50  and at epoch =  28  the loss is =  0.04986388981342316  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  29  the loss is =  0.049957700073719025  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  30  the loss is =  0.04903491213917732  and accuracy is =  0.9998\n",
            "At step  50  and at epoch =  31  the loss is =  0.04936767369508743  and accuracy is =  0.9992\n",
            "At step  50  and at epoch =  32  the loss is =  0.051108263432979584  and accuracy is =  0.999\n",
            "At step  50  and at epoch =  33  the loss is =  0.05052550137042999  and accuracy is =  0.9992\n",
            "At step  50  and at epoch =  34  the loss is =  0.05029350146651268  and accuracy is =  0.999\n",
            "At step  50  and at epoch =  35  the loss is =  0.05041540414094925  and accuracy is =  0.9996\n",
            "At step  50  and at epoch =  36  the loss is =  0.05020919814705849  and accuracy is =  0.9994\n",
            "At step  50  and at epoch =  37  the loss is =  0.049657925963401794  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  38  the loss is =  0.04948544502258301  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  39  the loss is =  0.04954465851187706  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  40  the loss is =  0.04944552481174469  and accuracy is =  0.9998\n",
            "At step  50  and at epoch =  41  the loss is =  0.04986586421728134  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  42  the loss is =  0.050654955208301544  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  43  the loss is =  0.051261477172374725  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  44  the loss is =  0.05021412670612335  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  45  the loss is =  0.04961693659424782  and accuracy is =  0.9998\n",
            "At step  50  and at epoch =  46  the loss is =  0.04908888787031174  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  47  the loss is =  0.04894110932946205  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  48  the loss is =  0.048720527440309525  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  49  the loss is =  0.0482315719127655  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  50  the loss is =  0.04813838750123978  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  51  the loss is =  0.04807205870747566  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  52  the loss is =  0.0480315275490284  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  53  the loss is =  0.04800163581967354  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  54  the loss is =  0.0479782372713089  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  55  the loss is =  0.04795978590846062  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  56  the loss is =  0.047944266349077225  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  57  the loss is =  0.04793044924736023  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  58  the loss is =  0.04791822284460068  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  59  the loss is =  0.04790731146931648  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  60  the loss is =  0.04789729788899422  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  61  the loss is =  0.047888077795505524  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  62  the loss is =  0.0478532575070858  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  63  the loss is =  0.04784788936376572  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  64  the loss is =  0.04784419760107994  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  65  the loss is =  0.04784151911735535  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  66  the loss is =  0.047839220613241196  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  67  the loss is =  0.047837160527706146  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  68  the loss is =  0.04783529043197632  and accuracy is =  1.0\n",
            "At step  50  and at epoch =  69  the loss is =  0.04783355072140694  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "112\n",
            "Validation Loss: 0.06960893422365189 Validation Accuracy : 0.2135\n",
            "task = 60 \n",
            "train col =  [95 13 28 34 70 89 81 15 41 91]\n",
            "train col =  [[95 13 28 34 70 89 81 15 41 91]]\n",
            "At step  60  and at epoch =  0  the loss is =  0.1249428540468216  and accuracy is =  0.4456\n",
            "At step  60  and at epoch =  1  the loss is =  0.11277767270803452  and accuracy is =  0.6178\n",
            "At step  60  and at epoch =  2  the loss is =  0.0937504917383194  and accuracy is =  0.6914\n",
            "At step  60  and at epoch =  3  the loss is =  0.08143705129623413  and accuracy is =  0.7614\n",
            "At step  60  and at epoch =  4  the loss is =  0.07787993550300598  and accuracy is =  0.8292\n",
            "At step  60  and at epoch =  5  the loss is =  0.08426463603973389  and accuracy is =  0.891\n",
            "At step  60  and at epoch =  6  the loss is =  0.08547160774469376  and accuracy is =  0.9126\n",
            "At step  60  and at epoch =  7  the loss is =  0.07783029228448868  and accuracy is =  0.931\n",
            "At step  60  and at epoch =  8  the loss is =  0.07350264489650726  and accuracy is =  0.9468\n",
            "At step  60  and at epoch =  9  the loss is =  0.06976533681154251  and accuracy is =  0.964\n",
            "At step  60  and at epoch =  10  the loss is =  0.06875627487897873  and accuracy is =  0.9792\n",
            "At step  60  and at epoch =  11  the loss is =  0.067914679646492  and accuracy is =  0.9874\n",
            "At step  60  and at epoch =  12  the loss is =  0.06701366603374481  and accuracy is =  0.9914\n",
            "At step  60  and at epoch =  13  the loss is =  0.06507259607315063  and accuracy is =  0.9922\n",
            "At step  60  and at epoch =  14  the loss is =  0.06440287083387375  and accuracy is =  0.9952\n",
            "At step  60  and at epoch =  15  the loss is =  0.06423815339803696  and accuracy is =  0.9972\n",
            "At step  60  and at epoch =  16  the loss is =  0.06462108343839645  and accuracy is =  0.9988\n",
            "At step  60  and at epoch =  17  the loss is =  0.0653640404343605  and accuracy is =  0.9994\n",
            "At step  60  and at epoch =  18  the loss is =  0.06606055051088333  and accuracy is =  0.9998\n",
            "At step  60  and at epoch =  19  the loss is =  0.06659486144781113  and accuracy is =  0.9996\n",
            "At step  60  and at epoch =  20  the loss is =  0.06430656462907791  and accuracy is =  0.9992\n",
            "At step  60  and at epoch =  21  the loss is =  0.06452678143978119  and accuracy is =  0.999\n",
            "At step  60  and at epoch =  22  the loss is =  0.06370358169078827  and accuracy is =  0.9982\n",
            "At step  60  and at epoch =  23  the loss is =  0.06328708678483963  and accuracy is =  0.9992\n",
            "At step  60  and at epoch =  24  the loss is =  0.06356815993785858  and accuracy is =  0.9996\n",
            "At step  60  and at epoch =  25  the loss is =  0.06431086361408234  and accuracy is =  0.9996\n",
            "At step  60  and at epoch =  26  the loss is =  0.0636679008603096  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  27  the loss is =  0.0638417899608612  and accuracy is =  0.9996\n",
            "At step  60  and at epoch =  28  the loss is =  0.06337431818246841  and accuracy is =  0.9998\n",
            "At step  60  and at epoch =  29  the loss is =  0.06347931921482086  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  30  the loss is =  0.06349169462919235  and accuracy is =  0.9996\n",
            "At step  60  and at epoch =  31  the loss is =  0.06361612677574158  and accuracy is =  0.9998\n",
            "At step  60  and at epoch =  32  the loss is =  0.06343600898981094  and accuracy is =  0.9998\n",
            "At step  60  and at epoch =  33  the loss is =  0.0633876621723175  and accuracy is =  0.9996\n",
            "At step  60  and at epoch =  34  the loss is =  0.06295478343963623  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  35  the loss is =  0.06331291049718857  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  36  the loss is =  0.06305014342069626  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  37  the loss is =  0.06279025226831436  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  38  the loss is =  0.06262700259685516  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  39  the loss is =  0.06274079531431198  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  40  the loss is =  0.06266532838344574  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  41  the loss is =  0.062368668615818024  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  42  the loss is =  0.06242167204618454  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  43  the loss is =  0.06269485503435135  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  44  the loss is =  0.06276694685220718  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  45  the loss is =  0.06262819468975067  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  46  the loss is =  0.06264321506023407  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  47  the loss is =  0.06242075189948082  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  48  the loss is =  0.06217051297426224  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  49  the loss is =  0.06185978651046753  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  50  the loss is =  0.06174920126795769  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  51  the loss is =  0.06168871745467186  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  52  the loss is =  0.061648305505514145  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  53  the loss is =  0.06161642074584961  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  54  the loss is =  0.061589889228343964  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  55  the loss is =  0.061566904187202454  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  56  the loss is =  0.06154697388410568  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  57  the loss is =  0.06152956187725067  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  58  the loss is =  0.061513833701610565  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  59  the loss is =  0.061499547213315964  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  60  the loss is =  0.061486635357141495  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  61  the loss is =  0.061474528163671494  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  62  the loss is =  0.06140374019742012  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  63  the loss is =  0.06140196695923805  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  64  the loss is =  0.06139827519655228  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  65  the loss is =  0.06139535829424858  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  66  the loss is =  0.06139282509684563  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  67  the loss is =  0.061390530318021774  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  68  the loss is =  0.06138838455080986  and accuracy is =  1.0\n",
            "At step  60  and at epoch =  69  the loss is =  0.061386384069919586  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "88\n",
            "Validation Loss: 0.06165194511413574 Validation Accuracy : 0.20142857142857143\n",
            "task = 70 \n",
            "train col =  [48  5 51  7  8 38 97 44 42 98]\n",
            "train col =  [[48  5 51  7  8 38 97 44 42 98]]\n",
            "At step  70  and at epoch =  0  the loss is =  0.11942975968122482  and accuracy is =  0.3936\n",
            "At step  70  and at epoch =  1  the loss is =  0.12337685376405716  and accuracy is =  0.5396\n",
            "At step  70  and at epoch =  2  the loss is =  0.10152354836463928  and accuracy is =  0.642\n",
            "At step  70  and at epoch =  3  the loss is =  0.09665588289499283  and accuracy is =  0.7382\n",
            "At step  70  and at epoch =  4  the loss is =  0.09532209485769272  and accuracy is =  0.8198\n",
            "At step  70  and at epoch =  5  the loss is =  0.08986391127109528  and accuracy is =  0.8808\n",
            "At step  70  and at epoch =  6  the loss is =  0.08968351036310196  and accuracy is =  0.8972\n",
            "At step  70  and at epoch =  7  the loss is =  0.08546492457389832  and accuracy is =  0.9236\n",
            "At step  70  and at epoch =  8  the loss is =  0.08907540887594223  and accuracy is =  0.938\n",
            "At step  70  and at epoch =  9  the loss is =  0.09285665303468704  and accuracy is =  0.9484\n",
            "At step  70  and at epoch =  10  the loss is =  0.09277251362800598  and accuracy is =  0.9456\n",
            "At step  70  and at epoch =  11  the loss is =  0.08766362816095352  and accuracy is =  0.9668\n",
            "At step  70  and at epoch =  12  the loss is =  0.0829426720738411  and accuracy is =  0.9774\n",
            "At step  70  and at epoch =  13  the loss is =  0.08214542269706726  and accuracy is =  0.9888\n",
            "At step  70  and at epoch =  14  the loss is =  0.08198853582143784  and accuracy is =  0.9944\n",
            "At step  70  and at epoch =  15  the loss is =  0.08046811819076538  and accuracy is =  0.9974\n",
            "At step  70  and at epoch =  16  the loss is =  0.08100831508636475  and accuracy is =  0.998\n",
            "At step  70  and at epoch =  17  the loss is =  0.08008735626935959  and accuracy is =  0.9988\n",
            "At step  70  and at epoch =  18  the loss is =  0.0807797759771347  and accuracy is =  0.9996\n",
            "At step  70  and at epoch =  19  the loss is =  0.08007043600082397  and accuracy is =  0.9994\n",
            "At step  70  and at epoch =  20  the loss is =  0.07997629046440125  and accuracy is =  0.9996\n",
            "At step  70  and at epoch =  21  the loss is =  0.07885676622390747  and accuracy is =  0.9994\n",
            "At step  70  and at epoch =  22  the loss is =  0.07931078970432281  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  23  the loss is =  0.0783880203962326  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  24  the loss is =  0.07815869152545929  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  25  the loss is =  0.07858719676733017  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  26  the loss is =  0.07860513776540756  and accuracy is =  0.9994\n",
            "At step  70  and at epoch =  27  the loss is =  0.0777188390493393  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  28  the loss is =  0.07775891572237015  and accuracy is =  0.9996\n",
            "At step  70  and at epoch =  29  the loss is =  0.0787292942404747  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  30  the loss is =  0.07949716597795486  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  31  the loss is =  0.07929356396198273  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  32  the loss is =  0.07839983701705933  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  33  the loss is =  0.07928407192230225  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  34  the loss is =  0.07772880047559738  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  35  the loss is =  0.07953110337257385  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  36  the loss is =  0.07991896569728851  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  37  the loss is =  0.07995213568210602  and accuracy is =  0.9996\n",
            "At step  70  and at epoch =  38  the loss is =  0.07899734377861023  and accuracy is =  0.9992\n",
            "At step  70  and at epoch =  39  the loss is =  0.07882136106491089  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  40  the loss is =  0.07902797311544418  and accuracy is =  0.9984\n",
            "At step  70  and at epoch =  41  the loss is =  0.07932242751121521  and accuracy is =  0.9978\n",
            "At step  70  and at epoch =  42  the loss is =  0.0774698555469513  and accuracy is =  0.9986\n",
            "At step  70  and at epoch =  43  the loss is =  0.07719624787569046  and accuracy is =  0.9974\n",
            "At step  70  and at epoch =  44  the loss is =  0.07784080505371094  and accuracy is =  0.9998\n",
            "At step  70  and at epoch =  45  the loss is =  0.0789051428437233  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  46  the loss is =  0.0786704272031784  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  47  the loss is =  0.07848059386014938  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  48  the loss is =  0.07733643054962158  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  49  the loss is =  0.07658522576093674  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  50  the loss is =  0.07625263184309006  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  51  the loss is =  0.07606719434261322  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  52  the loss is =  0.07595305144786835  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  53  the loss is =  0.0758795291185379  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  54  the loss is =  0.07582827657461166  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  55  the loss is =  0.07578949630260468  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  56  the loss is =  0.0757586881518364  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  57  the loss is =  0.0757327526807785  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  58  the loss is =  0.07571075856685638  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  59  the loss is =  0.07569155842065811  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  60  the loss is =  0.07567431032657623  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  61  the loss is =  0.07565903663635254  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  62  the loss is =  0.07579980790615082  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  63  the loss is =  0.07577335834503174  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  64  the loss is =  0.07576358318328857  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  65  the loss is =  0.07575664669275284  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  66  the loss is =  0.07575052231550217  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  67  the loss is =  0.07574523985385895  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  68  the loss is =  0.07574048638343811  and accuracy is =  1.0\n",
            "At step  70  and at epoch =  69  the loss is =  0.0757361426949501  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "64\n",
            "Validation Loss: 0.07523085922002792 Validation Accuracy : 0.17375\n",
            "task = 80 \n",
            "train col =  [58 33 37 64 19 69 50 78  2 18]\n",
            "train col =  [[58 33 37 64 19 69 50 78  2 18]]\n",
            "At step  80  and at epoch =  0  the loss is =  0.1345270574092865  and accuracy is =  0.4112\n",
            "At step  80  and at epoch =  1  the loss is =  0.1362759917974472  and accuracy is =  0.5872\n",
            "At step  80  and at epoch =  2  the loss is =  0.1132519319653511  and accuracy is =  0.6664\n",
            "At step  80  and at epoch =  3  the loss is =  0.10907651484012604  and accuracy is =  0.7372\n",
            "At step  80  and at epoch =  4  the loss is =  0.10548821836709976  and accuracy is =  0.8146\n",
            "At step  80  and at epoch =  5  the loss is =  0.10622157901525497  and accuracy is =  0.8716\n",
            "At step  80  and at epoch =  6  the loss is =  0.10256176441907883  and accuracy is =  0.9062\n",
            "At step  80  and at epoch =  7  the loss is =  0.10026363283395767  and accuracy is =  0.9118\n",
            "At step  80  and at epoch =  8  the loss is =  0.10214336216449738  and accuracy is =  0.9192\n",
            "At step  80  and at epoch =  9  the loss is =  0.0996311753988266  and accuracy is =  0.9388\n",
            "At step  80  and at epoch =  10  the loss is =  0.10377953946590424  and accuracy is =  0.9514\n",
            "At step  80  and at epoch =  11  the loss is =  0.10032732784748077  and accuracy is =  0.9704\n",
            "At step  80  and at epoch =  12  the loss is =  0.10215825587511063  and accuracy is =  0.9776\n",
            "At step  80  and at epoch =  13  the loss is =  0.09827999770641327  and accuracy is =  0.9838\n",
            "At step  80  and at epoch =  14  the loss is =  0.09701505303382874  and accuracy is =  0.9894\n",
            "At step  80  and at epoch =  15  the loss is =  0.0970265343785286  and accuracy is =  0.997\n",
            "At step  80  and at epoch =  16  the loss is =  0.09674566239118576  and accuracy is =  0.9996\n",
            "At step  80  and at epoch =  17  the loss is =  0.09631047397851944  and accuracy is =  0.9988\n",
            "At step  80  and at epoch =  18  the loss is =  0.09594635665416718  and accuracy is =  0.9998\n",
            "At step  80  and at epoch =  19  the loss is =  0.09712779521942139  and accuracy is =  0.9998\n",
            "At step  80  and at epoch =  20  the loss is =  0.09998100250959396  and accuracy is =  0.9998\n",
            "At step  80  and at epoch =  21  the loss is =  0.09645610302686691  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  22  the loss is =  0.09620849043130875  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  23  the loss is =  0.09573464840650558  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  24  the loss is =  0.09504757076501846  and accuracy is =  0.9994\n",
            "At step  80  and at epoch =  25  the loss is =  0.09469817578792572  and accuracy is =  0.9994\n",
            "At step  80  and at epoch =  26  the loss is =  0.09536491334438324  and accuracy is =  0.9994\n",
            "At step  80  and at epoch =  27  the loss is =  0.09523963928222656  and accuracy is =  0.999\n",
            "At step  80  and at epoch =  28  the loss is =  0.09534952044487  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  29  the loss is =  0.09572060406208038  and accuracy is =  0.9996\n",
            "At step  80  and at epoch =  30  the loss is =  0.09583180397748947  and accuracy is =  0.9998\n",
            "At step  80  and at epoch =  31  the loss is =  0.09615373611450195  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  32  the loss is =  0.09588713198900223  and accuracy is =  0.9998\n",
            "At step  80  and at epoch =  33  the loss is =  0.09545160830020905  and accuracy is =  0.9998\n",
            "At step  80  and at epoch =  34  the loss is =  0.09487301856279373  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  35  the loss is =  0.09516942501068115  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  36  the loss is =  0.095114566385746  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  37  the loss is =  0.09398447722196579  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  38  the loss is =  0.09307612478733063  and accuracy is =  0.9998\n",
            "At step  80  and at epoch =  39  the loss is =  0.09328887611627579  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  40  the loss is =  0.09354351460933685  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  41  the loss is =  0.09505552053451538  and accuracy is =  0.9998\n",
            "At step  80  and at epoch =  42  the loss is =  0.09456408023834229  and accuracy is =  0.9982\n",
            "At step  80  and at epoch =  43  the loss is =  0.09479887783527374  and accuracy is =  0.9984\n",
            "At step  80  and at epoch =  44  the loss is =  0.09354766458272934  and accuracy is =  0.9902\n",
            "At step  80  and at epoch =  45  the loss is =  0.09435443580150604  and accuracy is =  0.9784\n",
            "At step  80  and at epoch =  46  the loss is =  0.09645960479974747  and accuracy is =  0.973\n",
            "At step  80  and at epoch =  47  the loss is =  0.0973309800028801  and accuracy is =  0.9752\n",
            "At step  80  and at epoch =  48  the loss is =  0.09367553144693375  and accuracy is =  0.993\n",
            "At step  80  and at epoch =  49  the loss is =  0.0930727943778038  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  50  the loss is =  0.0927719697356224  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  51  the loss is =  0.09262388944625854  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  52  the loss is =  0.09251076728105545  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  53  the loss is =  0.09242931753396988  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  54  the loss is =  0.09236083179712296  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  55  the loss is =  0.09230457246303558  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  56  the loss is =  0.09225604683160782  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  57  the loss is =  0.09221305698156357  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  58  the loss is =  0.09217512607574463  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  59  the loss is =  0.09214086085557938  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  60  the loss is =  0.0921097993850708  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  61  the loss is =  0.09208156168460846  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  62  the loss is =  0.09215866774320602  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  63  the loss is =  0.0921093001961708  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  64  the loss is =  0.09209130704402924  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  65  the loss is =  0.09207740426063538  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  66  the loss is =  0.09206575155258179  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  67  the loss is =  0.09205561131238937  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  68  the loss is =  0.09204660356044769  and accuracy is =  1.0\n",
            "At step  80  and at epoch =  69  the loss is =  0.09203826636075974  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "40\n",
            "Validation Loss: 0.06139650195837021 Validation Accuracy : 0.15122222222222223\n",
            "task = 90 \n",
            "train col =  [31  3  4 71 57  9  1  6 99  0]\n",
            "train col =  [[31  3  4 71 57  9  1  6 99  0]]\n",
            "At step  90  and at epoch =  0  the loss is =  0.1633705049753189  and accuracy is =  0.4728\n",
            "At step  90  and at epoch =  1  the loss is =  0.14865145087242126  and accuracy is =  0.645\n",
            "At step  90  and at epoch =  2  the loss is =  0.1324964463710785  and accuracy is =  0.724\n",
            "At step  90  and at epoch =  3  the loss is =  0.12142612040042877  and accuracy is =  0.7872\n",
            "At step  90  and at epoch =  4  the loss is =  0.12036944925785065  and accuracy is =  0.8542\n",
            "At step  90  and at epoch =  5  the loss is =  0.11469419300556183  and accuracy is =  0.9106\n",
            "At step  90  and at epoch =  6  the loss is =  0.11644721031188965  and accuracy is =  0.9506\n",
            "At step  90  and at epoch =  7  the loss is =  0.11666962504386902  and accuracy is =  0.9526\n",
            "At step  90  and at epoch =  8  the loss is =  0.11598340421915054  and accuracy is =  0.9474\n",
            "At step  90  and at epoch =  9  the loss is =  0.1157105416059494  and accuracy is =  0.9648\n",
            "At step  90  and at epoch =  10  the loss is =  0.11129039525985718  and accuracy is =  0.9738\n",
            "At step  90  and at epoch =  11  the loss is =  0.10892657190561295  and accuracy is =  0.9848\n",
            "At step  90  and at epoch =  12  the loss is =  0.10944481939077377  and accuracy is =  0.9866\n",
            "At step  90  and at epoch =  13  the loss is =  0.10759074985980988  and accuracy is =  0.9916\n",
            "At step  90  and at epoch =  14  the loss is =  0.10726574063301086  and accuracy is =  0.9962\n",
            "At step  90  and at epoch =  15  the loss is =  0.10718242079019547  and accuracy is =  0.9974\n",
            "At step  90  and at epoch =  16  the loss is =  0.10905490815639496  and accuracy is =  0.9984\n",
            "At step  90  and at epoch =  17  the loss is =  0.10819404572248459  and accuracy is =  0.9984\n",
            "At step  90  and at epoch =  18  the loss is =  0.10738704353570938  and accuracy is =  0.999\n",
            "At step  90  and at epoch =  19  the loss is =  0.1060803234577179  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  20  the loss is =  0.10597635060548782  and accuracy is =  0.9996\n",
            "At step  90  and at epoch =  21  the loss is =  0.10646575689315796  and accuracy is =  0.9996\n",
            "At step  90  and at epoch =  22  the loss is =  0.10614582151174545  and accuracy is =  0.9992\n",
            "At step  90  and at epoch =  23  the loss is =  0.10535173118114471  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  24  the loss is =  0.10500535368919373  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  25  the loss is =  0.10525136440992355  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  26  the loss is =  0.10541269928216934  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  27  the loss is =  0.10599160939455032  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  28  the loss is =  0.1055249571800232  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  29  the loss is =  0.10551449656486511  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  30  the loss is =  0.10437970608472824  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  31  the loss is =  0.1046474277973175  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  32  the loss is =  0.1045074611902237  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  33  the loss is =  0.10488905757665634  and accuracy is =  0.9996\n",
            "At step  90  and at epoch =  34  the loss is =  0.10442181676626205  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  35  the loss is =  0.10515599697828293  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  36  the loss is =  0.10542996972799301  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  37  the loss is =  0.10529815405607224  and accuracy is =  0.9996\n",
            "At step  90  and at epoch =  38  the loss is =  0.1045181155204773  and accuracy is =  0.9996\n",
            "At step  90  and at epoch =  39  the loss is =  0.10453861206769943  and accuracy is =  0.999\n",
            "At step  90  and at epoch =  40  the loss is =  0.10528101027011871  and accuracy is =  0.9996\n",
            "At step  90  and at epoch =  41  the loss is =  0.10579143464565277  and accuracy is =  0.999\n",
            "At step  90  and at epoch =  42  the loss is =  0.10490643233060837  and accuracy is =  0.999\n",
            "At step  90  and at epoch =  43  the loss is =  0.1043032556772232  and accuracy is =  0.9992\n",
            "At step  90  and at epoch =  44  the loss is =  0.10399476438760757  and accuracy is =  0.9996\n",
            "At step  90  and at epoch =  45  the loss is =  0.10499804466962814  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  46  the loss is =  0.10500522702932358  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  47  the loss is =  0.10491432994604111  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  48  the loss is =  0.10358503460884094  and accuracy is =  0.9998\n",
            "At step  90  and at epoch =  49  the loss is =  0.10308001935482025  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  50  the loss is =  0.10287288576364517  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  51  the loss is =  0.10276072472333908  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  52  the loss is =  0.10268627852201462  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  53  the loss is =  0.10263192653656006  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  54  the loss is =  0.10258934646844864  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  55  the loss is =  0.10255555808544159  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  56  the loss is =  0.10252765566110611  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  57  the loss is =  0.10250326991081238  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  58  the loss is =  0.10248168557882309  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  59  the loss is =  0.10246263444423676  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  60  the loss is =  0.10244493186473846  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  61  the loss is =  0.10242848843336105  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  62  the loss is =  0.10241570323705673  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  63  the loss is =  0.10239604860544205  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  64  the loss is =  0.10238460451364517  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  65  the loss is =  0.10237565636634827  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  66  the loss is =  0.1023678183555603  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  67  the loss is =  0.10236083716154099  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  68  the loss is =  0.10235443711280823  and accuracy is =  1.0\n",
            "At step  90  and at epoch =  69  the loss is =  0.10234849900007248  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "16\n",
            "Validation Loss: 0.0860503539443016 Validation Accuracy : 0.1434\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}