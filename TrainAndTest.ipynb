{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainAndTest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5997758ff54944ecb5ed2f903a583bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_57130a2ae33944668c20a585f0080fec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bc21025f66e3413f8d8bd8798ab2cf03",
              "IPY_MODEL_0add8d88959f4b56a52a09bcbc0a2965"
            ]
          }
        },
        "57130a2ae33944668c20a585f0080fec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc21025f66e3413f8d8bd8798ab2cf03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1f0826090802451b9bbacde43a79af9d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ccccbf3d3e2499baae697c0feb7f3d4"
          }
        },
        "0add8d88959f4b56a52a09bcbc0a2965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6da542fea05e47918854f72194130e11",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169009152/? [00:20&lt;00:00, 33657050.78it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d4b9031d39504d5ba0d79465522f62bf"
          }
        },
        "1f0826090802451b9bbacde43a79af9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ccccbf3d3e2499baae697c0feb7f3d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6da542fea05e47918854f72194130e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d4b9031d39504d5ba0d79465522f62bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciainnocenti/IncrementalLearning/blob/Lucia/TrainAndTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbtGDBU3QJaq",
        "colab_type": "text"
      },
      "source": [
        "# Import GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf0TmOM3NdFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import sys\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I0pKIVIM2KC",
        "colab_type": "code",
        "outputId": "9104947f-d531-4078-e8e0-004b2a95e29f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "if not os.path.isdir('./DatasetCIFAR'):\n",
        "  !git clone -b Lucia https://github.com/luciainnocenti/IncrementalLearning.git\n",
        "  !mv 'IncrementalLearning' 'DatasetCIFAR'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IncrementalLearning'...\n",
            "remote: Enumerating objects: 73, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/73)\u001b[K\rremote: Counting objects:   2% (2/73)\u001b[K\rremote: Counting objects:   4% (3/73)\u001b[K\rremote: Counting objects:   5% (4/73)\u001b[K\rremote: Counting objects:   6% (5/73)\u001b[K\rremote: Counting objects:   8% (6/73)\u001b[K\rremote: Counting objects:   9% (7/73)\u001b[K\rremote: Counting objects:  10% (8/73)\u001b[K\rremote: Counting objects:  12% (9/73)\u001b[K\rremote: Counting objects:  13% (10/73)\u001b[K\rremote: Counting objects:  15% (11/73)\u001b[K\rremote: Counting objects:  16% (12/73)\u001b[K\rremote: Counting objects:  17% (13/73)\u001b[K\rremote: Counting objects:  19% (14/73)\u001b[K\rremote: Counting objects:  20% (15/73)\u001b[K\rremote: Counting objects:  21% (16/73)\u001b[K\rremote: Counting objects:  23% (17/73)\u001b[K\rremote: Counting objects:  24% (18/73)\u001b[K\rremote: Counting objects:  26% (19/73)\u001b[K\rremote: Counting objects:  27% (20/73)\u001b[K\rremote: Counting objects:  28% (21/73)\u001b[K\rremote: Counting objects:  30% (22/73)\u001b[K\rremote: Counting objects:  31% (23/73)\u001b[K\rremote: Counting objects:  32% (24/73)\u001b[K\rremote: Counting objects:  34% (25/73)\u001b[K\rremote: Counting objects:  35% (26/73)\u001b[K\rremote: Counting objects:  36% (27/73)\u001b[K\rremote: Counting objects:  38% (28/73)\u001b[K\rremote: Counting objects:  39% (29/73)\u001b[K\rremote: Counting objects:  41% (30/73)\u001b[K\rremote: Counting objects:  42% (31/73)\u001b[K\rremote: Counting objects:  43% (32/73)\u001b[K\rremote: Counting objects:  45% (33/73)\u001b[K\rremote: Counting objects:  46% (34/73)\u001b[K\rremote: Counting objects:  47% (35/73)\u001b[K\rremote: Counting objects:  49% (36/73)\u001b[K\rremote: Counting objects:  50% (37/73)\u001b[K\rremote: Counting objects:  52% (38/73)\u001b[K\rremote: Counting objects:  53% (39/73)\u001b[K\rremote: Counting objects:  54% (40/73)\u001b[K\rremote: Counting objects:  56% (41/73)\u001b[K\rremote: Counting objects:  57% (42/73)\u001b[K\rremote: Counting objects:  58% (43/73)\u001b[K\rremote: Counting objects:  60% (44/73)\u001b[K\rremote: Counting objects:  61% (45/73)\u001b[K\rremote: Counting objects:  63% (46/73)\u001b[K\rremote: Counting objects:  64% (47/73)\u001b[K\rremote: Counting objects:  65% (48/73)\u001b[K\rremote: Counting objects:  67% (49/73)\u001b[K\rremote: Counting objects:  68% (50/73)\u001b[K\rremote: Counting objects:  69% (51/73)\u001b[K\rremote: Counting objects:  71% (52/73)\u001b[K\rremote: Counting objects:  72% (53/73)\u001b[K\rremote: Counting objects:  73% (54/73)\u001b[K\rremote: Counting objects:  75% (55/73)\u001b[K\rremote: Counting objects:  76% (56/73)\u001b[K\rremote: Counting objects:  78% (57/73)\u001b[K\rremote: Counting objects:  79% (58/73)\u001b[K\rremote: Counting objects:  80% (59/73)\u001b[K\rremote: Counting objects:  82% (60/73)\u001b[K\rremote: Counting objects:  83% (61/73)\u001b[K\rremote: Counting objects:  84% (62/73)\u001b[K\rremote: Counting objects:  86% (63/73)\u001b[K\rremote: Counting objects:  87% (64/73)\u001b[K\rremote: Counting objects:  89% (65/73)\u001b[K\rremote: Counting objects:  90% (66/73)\u001b[K\rremote: Counting objects:  91% (67/73)\u001b[K\rremote: Counting objects:  93% (68/73)\u001b[K\rremote: Counting objects:  94% (69/73)\u001b[K\rremote: Counting objects:  95% (70/73)\u001b[K\rremote: Counting objects:  97% (71/73)\u001b[K\rremote: Counting objects:  98% (72/73)\u001b[K\rremote: Counting objects: 100% (73/73)\u001b[K\rremote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 605 (delta 44), reused 0 (delta 0), pack-reused 532\u001b[K\n",
            "Receiving objects: 100% (605/605), 387.31 KiB | 1.36 MiB/s, done.\n",
            "Resolving deltas: 100% (373/373), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLaS2laafBaG",
        "colab_type": "text"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liUP5Kc1DMbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from DatasetCIFAR.data_set import Dataset \n",
        "from DatasetCIFAR import ResNet\n",
        "from DatasetCIFAR import utils\n",
        "from DatasetCIFAR import params\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.nn import functional as F\n",
        "import random\n",
        "random.seed(params.SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_vlqOL7ehLC",
        "colab_type": "text"
      },
      "source": [
        "# Define Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWttFW3ljoMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resNet = ResNet.resnet32(num_classes=100)\n",
        "resNet = resNet.to(params.DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSmohsyVWFpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet_transformer = transforms.Compose([transforms.Resize(32), \n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_cyhIzFej5-",
        "colab_type": "text"
      },
      "source": [
        "# Define DataSets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcBNohmiYBtP",
        "colab_type": "code",
        "outputId": "6509014d-86a0-4831-afca-606827e2059c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "5997758ff54944ecb5ed2f903a583bf8",
            "57130a2ae33944668c20a585f0080fec",
            "bc21025f66e3413f8d8bd8798ab2cf03",
            "0add8d88959f4b56a52a09bcbc0a2965",
            "1f0826090802451b9bbacde43a79af9d",
            "7ccccbf3d3e2499baae697c0feb7f3d4",
            "6da542fea05e47918854f72194130e11",
            "d4b9031d39504d5ba0d79465522f62bf"
          ]
        }
      },
      "source": [
        "trainDS = Dataset(train=True, transform = resnet_transformer)\n",
        "testDS = Dataset(train=False, transform = resnet_transformer)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5997758ff54944ecb5ed2f903a583bf8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFxMUO_FQZRo",
        "colab_type": "code",
        "outputId": "ac8d63ac-d778-4b14-f5ae-a833797b44b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "train_splits = trainDS.splits\n",
        "test_splits = testDS.splits\n",
        "print(train_splits)\n",
        "print(test_splits)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[60.0, 34.0, 84.0, 67.0, 85.0, 44.0, 18.0, 48.0, 1.0, 47.0], [68.0, 37.0, 94.0, 75.0, 95.0, 50.0, 20.0, 54.0, 2.0, 53.0], [76.0, 40.0, 83.0, 56.0, 22.0, 61.0, 3.0, 59.0, 77.0, 41.0], [88.0, 45.0, 97.0, 64.0, 24.0, 70.0, 4.0, 29.0, 38.0, 23.0], [49.0, 26.0, 72.0, 55.0, 96.0, 32.0, 13.0, 35.0, 0.0, 33.0], [65.0, 30.0, 87.0, 71.0, 93.0, 43.0, 15.0, 51.0, 5.0, 46.0], [80.0, 39.0, 86.0, 62.0, 17.0, 66.0, 6.0, 63.0, 99.0, 16.0], [52.0, 21.0, 78.0, 57.0, 91.0, 28.0, 11.0, 31.0, 7.0, 82.0], [89.0, 12.0, 90.0, 74.0, 8.0, 10.0, 98.0, 9.0, 42.0, 25.0], [58.0, 79.0, 81.0, 69.0, 14.0, 36.0, 73.0, 19.0, 92.0, 27.0]]\n",
            "[[60.0, 34.0, 84.0, 67.0, 85.0, 44.0, 18.0, 48.0, 1.0, 47.0], [68.0, 37.0, 94.0, 75.0, 95.0, 50.0, 20.0, 54.0, 2.0, 53.0], [76.0, 40.0, 83.0, 56.0, 22.0, 61.0, 3.0, 59.0, 77.0, 41.0], [88.0, 45.0, 97.0, 64.0, 24.0, 70.0, 4.0, 29.0, 38.0, 23.0], [49.0, 26.0, 72.0, 55.0, 96.0, 32.0, 13.0, 35.0, 0.0, 33.0], [65.0, 30.0, 87.0, 71.0, 93.0, 43.0, 15.0, 51.0, 5.0, 46.0], [80.0, 39.0, 86.0, 62.0, 17.0, 66.0, 6.0, 63.0, 99.0, 16.0], [52.0, 21.0, 78.0, 57.0, 91.0, 28.0, 11.0, 31.0, 7.0, 82.0], [89.0, 12.0, 90.0, 74.0, 8.0, 10.0, 98.0, 9.0, 42.0, 25.0], [58.0, 79.0, 81.0, 69.0, 14.0, 36.0, 73.0, 19.0, 92.0, 27.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgAT2KQEersx",
        "colab_type": "text"
      },
      "source": [
        "# Useful plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1l7flYj4NJh",
        "colab_type": "text"
      },
      "source": [
        "The function plotEpoch plots, at the end of each task, how accuracy and loss change during the training phase. It show\n",
        "\n",
        "*   Validation and Training Accuracy\n",
        "*   Validation and Training Loss\n",
        "\n",
        "The function plotTask, for each task, how the accuracy on the validation set change when adding new tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr58kkHiIzZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotTask(pars_tasks):\n",
        "  import numpy as np\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  x_tasks =  np.linspace(10, 100, 10)\n",
        "\n",
        "  plt.plot(x_tasks, pars_tasks, label=['Accuracy', 'Loss'])\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.title('Accuracy over tasks')\n",
        "  plt.legend(['Accuracy', 'Loss'])\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iApKvCs942aS",
        "colab_type": "text"
      },
      "source": [
        "# Train and evaluation phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJse4JU7d9ck",
        "colab_type": "code",
        "outputId": "ead110fb-807f-46cd-f285-44286d6a5cb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pars_tasks = []\n",
        "test_indexes = []\n",
        "\n",
        "for task in range(0, 100, params.TASK_SIZE):\n",
        "  pars_tasks.insert(task, 0)\n",
        "\n",
        "for task in range(0, 100, params.TASK_SIZE):\n",
        "\n",
        "  train_indexes = trainDS.__getIndexesGroups__(task)\n",
        "  test_indexes = test_indexes + testDS.__getIndexesGroups__(task)\n",
        "\n",
        "  train_dataset = Subset(trainDS, train_indexes)\n",
        "  test_dataset = Subset(testDS, test_indexes)\n",
        "\n",
        "  train_loader = DataLoader( train_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE)\n",
        "  test_loader = DataLoader( test_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE )\n",
        "\n",
        "  if(task == 0):\n",
        "    torch.save(resNet, 'resNet_task{0}.pt'.format(task))\n",
        "  \n",
        "  \n",
        "\n",
        "  utils.trainfunction(task, train_loader, train_splits)\n",
        "  param = utils.evaluationTest(task, test_loader, test_splits)\n",
        "  pars_tasks[int(task/10)] = param #pars_task[i] = (accuracy, loss) at i-th task\t"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task = 0 \n",
            "train col =  [60 34 84 67 85 44 18 48  1 47]\n",
            "train col =  [[60 34 84 67 85 44 18 48  1 47]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "At step  0  and at epoch =  0  the loss is =  0.029300345107913017  and accuracy is =  0.2114\n",
            "At step  0  and at epoch =  1  the loss is =  0.02206692472100258  and accuracy is =  0.4456\n",
            "At step  0  and at epoch =  2  the loss is =  0.0174326840788126  and accuracy is =  0.5316\n",
            "At step  0  and at epoch =  3  the loss is =  0.01277845911681652  and accuracy is =  0.594\n",
            "At step  0  and at epoch =  4  the loss is =  0.008918427862226963  and accuracy is =  0.6398\n",
            "At step  0  and at epoch =  5  the loss is =  0.008076080121099949  and accuracy is =  0.6716\n",
            "At step  0  and at epoch =  6  the loss is =  0.0059523568488657475  and accuracy is =  0.7046\n",
            "At step  0  and at epoch =  7  the loss is =  0.004488552920520306  and accuracy is =  0.7302\n",
            "At step  0  and at epoch =  8  the loss is =  0.0021176335867494345  and accuracy is =  0.761\n",
            "At step  0  and at epoch =  9  the loss is =  0.00196070340462029  and accuracy is =  0.7836\n",
            "At step  0  and at epoch =  10  the loss is =  0.0024639603216201067  and accuracy is =  0.8124\n",
            "At step  0  and at epoch =  11  the loss is =  0.0048345476388931274  and accuracy is =  0.8288\n",
            "At step  0  and at epoch =  12  the loss is =  0.009438732638955116  and accuracy is =  0.8418\n",
            "At step  0  and at epoch =  13  the loss is =  0.0012366602895781398  and accuracy is =  0.8618\n",
            "At step  0  and at epoch =  14  the loss is =  0.0023973453789949417  and accuracy is =  0.8688\n",
            "At step  0  and at epoch =  15  the loss is =  0.0040096077136695385  and accuracy is =  0.8588\n",
            "At step  0  and at epoch =  16  the loss is =  0.0029692314565181732  and accuracy is =  0.8694\n",
            "At step  0  and at epoch =  17  the loss is =  0.002615454839542508  and accuracy is =  0.8918\n",
            "At step  0  and at epoch =  18  the loss is =  0.0054952786304056644  and accuracy is =  0.9\n",
            "At step  0  and at epoch =  19  the loss is =  0.0030334731563925743  and accuracy is =  0.8966\n",
            "At step  0  and at epoch =  20  the loss is =  0.0028785394970327616  and accuracy is =  0.9266\n",
            "At step  0  and at epoch =  21  the loss is =  0.0016282214783132076  and accuracy is =  0.9342\n",
            "At step  0  and at epoch =  22  the loss is =  0.0020426202099770308  and accuracy is =  0.9348\n",
            "At step  0  and at epoch =  23  the loss is =  0.0007960858638398349  and accuracy is =  0.9374\n",
            "At step  0  and at epoch =  24  the loss is =  0.0014662445755675435  and accuracy is =  0.9446\n",
            "At step  0  and at epoch =  25  the loss is =  0.0005718344473280013  and accuracy is =  0.9502\n",
            "At step  0  and at epoch =  26  the loss is =  0.00025052466662600636  and accuracy is =  0.9606\n",
            "At step  0  and at epoch =  27  the loss is =  0.0001307814964093268  and accuracy is =  0.9686\n",
            "At step  0  and at epoch =  28  the loss is =  0.0003031579835806042  and accuracy is =  0.978\n",
            "At step  0  and at epoch =  29  the loss is =  0.0002545045572333038  and accuracy is =  0.9884\n",
            "At step  0  and at epoch =  30  the loss is =  0.00013765109179075807  and accuracy is =  0.9976\n",
            "At step  0  and at epoch =  31  the loss is =  8.364015957340598e-05  and accuracy is =  0.9992\n",
            "At step  0  and at epoch =  32  the loss is =  8.751040149945766e-05  and accuracy is =  0.9998\n",
            "At step  0  and at epoch =  33  the loss is =  6.539999594679102e-05  and accuracy is =  0.9998\n",
            "At step  0  and at epoch =  34  the loss is =  6.442687299568206e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  35  the loss is =  6.384419975802302e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  36  the loss is =  6.385354208759964e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  37  the loss is =  6.423822196666151e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  38  the loss is =  6.485504127340391e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  39  the loss is =  6.562680937349796e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  40  the loss is =  6.6519329266157e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  41  the loss is =  6.749649037374184e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  42  the loss is =  6.853316881461069e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  43  the loss is =  6.957622827030718e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  44  the loss is =  7.060419738991186e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  45  the loss is =  7.165298302425072e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  46  the loss is =  7.268766057677567e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  47  the loss is =  7.369360537268221e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  48  the loss is =  7.367602665908635e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  49  the loss is =  7.381474279100075e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  50  the loss is =  7.396908040391281e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  51  the loss is =  7.413485582219437e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  52  the loss is =  7.430227560689673e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  53  the loss is =  7.447892858181149e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  54  the loss is =  7.465882663382217e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  55  the loss is =  7.48457241570577e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  56  the loss is =  7.503320375690237e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  57  the loss is =  7.522320811403915e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  58  the loss is =  7.541097875218838e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  59  the loss is =  7.55988949094899e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  60  the loss is =  7.578709482913837e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  61  the loss is =  7.597514922963455e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  62  the loss is =  7.59778922656551e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  63  the loss is =  7.601526885991916e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  64  the loss is =  7.604817801620811e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  65  the loss is =  7.608123996760696e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  66  the loss is =  7.611637556692585e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  67  the loss is =  7.615316280862316e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  68  the loss is =  7.61893461458385e-05  and accuracy is =  1.0\n",
            "At step  0  and at epoch =  69  the loss is =  7.622344855917618e-05  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "104\n",
            "Validation Loss: 0.012548781000077724 Validation Accuracy : 0.749\n",
            "task = 10 \n",
            "train col =  [68 37 94 75 95 50 20 54  2 53]\n",
            "train col =  [[68 37 94 75 95 50 20 54  2 53]]\n",
            "At step  10  and at epoch =  0  the loss is =  0.04278818890452385  and accuracy is =  0.4558\n",
            "At step  10  and at epoch =  1  the loss is =  0.027741076424717903  and accuracy is =  0.6834\n",
            "At step  10  and at epoch =  2  the loss is =  0.02091831900179386  and accuracy is =  0.7738\n",
            "At step  10  and at epoch =  3  the loss is =  0.020968584343791008  and accuracy is =  0.832\n",
            "At step  10  and at epoch =  4  the loss is =  0.019585460424423218  and accuracy is =  0.8786\n",
            "At step  10  and at epoch =  5  the loss is =  0.01375393383204937  and accuracy is =  0.9118\n",
            "At step  10  and at epoch =  6  the loss is =  0.012762606143951416  and accuracy is =  0.931\n",
            "At step  10  and at epoch =  7  the loss is =  0.01285878662019968  and accuracy is =  0.94\n",
            "At step  10  and at epoch =  8  the loss is =  0.014766791835427284  and accuracy is =  0.941\n",
            "At step  10  and at epoch =  9  the loss is =  0.01671714521944523  and accuracy is =  0.939\n",
            "At step  10  and at epoch =  10  the loss is =  0.012362382374703884  and accuracy is =  0.9606\n",
            "At step  10  and at epoch =  11  the loss is =  0.010429437272250652  and accuracy is =  0.9734\n",
            "At step  10  and at epoch =  12  the loss is =  0.00934866163879633  and accuracy is =  0.9858\n",
            "At step  10  and at epoch =  13  the loss is =  0.00954950600862503  and accuracy is =  0.9882\n",
            "At step  10  and at epoch =  14  the loss is =  0.011158532463014126  and accuracy is =  0.9872\n",
            "At step  10  and at epoch =  15  the loss is =  0.010394258424639702  and accuracy is =  0.9938\n",
            "At step  10  and at epoch =  16  the loss is =  0.010383333079516888  and accuracy is =  0.994\n",
            "At step  10  and at epoch =  17  the loss is =  0.010026508010923862  and accuracy is =  0.996\n",
            "At step  10  and at epoch =  18  the loss is =  0.009096106514334679  and accuracy is =  0.9976\n",
            "At step  10  and at epoch =  19  the loss is =  0.008986281231045723  and accuracy is =  0.9968\n",
            "At step  10  and at epoch =  20  the loss is =  0.008937069214880466  and accuracy is =  0.9982\n",
            "At step  10  and at epoch =  21  the loss is =  0.008746382780373096  and accuracy is =  0.9984\n",
            "At step  10  and at epoch =  22  the loss is =  0.0091975387185812  and accuracy is =  0.9978\n",
            "At step  10  and at epoch =  23  the loss is =  0.009329539723694324  and accuracy is =  0.9966\n",
            "At step  10  and at epoch =  24  the loss is =  0.010747726075351238  and accuracy is =  0.9972\n",
            "At step  10  and at epoch =  25  the loss is =  0.009067430160939693  and accuracy is =  0.995\n",
            "At step  10  and at epoch =  26  the loss is =  0.008751421235501766  and accuracy is =  0.995\n",
            "At step  10  and at epoch =  27  the loss is =  0.008710683323442936  and accuracy is =  0.9982\n",
            "At step  10  and at epoch =  28  the loss is =  0.00958783645182848  and accuracy is =  0.9978\n",
            "At step  10  and at epoch =  29  the loss is =  0.008467310108244419  and accuracy is =  0.9988\n",
            "At step  10  and at epoch =  30  the loss is =  0.008635512553155422  and accuracy is =  0.9982\n",
            "At step  10  and at epoch =  31  the loss is =  0.008956236764788628  and accuracy is =  0.9998\n",
            "At step  10  and at epoch =  32  the loss is =  0.009152197279036045  and accuracy is =  0.9996\n",
            "At step  10  and at epoch =  33  the loss is =  0.008308351039886475  and accuracy is =  0.9996\n",
            "At step  10  and at epoch =  34  the loss is =  0.007936832495033741  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  35  the loss is =  0.008137617260217667  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  36  the loss is =  0.00815958809107542  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  37  the loss is =  0.008150611072778702  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  38  the loss is =  0.008135347627103329  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  39  the loss is =  0.008194949477910995  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  40  the loss is =  0.00802476704120636  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  41  the loss is =  0.0080066854134202  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  42  the loss is =  0.008318902924656868  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  43  the loss is =  0.008373329415917397  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  44  the loss is =  0.007997982203960419  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  45  the loss is =  0.008078845217823982  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  46  the loss is =  0.008060327731072903  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  47  the loss is =  0.008076588623225689  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  48  the loss is =  0.007644828874617815  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  49  the loss is =  0.007507456932216883  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  50  the loss is =  0.007466444745659828  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  51  the loss is =  0.007443488575518131  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  52  the loss is =  0.007430524565279484  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  53  the loss is =  0.007422184571623802  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  54  the loss is =  0.007415355648845434  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  55  the loss is =  0.007409578189253807  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  56  the loss is =  0.0074043283239007  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  57  the loss is =  0.007399401627480984  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  58  the loss is =  0.00739494850859046  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  59  the loss is =  0.007390808314085007  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  60  the loss is =  0.007387004792690277  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  61  the loss is =  0.007383484859019518  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  62  the loss is =  0.007380523718893528  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  63  the loss is =  0.007379666902124882  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  64  the loss is =  0.007378903683274984  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  65  the loss is =  0.007378235924988985  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  66  the loss is =  0.007377592381089926  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  67  the loss is =  0.007376966532319784  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  68  the loss is =  0.007376349996775389  and accuracy is =  1.0\n",
            "At step  10  and at epoch =  69  the loss is =  0.007375745568424463  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "80\n",
            "Validation Loss: 0.02848616987466812 Validation Accuracy : 0.5585\n",
            "task = 20 \n",
            "train col =  [76 40 83 56 22 61  3 59 77 41]\n",
            "train col =  [[76 40 83 56 22 61  3 59 77 41]]\n",
            "At step  20  and at epoch =  0  the loss is =  0.06725972890853882  and accuracy is =  0.38\n",
            "At step  20  and at epoch =  1  the loss is =  0.05284728482365608  and accuracy is =  0.5512\n",
            "At step  20  and at epoch =  2  the loss is =  0.04417463019490242  and accuracy is =  0.6588\n",
            "At step  20  and at epoch =  3  the loss is =  0.046045660972595215  and accuracy is =  0.723\n",
            "At step  20  and at epoch =  4  the loss is =  0.039125289767980576  and accuracy is =  0.793\n",
            "At step  20  and at epoch =  5  the loss is =  0.038570668548345566  and accuracy is =  0.8428\n",
            "At step  20  and at epoch =  6  the loss is =  0.030854864045977592  and accuracy is =  0.8482\n",
            "At step  20  and at epoch =  7  the loss is =  0.02804863452911377  and accuracy is =  0.8662\n",
            "At step  20  and at epoch =  8  the loss is =  0.026310725137591362  and accuracy is =  0.8928\n",
            "At step  20  and at epoch =  9  the loss is =  0.023883767426013947  and accuracy is =  0.9118\n",
            "At step  20  and at epoch =  10  the loss is =  0.024736471474170685  and accuracy is =  0.931\n",
            "At step  20  and at epoch =  11  the loss is =  0.027321405708789825  and accuracy is =  0.9456\n",
            "At step  20  and at epoch =  12  the loss is =  0.02540142647922039  and accuracy is =  0.9482\n",
            "At step  20  and at epoch =  13  the loss is =  0.02240069769322872  and accuracy is =  0.9682\n",
            "At step  20  and at epoch =  14  the loss is =  0.023130731657147408  and accuracy is =  0.9782\n",
            "At step  20  and at epoch =  15  the loss is =  0.023750171065330505  and accuracy is =  0.9774\n",
            "At step  20  and at epoch =  16  the loss is =  0.023143140599131584  and accuracy is =  0.98\n",
            "At step  20  and at epoch =  17  the loss is =  0.023270487785339355  and accuracy is =  0.9768\n",
            "At step  20  and at epoch =  18  the loss is =  0.021831251680850983  and accuracy is =  0.9746\n",
            "At step  20  and at epoch =  19  the loss is =  0.023573756217956543  and accuracy is =  0.9808\n",
            "At step  20  and at epoch =  20  the loss is =  0.02578052505850792  and accuracy is =  0.9862\n",
            "At step  20  and at epoch =  21  the loss is =  0.02376542054116726  and accuracy is =  0.989\n",
            "At step  20  and at epoch =  22  the loss is =  0.022022366523742676  and accuracy is =  0.9924\n",
            "At step  20  and at epoch =  23  the loss is =  0.020415855571627617  and accuracy is =  0.9956\n",
            "At step  20  and at epoch =  24  the loss is =  0.02050197124481201  and accuracy is =  0.9972\n",
            "At step  20  and at epoch =  25  the loss is =  0.022083166986703873  and accuracy is =  0.9974\n",
            "At step  20  and at epoch =  26  the loss is =  0.021841339766979218  and accuracy is =  0.9956\n",
            "At step  20  and at epoch =  27  the loss is =  0.02125764638185501  and accuracy is =  0.9966\n",
            "At step  20  and at epoch =  28  the loss is =  0.02081611566245556  and accuracy is =  0.998\n",
            "At step  20  and at epoch =  29  the loss is =  0.020944654941558838  and accuracy is =  0.9974\n",
            "At step  20  and at epoch =  30  the loss is =  0.021340645849704742  and accuracy is =  0.9982\n",
            "At step  20  and at epoch =  31  the loss is =  0.0197739414870739  and accuracy is =  0.9972\n",
            "At step  20  and at epoch =  32  the loss is =  0.01989562250673771  and accuracy is =  0.998\n",
            "At step  20  and at epoch =  33  the loss is =  0.01969488523900509  and accuracy is =  0.9994\n",
            "At step  20  and at epoch =  34  the loss is =  0.02003823220729828  and accuracy is =  0.9998\n",
            "At step  20  and at epoch =  35  the loss is =  0.01901606284081936  and accuracy is =  0.9992\n",
            "At step  20  and at epoch =  36  the loss is =  0.019125813618302345  and accuracy is =  0.9998\n",
            "At step  20  and at epoch =  37  the loss is =  0.01952037774026394  and accuracy is =  0.9994\n",
            "At step  20  and at epoch =  38  the loss is =  0.019910737872123718  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  39  the loss is =  0.020331520587205887  and accuracy is =  0.9998\n",
            "At step  20  and at epoch =  40  the loss is =  0.021018875762820244  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  41  the loss is =  0.02003317140042782  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  42  the loss is =  0.019277291372418404  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  43  the loss is =  0.019125929102301598  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  44  the loss is =  0.019425297155976295  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  45  the loss is =  0.019402574747800827  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  46  the loss is =  0.01957119256258011  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  47  the loss is =  0.019696196541190147  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  48  the loss is =  0.019012311473488808  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  49  the loss is =  0.018674621358513832  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  50  the loss is =  0.018560508266091347  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  51  the loss is =  0.01849595084786415  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  52  the loss is =  0.01845337636768818  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  53  the loss is =  0.01842169091105461  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  54  the loss is =  0.018396632745862007  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  55  the loss is =  0.01837594248354435  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  56  the loss is =  0.018358809873461723  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  57  the loss is =  0.01834496669471264  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  58  the loss is =  0.018333422020077705  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  59  the loss is =  0.01832367107272148  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  60  the loss is =  0.018315238878130913  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  61  the loss is =  0.018307924270629883  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  62  the loss is =  0.01830696500837803  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  63  the loss is =  0.018302060663700104  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  64  the loss is =  0.018297379836440086  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  65  the loss is =  0.018294140696525574  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  66  the loss is =  0.018291307613253593  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  67  the loss is =  0.018288835883140564  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  68  the loss is =  0.018286654725670815  and accuracy is =  1.0\n",
            "At step  20  and at epoch =  69  the loss is =  0.018284689635038376  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "56\n",
            "Validation Loss: 0.04075023531913757 Validation Accuracy : 0.4096666666666667\n",
            "task = 30 \n",
            "train col =  [88 45 97 64 24 70  4 29 38 23]\n",
            "train col =  [[88 45 97 64 24 70  4 29 38 23]]\n",
            "At step  30  and at epoch =  0  the loss is =  0.07458999007940292  and accuracy is =  0.3574\n",
            "At step  30  and at epoch =  1  the loss is =  0.05327361449599266  and accuracy is =  0.5198\n",
            "At step  30  and at epoch =  2  the loss is =  0.04921990633010864  and accuracy is =  0.616\n",
            "At step  30  and at epoch =  3  the loss is =  0.04711513966321945  and accuracy is =  0.704\n",
            "At step  30  and at epoch =  4  the loss is =  0.04124412313103676  and accuracy is =  0.7886\n",
            "At step  30  and at epoch =  5  the loss is =  0.03628263249993324  and accuracy is =  0.8462\n",
            "At step  30  and at epoch =  6  the loss is =  0.03389567881822586  and accuracy is =  0.887\n",
            "At step  30  and at epoch =  7  the loss is =  0.036443572491407394  and accuracy is =  0.8746\n",
            "At step  30  and at epoch =  8  the loss is =  0.03532399237155914  and accuracy is =  0.878\n",
            "At step  30  and at epoch =  9  the loss is =  0.0353812500834465  and accuracy is =  0.9074\n",
            "At step  30  and at epoch =  10  the loss is =  0.03324120119214058  and accuracy is =  0.937\n",
            "At step  30  and at epoch =  11  the loss is =  0.0317002609372139  and accuracy is =  0.9588\n",
            "At step  30  and at epoch =  12  the loss is =  0.030804894864559174  and accuracy is =  0.9654\n",
            "At step  30  and at epoch =  13  the loss is =  0.03132730722427368  and accuracy is =  0.9726\n",
            "At step  30  and at epoch =  14  the loss is =  0.03256276249885559  and accuracy is =  0.9694\n",
            "At step  30  and at epoch =  15  the loss is =  0.034009866416454315  and accuracy is =  0.9762\n",
            "At step  30  and at epoch =  16  the loss is =  0.03396468982100487  and accuracy is =  0.9698\n",
            "At step  30  and at epoch =  17  the loss is =  0.03175518289208412  and accuracy is =  0.9726\n",
            "At step  30  and at epoch =  18  the loss is =  0.030028395354747772  and accuracy is =  0.986\n",
            "At step  30  and at epoch =  19  the loss is =  0.02890491858124733  and accuracy is =  0.992\n",
            "At step  30  and at epoch =  20  the loss is =  0.029146257787942886  and accuracy is =  0.997\n",
            "At step  30  and at epoch =  21  the loss is =  0.028889989480376244  and accuracy is =  0.9986\n",
            "At step  30  and at epoch =  22  the loss is =  0.029147490859031677  and accuracy is =  0.9994\n",
            "At step  30  and at epoch =  23  the loss is =  0.028534064069390297  and accuracy is =  0.9996\n",
            "At step  30  and at epoch =  24  the loss is =  0.028803391382098198  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  25  the loss is =  0.02820243313908577  and accuracy is =  0.9996\n",
            "At step  30  and at epoch =  26  the loss is =  0.02889777347445488  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  27  the loss is =  0.02926386334002018  and accuracy is =  0.9996\n",
            "At step  30  and at epoch =  28  the loss is =  0.02881033346056938  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  29  the loss is =  0.027861904352903366  and accuracy is =  0.9994\n",
            "At step  30  and at epoch =  30  the loss is =  0.027886727824807167  and accuracy is =  0.9994\n",
            "At step  30  and at epoch =  31  the loss is =  0.027855830267071724  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  32  the loss is =  0.02788064442574978  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  33  the loss is =  0.028147896751761436  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  34  the loss is =  0.028715388849377632  and accuracy is =  0.9998\n",
            "At step  30  and at epoch =  35  the loss is =  0.02869350276887417  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  36  the loss is =  0.02873745933175087  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  37  the loss is =  0.027637720108032227  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  38  the loss is =  0.028135990723967552  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  39  the loss is =  0.029588855803012848  and accuracy is =  0.9996\n",
            "At step  30  and at epoch =  40  the loss is =  0.029443249106407166  and accuracy is =  0.9996\n",
            "At step  30  and at epoch =  41  the loss is =  0.028642475605010986  and accuracy is =  0.9974\n",
            "At step  30  and at epoch =  42  the loss is =  0.028544757515192032  and accuracy is =  0.9896\n",
            "At step  30  and at epoch =  43  the loss is =  0.02908899448812008  and accuracy is =  0.9728\n",
            "At step  30  and at epoch =  44  the loss is =  0.03239015117287636  and accuracy is =  0.938\n",
            "At step  30  and at epoch =  45  the loss is =  0.0343964658677578  and accuracy is =  0.8854\n",
            "At step  30  and at epoch =  46  the loss is =  0.03454909101128578  and accuracy is =  0.954\n",
            "At step  30  and at epoch =  47  the loss is =  0.028944071382284164  and accuracy is =  0.9868\n",
            "At step  30  and at epoch =  48  the loss is =  0.028302963823080063  and accuracy is =  0.9988\n",
            "At step  30  and at epoch =  49  the loss is =  0.027857808396220207  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  50  the loss is =  0.027649398893117905  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  51  the loss is =  0.027521945536136627  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  52  the loss is =  0.0274274293333292  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  53  the loss is =  0.027351507917046547  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  54  the loss is =  0.027285248041152954  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  55  the loss is =  0.02722805365920067  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  56  the loss is =  0.0271784495562315  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  57  the loss is =  0.027133584022521973  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  58  the loss is =  0.027093717828392982  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  59  the loss is =  0.027058299630880356  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  60  the loss is =  0.027026720345020294  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  61  the loss is =  0.02699759416282177  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  62  the loss is =  0.026920557022094727  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  63  the loss is =  0.026908444240689278  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  64  the loss is =  0.026901325210928917  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  65  the loss is =  0.026895275339484215  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  66  the loss is =  0.026889927685260773  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  67  the loss is =  0.02688506804406643  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  68  the loss is =  0.026880472898483276  and accuracy is =  1.0\n",
            "At step  30  and at epoch =  69  the loss is =  0.026876121759414673  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "32\n",
            "Validation Loss: 0.0520707368850708 Validation Accuracy : 0.28725\n",
            "task = 40 \n",
            "train col =  [49 26 72 55 96 32 13 35  0 33]\n",
            "train col =  [[49 26 72 55 96 32 13 35  0 33]]\n",
            "At step  40  and at epoch =  0  the loss is =  0.06919371336698532  and accuracy is =  0.4514\n",
            "At step  40  and at epoch =  1  the loss is =  0.06977034360170364  and accuracy is =  0.6104\n",
            "At step  40  and at epoch =  2  the loss is =  0.05693097785115242  and accuracy is =  0.6848\n",
            "At step  40  and at epoch =  3  the loss is =  0.051217544823884964  and accuracy is =  0.7516\n",
            "At step  40  and at epoch =  4  the loss is =  0.04851547256112099  and accuracy is =  0.8078\n",
            "At step  40  and at epoch =  5  the loss is =  0.04949016869068146  and accuracy is =  0.8498\n",
            "At step  40  and at epoch =  6  the loss is =  0.04749583080410957  and accuracy is =  0.8644\n",
            "At step  40  and at epoch =  7  the loss is =  0.046110495924949646  and accuracy is =  0.8798\n",
            "At step  40  and at epoch =  8  the loss is =  0.0438331738114357  and accuracy is =  0.9154\n",
            "At step  40  and at epoch =  9  the loss is =  0.04334581643342972  and accuracy is =  0.9304\n",
            "At step  40  and at epoch =  10  the loss is =  0.04115784540772438  and accuracy is =  0.9482\n",
            "At step  40  and at epoch =  11  the loss is =  0.042104434221982956  and accuracy is =  0.9694\n",
            "At step  40  and at epoch =  12  the loss is =  0.044032711535692215  and accuracy is =  0.9784\n",
            "At step  40  and at epoch =  13  the loss is =  0.042555950582027435  and accuracy is =  0.9774\n",
            "At step  40  and at epoch =  14  the loss is =  0.04139610752463341  and accuracy is =  0.9796\n",
            "At step  40  and at epoch =  15  the loss is =  0.04171031713485718  and accuracy is =  0.9842\n",
            "At step  40  and at epoch =  16  the loss is =  0.042202673852443695  and accuracy is =  0.9876\n",
            "At step  40  and at epoch =  17  the loss is =  0.041099436581134796  and accuracy is =  0.9908\n",
            "At step  40  and at epoch =  18  the loss is =  0.04164179787039757  and accuracy is =  0.9926\n",
            "At step  40  and at epoch =  19  the loss is =  0.04376908764243126  and accuracy is =  0.9898\n",
            "At step  40  and at epoch =  20  the loss is =  0.04511319845914841  and accuracy is =  0.9872\n",
            "At step  40  and at epoch =  21  the loss is =  0.04886379465460777  and accuracy is =  0.9872\n",
            "At step  40  and at epoch =  22  the loss is =  0.041073206812143326  and accuracy is =  0.9896\n",
            "At step  40  and at epoch =  23  the loss is =  0.03950190544128418  and accuracy is =  0.9958\n",
            "At step  40  and at epoch =  24  the loss is =  0.03909621015191078  and accuracy is =  0.998\n",
            "At step  40  and at epoch =  25  the loss is =  0.03874465078115463  and accuracy is =  0.999\n",
            "At step  40  and at epoch =  26  the loss is =  0.03892233222723007  and accuracy is =  0.9992\n",
            "At step  40  and at epoch =  27  the loss is =  0.04024415463209152  and accuracy is =  0.9994\n",
            "At step  40  and at epoch =  28  the loss is =  0.04056546092033386  and accuracy is =  0.999\n",
            "At step  40  and at epoch =  29  the loss is =  0.039244528859853745  and accuracy is =  0.999\n",
            "At step  40  and at epoch =  30  the loss is =  0.03862491622567177  and accuracy is =  0.9992\n",
            "At step  40  and at epoch =  31  the loss is =  0.03859765827655792  and accuracy is =  0.999\n",
            "At step  40  and at epoch =  32  the loss is =  0.03869343549013138  and accuracy is =  0.9986\n",
            "At step  40  and at epoch =  33  the loss is =  0.039134591817855835  and accuracy is =  0.9988\n",
            "At step  40  and at epoch =  34  the loss is =  0.03908064216375351  and accuracy is =  0.9994\n",
            "At step  40  and at epoch =  35  the loss is =  0.039636753499507904  and accuracy is =  0.9992\n",
            "At step  40  and at epoch =  36  the loss is =  0.039059728384017944  and accuracy is =  0.9994\n",
            "At step  40  and at epoch =  37  the loss is =  0.03891856223344803  and accuracy is =  0.9994\n",
            "At step  40  and at epoch =  38  the loss is =  0.038710854947566986  and accuracy is =  0.9994\n",
            "At step  40  and at epoch =  39  the loss is =  0.03918303921818733  and accuracy is =  0.9998\n",
            "At step  40  and at epoch =  40  the loss is =  0.03907852619886398  and accuracy is =  0.9996\n",
            "At step  40  and at epoch =  41  the loss is =  0.03885335475206375  and accuracy is =  0.9998\n",
            "At step  40  and at epoch =  42  the loss is =  0.03859414905309677  and accuracy is =  0.9998\n",
            "At step  40  and at epoch =  43  the loss is =  0.0388767272233963  and accuracy is =  0.9996\n",
            "At step  40  and at epoch =  44  the loss is =  0.03850903362035751  and accuracy is =  0.9992\n",
            "At step  40  and at epoch =  45  the loss is =  0.038912490010261536  and accuracy is =  0.9994\n",
            "At step  40  and at epoch =  46  the loss is =  0.038549624383449554  and accuracy is =  0.9988\n",
            "At step  40  and at epoch =  47  the loss is =  0.03870495781302452  and accuracy is =  0.9984\n",
            "At step  40  and at epoch =  48  the loss is =  0.03810906410217285  and accuracy is =  0.9988\n",
            "At step  40  and at epoch =  49  the loss is =  0.0376410149037838  and accuracy is =  0.9996\n",
            "At step  40  and at epoch =  50  the loss is =  0.03746981546282768  and accuracy is =  0.9998\n",
            "At step  40  and at epoch =  51  the loss is =  0.0373893566429615  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  52  the loss is =  0.037337448447942734  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  53  the loss is =  0.03730101138353348  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  54  the loss is =  0.037272267043590546  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  55  the loss is =  0.03724849596619606  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  56  the loss is =  0.03722835332155228  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  57  the loss is =  0.03721011430025101  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  58  the loss is =  0.03719419240951538  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  59  the loss is =  0.03717994689941406  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  60  the loss is =  0.03716713935136795  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  61  the loss is =  0.03715544939041138  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  62  the loss is =  0.03719043731689453  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  63  the loss is =  0.037164680659770966  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  64  the loss is =  0.037155695259571075  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  65  the loss is =  0.03714819625020027  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  66  the loss is =  0.037142157554626465  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  67  the loss is =  0.03713708743453026  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  68  the loss is =  0.03713275492191315  and accuracy is =  1.0\n",
            "At step  40  and at epoch =  69  the loss is =  0.037128981202840805  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "8\n",
            "Validation Loss: 0.06622393429279327 Validation Accuracy : 0.2378\n",
            "task = 50 \n",
            "train col =  [65 30 87 71 93 43 15 51  5 46]\n",
            "train col =  [[65 30 87 71 93 43 15 51  5 46]]\n",
            "At step  50  and at epoch =  0  the loss is =  0.09030745923519135  and accuracy is =  0.4306\n",
            "At step  50  and at epoch =  1  the loss is =  0.08304143697023392  and accuracy is =  0.612\n",
            "At step  50  and at epoch =  2  the loss is =  0.07806762307882309  and accuracy is =  0.6886\n",
            "At step  50  and at epoch =  3  the loss is =  0.06731285899877548  and accuracy is =  0.7714\n",
            "At step  50  and at epoch =  4  the loss is =  0.06370099633932114  and accuracy is =  0.8358\n",
            "At step  50  and at epoch =  5  the loss is =  0.05796658247709274  and accuracy is =  0.892\n",
            "At step  50  and at epoch =  6  the loss is =  0.05798748508095741  and accuracy is =  0.9192\n",
            "At step  50  and at epoch =  7  the loss is =  0.05634202063083649  and accuracy is =  0.9358\n",
            "At step  50  and at epoch =  8  the loss is =  0.05608208477497101  and accuracy is =  0.9456\n",
            "At step  50  and at epoch =  9  the loss is =  0.055904489010572433  and accuracy is =  0.9534\n",
            "At step  50  and at epoch =  10  the loss is =  0.058436863124370575  and accuracy is =  0.9624\n",
            "At step  50  and at epoch =  11  the loss is =  0.05613787844777107  and accuracy is =  0.9708\n",
            "At step  50  and at epoch =  12  the loss is =  0.054147977381944656  and accuracy is =  0.9762\n",
            "At step  50  and at epoch =  13  the loss is =  0.054045602679252625  and accuracy is =  0.9868\n",
            "At step  50  and at epoch =  14  the loss is =  0.05366002768278122  and accuracy is =  0.9936\n",
            "At step  50  and at epoch =  15  the loss is =  0.05326886847615242  and accuracy is =  0.9948\n",
            "At step  50  and at epoch =  16  the loss is =  0.05483531951904297  and accuracy is =  0.9974\n",
            "At step  50  and at epoch =  17  the loss is =  0.05490238219499588  and accuracy is =  0.9948\n",
            "At step  50  and at epoch =  18  the loss is =  0.05364585667848587  and accuracy is =  0.9968\n",
            "At step  50  and at epoch =  19  the loss is =  0.05278046429157257  and accuracy is =  0.9968\n",
            "At step  50  and at epoch =  20  the loss is =  0.05228973925113678  and accuracy is =  0.9988\n",
            "At step  50  and at epoch =  21  the loss is =  0.05213722214102745  and accuracy is =  0.9988\n",
            "At step  50  and at epoch =  22  the loss is =  0.051907069981098175  and accuracy is =  0.9992\n",
            "At step  50  and at epoch =  23  the loss is =  0.052096981555223465  and accuracy is =  0.9994\n",
            "At step  50  and at epoch =  24  the loss is =  0.052161235362291336  and accuracy is =  0.9988\n",
            "At step  50  and at epoch =  25  the loss is =  0.052225980907678604  and accuracy is =  0.9984\n",
            "At step  50  and at epoch =  26  the loss is =  0.0521775558590889  and accuracy is =  0.9998\n",
            "At step  50  and at epoch =  27  the loss is =  0.05185392126441002  and accuracy is =  0.999\n",
            "At step  50  and at epoch =  28  the loss is =  0.051646266132593155  and accuracy is =  0.9994\n",
            "At step  50  and at epoch =  29  the loss is =  0.05183492228388786  and accuracy is =  0.9992\n",
            "At step  50  and at epoch =  30  the loss is =  0.05195669084787369  and accuracy is =  0.9988\n",
            "At step  50  and at epoch =  31  the loss is =  0.0524420440196991  and accuracy is =  0.9996\n",
            "At step  50  and at epoch =  32  the loss is =  0.05170103535056114  and accuracy is =  0.9998\n",
            "At step  50  and at epoch =  33  the loss is =  0.05144082009792328  and accuracy is =  0.9998\n",
            "At step  50  and at epoch =  34  the loss is =  0.05209830775856972  and accuracy is =  0.9994\n",
            "At step  50  and at epoch =  35  the loss is =  0.05249764397740364  and accuracy is =  0.9992\n",
            "At step  50  and at epoch =  36  the loss is =  0.052320461720228195  and accuracy is =  0.9988\n",
            "At step  50  and at epoch =  37  the loss is =  0.05138404667377472  and accuracy is =  0.9986\n",
            "At step  50  and at epoch =  38  the loss is =  0.05151236429810524  and accuracy is =  0.998\n",
            "At step  50  and at epoch =  39  the loss is =  0.05206438899040222  and accuracy is =  0.9976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ptf2qZjFbWNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotTask(pars_tasks)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}