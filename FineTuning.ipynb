{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FineTuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ee156c9d9c247fa8c2625ecde7e7bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4c7d20920c7f47adb9a1e2acb181ea11",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_30d29e34b8134b63916cd8c707b99462",
              "IPY_MODEL_66812d64072a4ca584a771e47709a61e"
            ]
          }
        },
        "4c7d20920c7f47adb9a1e2acb181ea11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30d29e34b8134b63916cd8c707b99462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_feaf39922d94413ba925325e2168b4ea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_697efdf6720e43bfa6613d3f1d21f48c"
          }
        },
        "66812d64072a4ca584a771e47709a61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b69667a0fc614f54b1b05efef00ae76e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169009152/? [00:20&lt;00:00, 31539494.50it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1883806207d44eee96f80a3a8cae2c54"
          }
        },
        "feaf39922d94413ba925325e2168b4ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "697efdf6720e43bfa6613d3f1d21f48c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b69667a0fc614f54b1b05efef00ae76e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1883806207d44eee96f80a3a8cae2c54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciainnocenti/IncrementalLearning/blob/debugV1_Lucia/FineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCO7owW4O0jb",
        "colab_type": "text"
      },
      "source": [
        "# Import GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01VjtslGOvI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSC6q-24O8Yr",
        "colab_type": "code",
        "outputId": "964e0e81-9b08-4865-a8bc-05211af86998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "if not os.path.isdir('./DatasetCIFAR'):\n",
        "  !git clone -b debugV1_Lucia https://github.com/luciainnocenti/IncrementalLearning.git\n",
        "  !mv 'IncrementalLearning' 'DatasetCIFAR'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IncrementalLearning'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 1155 (delta 7), reused 0 (delta 0), pack-reused 1140\u001b[K\n",
            "Receiving objects: 100% (1155/1155), 761.64 KiB | 2.13 MiB/s, done.\n",
            "Resolving deltas: 100% (733/733), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q5sdRysO9-F",
        "colab_type": "text"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3AwEK1IPEDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from DatasetCIFAR.data_set import Dataset \n",
        "from DatasetCIFAR import ResNet\n",
        "from DatasetCIFAR import utils\n",
        "from DatasetCIFAR import params\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.nn import functional as F\n",
        "import random\n",
        "random.seed(params.SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU8_JQV3O_c5",
        "colab_type": "text"
      },
      "source": [
        "# Define Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SN6IDz3PJUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resNet = ResNet.resnet32(num_classes=100)\n",
        "resNet = resNet.to(params.DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXGgft0iPLVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_transformer = transforms.Compose([transforms.RandomCrop(size = 32, padding=4),\n",
        "                                         transforms.RandomHorizontalFlip(),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transformer = transforms.Compose([transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ldJmjNkPNiG",
        "colab_type": "text"
      },
      "source": [
        "# Define DataSets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czGrTi8VPRoB",
        "colab_type": "code",
        "outputId": "39035cd5-e483-4d92-bef8-faf0deee9b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "3ee156c9d9c247fa8c2625ecde7e7bd2",
            "4c7d20920c7f47adb9a1e2acb181ea11",
            "30d29e34b8134b63916cd8c707b99462",
            "66812d64072a4ca584a771e47709a61e",
            "feaf39922d94413ba925325e2168b4ea",
            "697efdf6720e43bfa6613d3f1d21f48c",
            "b69667a0fc614f54b1b05efef00ae76e",
            "1883806207d44eee96f80a3a8cae2c54"
          ]
        }
      },
      "source": [
        "trainDS = Dataset(train=True, transform = train_transformer)\n",
        "testDS = Dataset(train=False, transform = test_transformer)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ee156c9d9c247fa8c2625ecde7e7bd2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn8XrSWqPUiN",
        "colab_type": "code",
        "outputId": "05c0b4b2-4e71-4576-bc59-4eee4320e70d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "train_splits = trainDS.splits\n",
        "test_splits = testDS.splits\n",
        "print(train_splits)\n",
        "print(test_splits)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[84.0, 60.0, 93.0, 81.0, 64.0, 11.0, 49.0, 80.0, 69.0, 61.0], [94.0, 65.0, 90.0, 70.0, 12.0, 51.0, 89.0, 75.0, 66.0, 16.0], [72.0, 77.0, 13.0, 54.0, 85.0, 73.0, 18.0, 37.0, 29.0, 36.0], [86.0, 92.0, 14.0, 62.0, 87.0, 20.0, 42.0, 58.0, 63.0, 17.0], [57.0, 41.0, 71.0, 55.0, 44.0, 88.0, 5.0, 33.0, 96.0, 99.0], [78.0, 46.0, 91.0, 74.0, 48.0, 6.0, 35.0, 95.0, 52.0, 97.0], [53.0, 59.0, 7.0, 39.0, 68.0, 98.0, 9.0, 27.0, 23.0, 10.0], [45.0, 31.0, 50.0, 43.0, 32.0, 2.0, 26.0, 76.0, 83.0, 34.0], [24.0, 25.0, 67.0, 19.0, 30.0, 1.0, 82.0, 47.0, 4.0, 3.0], [22.0, 56.0, 38.0, 40.0, 79.0, 15.0, 21.0, 0.0, 28.0, 8.0]]\n",
            "[[84.0, 60.0, 93.0, 81.0, 64.0, 11.0, 49.0, 80.0, 69.0, 61.0], [94.0, 65.0, 90.0, 70.0, 12.0, 51.0, 89.0, 75.0, 66.0, 16.0], [72.0, 77.0, 13.0, 54.0, 85.0, 73.0, 18.0, 37.0, 29.0, 36.0], [86.0, 92.0, 14.0, 62.0, 87.0, 20.0, 42.0, 58.0, 63.0, 17.0], [57.0, 41.0, 71.0, 55.0, 44.0, 88.0, 5.0, 33.0, 96.0, 99.0], [78.0, 46.0, 91.0, 74.0, 48.0, 6.0, 35.0, 95.0, 52.0, 97.0], [53.0, 59.0, 7.0, 39.0, 68.0, 98.0, 9.0, 27.0, 23.0, 10.0], [45.0, 31.0, 50.0, 43.0, 32.0, 2.0, 26.0, 76.0, 83.0, 34.0], [24.0, 25.0, 67.0, 19.0, 30.0, 1.0, 82.0, 47.0, 4.0, 3.0], [22.0, 56.0, 38.0, 40.0, 79.0, 15.0, 21.0, 0.0, 28.0, 8.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc8WMLe3PQvI",
        "colab_type": "text"
      },
      "source": [
        "# Useful plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQBZdyyrPW_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotTask(pars_tasks):\n",
        "  import numpy as np\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  x_tasks =  np.linspace(10, 100, 10)\n",
        "\n",
        "  plt.plot(x_tasks, pars_tasks, label=['Accuracy', 'Loss'])\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.title('Accuracy over tasks')\n",
        "  plt.legend(['Accuracy', 'Loss'])\n",
        "  plt.grid(True)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RzunPCcSfip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mapFunction(labels, splits):\n",
        "\tm_l = []\n",
        "\tl_splits = list(splits)\n",
        "\tfor el in labels:\n",
        "\t\tm_l.append( l_splits.index(el) )\n",
        "\treturn torch.LongTensor(m_l).to(params.DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPWcz2ISRN6E",
        "colab_type": "text"
      },
      "source": [
        "# Train and evaluation phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs6I_lmjRLYo",
        "colab_type": "code",
        "outputId": "9b213939-9950-40a9-89ba-ea913298ce0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pars_tasks = []\n",
        "test_indexes = []\n",
        "\n",
        "for task in range(0, 100, params.TASK_SIZE):\n",
        "  pars_tasks.insert(task, 0)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD(resNet.parameters(), lr=params.LR, momentum=params.MOMENTUM, weight_decay=params.WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, params.STEP_SIZE, gamma=params.GAMMA) #allow to change the LR at predefined epochs\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "current_step = 0\n",
        "\n",
        "\n",
        "for task in range(0, 100, params.TASK_SIZE):\n",
        "\n",
        "  train_indexes = trainDS.__getIndexesGroups__(task)\n",
        "  test_indexes = test_indexes + testDS.__getIndexesGroups__(task)\n",
        "\n",
        "  train_dataset = Subset(trainDS, train_indexes)\n",
        "  test_dataset = Subset(testDS, test_indexes)\n",
        "\n",
        "  train_loader = DataLoader( train_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE, shuffle=True)\n",
        "  test_loader = DataLoader( test_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE, shuffle=True )\n",
        "  \n",
        "  col = np.array(train_splits[int(task/10)]).astype(int)\n",
        "  \n",
        "  for epoch in range(params.NUM_EPOCHS):\n",
        "    lenght = 0\n",
        "    scheduler.step() #update the learning rate\n",
        "    running_corrects = 0    \n",
        "    for images, labels, _ in train_loader:\n",
        "      images = images.float().to(params.DEVICE)\n",
        "      labels = labels.to(params.DEVICE)\n",
        "      mappedLabels = mapFunction(labels, col)   \n",
        "      onehot_labels = torch.eye(100)[labels].to(params.DEVICE)#it creates the one-hot-encoding list for the labels; needed for BCELoss    \n",
        "      optimizer.zero_grad() # Zero-ing the gradients\n",
        "      outputs = resNet(images)\n",
        "      loss = criterion(outputs,onehot_labels)   \n",
        "      cut_outputs = np.take_along_axis(outputs.to(params.DEVICE), col[None, :], axis = 1).to(params.DEVICE)\n",
        "      _, preds = torch.max(cut_outputs.data, 1)\n",
        "      running_corrects += torch.sum(preds == mappedLabels.data).data.item()   \n",
        "      loss.backward()   \n",
        "      optimizer.step()    \n",
        "      current_step += 1\n",
        "      lenght += len(images)   \n",
        "    accuracy = running_corrects / float(lenght)\n",
        "    print(\"At step \", str(task), \" and at epoch = \", epoch, \" the loss is = \", loss.item(), \" and accuracy is = \", accuracy)\n",
        "  \n",
        "  resNet = resNet.eval()\n",
        "\n",
        "  t_l = 0\n",
        "  running_corrects = 0\n",
        "  col = []\n",
        "  for i,x in enumerate( test_splits[ :int(task/10) + 1]):\n",
        "  \tv = np.array(x)\n",
        "  \tcol = np.concatenate( (col,v), axis = None)\n",
        "  col = col.astype(int)\n",
        "\n",
        "  for images, labels, _ in test_loader:\n",
        "    images = images.float().to(params.DEVICE)\n",
        "    labels = labels.to(params.DEVICE)   \n",
        "    mappedLabels = mapFunction(labels, col)\n",
        "\n",
        "    onehot_labels = torch.eye(100)[labels].to(params.DEVICE)\n",
        "\n",
        "    outputs = resNet(images).to(params.DEVICE)\n",
        "    cut_outputs = np.take_along_axis(outputs, col[None, :], axis = 1)\n",
        "    cut_outputs = cut_outputs.to(params.DEVICE)\n",
        "    _, preds = torch.max(cut_outputs.data, 1)\n",
        "\t\t# Update Corrects\n",
        "    running_corrects += torch.sum(preds == mappedLabels.data).data.item()\n",
        "    print(len(images))\n",
        "    t_l += len(images)\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(t_l)\n",
        "  loss = criterion(outputs,onehot_labels)\n",
        "  print('Validation Loss: {} Validation Accuracy : {}'.format(loss.item(),accuracy) )\n",
        "  pars_tasks[int(task/10)] = (accuracy, loss.item())\n",
        "  resNet = resNet.train(True)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "At step  0  and at epoch =  0  the loss is =  0.023152070119976997  and accuracy is =  0.2104\n",
            "At step  0  and at epoch =  1  the loss is =  0.025593284517526627  and accuracy is =  0.4234\n",
            "At step  0  and at epoch =  2  the loss is =  0.021870208904147148  and accuracy is =  0.483\n",
            "At step  0  and at epoch =  3  the loss is =  0.02094932831823826  and accuracy is =  0.5392\n",
            "At step  0  and at epoch =  4  the loss is =  0.0212533138692379  and accuracy is =  0.575\n",
            "At step  0  and at epoch =  5  the loss is =  0.015877999365329742  and accuracy is =  0.6086\n",
            "At step  0  and at epoch =  6  the loss is =  0.01675933040678501  and accuracy is =  0.6466\n",
            "At step  0  and at epoch =  7  the loss is =  0.027993347495794296  and accuracy is =  0.6704\n",
            "At step  0  and at epoch =  8  the loss is =  0.01844351924955845  and accuracy is =  0.676\n",
            "At step  0  and at epoch =  9  the loss is =  0.014976182952523232  and accuracy is =  0.7098\n",
            "At step  0  and at epoch =  10  the loss is =  0.009001010097563267  and accuracy is =  0.7066\n",
            "At step  0  and at epoch =  11  the loss is =  0.02233501896262169  and accuracy is =  0.7546\n",
            "At step  0  and at epoch =  12  the loss is =  0.022119898349046707  and accuracy is =  0.7908\n",
            "At step  0  and at epoch =  13  the loss is =  0.028129128739237785  and accuracy is =  0.7658\n",
            "At step  0  and at epoch =  14  the loss is =  0.012762063182890415  and accuracy is =  0.7948\n",
            "At step  0  and at epoch =  15  the loss is =  0.008409271948039532  and accuracy is =  0.8296\n",
            "At step  0  and at epoch =  16  the loss is =  0.007968279533088207  and accuracy is =  0.8746\n",
            "At step  0  and at epoch =  17  the loss is =  0.008406572975218296  and accuracy is =  0.8874\n",
            "At step  0  and at epoch =  18  the loss is =  0.025298085063695908  and accuracy is =  0.903\n",
            "At step  0  and at epoch =  19  the loss is =  0.011324023827910423  and accuracy is =  0.8674\n",
            "At step  0  and at epoch =  20  the loss is =  0.004197489004582167  and accuracy is =  0.8888\n",
            "At step  0  and at epoch =  21  the loss is =  0.007848580367863178  and accuracy is =  0.9262\n",
            "At step  0  and at epoch =  22  the loss is =  0.018878936767578125  and accuracy is =  0.9492\n",
            "At step  0  and at epoch =  23  the loss is =  0.025149935856461525  and accuracy is =  0.8368\n",
            "At step  0  and at epoch =  24  the loss is =  0.017382394522428513  and accuracy is =  0.9038\n",
            "At step  0  and at epoch =  25  the loss is =  0.009832403622567654  and accuracy is =  0.8948\n",
            "At step  0  and at epoch =  26  the loss is =  0.026073068380355835  and accuracy is =  0.9488\n",
            "At step  0  and at epoch =  27  the loss is =  0.02365845814347267  and accuracy is =  0.8964\n",
            "At step  0  and at epoch =  28  the loss is =  0.0004888975527137518  and accuracy is =  0.9232\n",
            "At step  0  and at epoch =  29  the loss is =  0.012839213013648987  and accuracy is =  0.9854\n",
            "At step  0  and at epoch =  30  the loss is =  0.016489271074533463  and accuracy is =  0.9736\n",
            "At step  0  and at epoch =  31  the loss is =  0.010706473141908646  and accuracy is =  0.8962\n",
            "At step  0  and at epoch =  32  the loss is =  0.003590448759496212  and accuracy is =  0.9342\n",
            "At step  0  and at epoch =  33  the loss is =  0.031211571767926216  and accuracy is =  0.9856\n",
            "At step  0  and at epoch =  34  the loss is =  0.016590921208262444  and accuracy is =  0.9096\n",
            "At step  0  and at epoch =  35  the loss is =  0.01796889118850231  and accuracy is =  0.9562\n",
            "At step  0  and at epoch =  36  the loss is =  0.009286891669034958  and accuracy is =  0.948\n",
            "At step  0  and at epoch =  37  the loss is =  0.023010393604636192  and accuracy is =  0.9684\n",
            "At step  0  and at epoch =  38  the loss is =  0.0036864711437374353  and accuracy is =  0.9196\n",
            "At step  0  and at epoch =  39  the loss is =  0.004300978966057301  and accuracy is =  0.9714\n",
            "At step  0  and at epoch =  40  the loss is =  0.013624482788145542  and accuracy is =  0.9778\n",
            "At step  0  and at epoch =  41  the loss is =  0.005497170612215996  and accuracy is =  0.9722\n",
            "At step  0  and at epoch =  42  the loss is =  0.004718596115708351  and accuracy is =  0.952\n",
            "At step  0  and at epoch =  43  the loss is =  0.02449904941022396  and accuracy is =  0.9814\n",
            "At step  0  and at epoch =  44  the loss is =  0.005941271781921387  and accuracy is =  0.936\n",
            "At step  0  and at epoch =  45  the loss is =  0.005963942967355251  and accuracy is =  0.9766\n",
            "At step  0  and at epoch =  46  the loss is =  0.003527861088514328  and accuracy is =  0.9666\n",
            "At step  0  and at epoch =  47  the loss is =  0.009901855140924454  and accuracy is =  0.972\n",
            "At step  0  and at epoch =  48  the loss is =  0.013545789755880833  and accuracy is =  0.9904\n",
            "At step  0  and at epoch =  49  the loss is =  0.002696072682738304  and accuracy is =  0.9964\n",
            "At step  0  and at epoch =  50  the loss is =  0.003735770471394062  and accuracy is =  0.9978\n",
            "At step  0  and at epoch =  51  the loss is =  0.0007922658114694059  and accuracy is =  0.9984\n",
            "At step  0  and at epoch =  52  the loss is =  0.006200665142387152  and accuracy is =  0.9988\n",
            "At step  0  and at epoch =  53  the loss is =  0.01603456772863865  and accuracy is =  0.998\n",
            "At step  0  and at epoch =  54  the loss is =  0.01219592709094286  and accuracy is =  0.998\n",
            "At step  0  and at epoch =  55  the loss is =  0.0018813186325132847  and accuracy is =  0.996\n",
            "At step  0  and at epoch =  56  the loss is =  0.0011080396361649036  and accuracy is =  0.9988\n",
            "At step  0  and at epoch =  57  the loss is =  0.009375724010169506  and accuracy is =  0.9996\n",
            "At step  0  and at epoch =  58  the loss is =  0.004331190604716539  and accuracy is =  0.9936\n",
            "At step  0  and at epoch =  59  the loss is =  0.00022408818767871708  and accuracy is =  0.999\n",
            "At step  0  and at epoch =  60  the loss is =  0.003902639262378216  and accuracy is =  0.9994\n",
            "At step  0  and at epoch =  61  the loss is =  0.006937665864825249  and accuracy is =  0.9982\n",
            "At step  0  and at epoch =  62  the loss is =  0.013717293739318848  and accuracy is =  0.9988\n",
            "At step  0  and at epoch =  63  the loss is =  0.0020559222903102636  and accuracy is =  0.9998\n",
            "At step  0  and at epoch =  64  the loss is =  0.017878910526633263  and accuracy is =  0.999\n",
            "At step  0  and at epoch =  65  the loss is =  0.0012572105042636395  and accuracy is =  0.9998\n",
            "At step  0  and at epoch =  66  the loss is =  0.0063643441535532475  and accuracy is =  0.9996\n",
            "At step  0  and at epoch =  67  the loss is =  0.008726203814148903  and accuracy is =  0.9996\n",
            "At step  0  and at epoch =  68  the loss is =  0.016807744279503822  and accuracy is =  0.9994\n",
            "At step  0  and at epoch =  69  the loss is =  0.0015461832517758012  and accuracy is =  1.0\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "104\n",
            "Validation Loss: 0.0189205352216959 Validation Accuracy : 0.723\n",
            "At step  10  and at epoch =  0  the loss is =  0.10033272206783295  and accuracy is =  0.139\n",
            "At step  10  and at epoch =  1  the loss is =  0.05851328745484352  and accuracy is =  0.1426\n",
            "At step  10  and at epoch =  2  the loss is =  0.04910142719745636  and accuracy is =  0.1608\n",
            "At step  10  and at epoch =  3  the loss is =  0.029101179912686348  and accuracy is =  0.2278\n",
            "At step  10  and at epoch =  4  the loss is =  0.02635018713772297  and accuracy is =  0.2762\n",
            "At step  10  and at epoch =  5  the loss is =  0.02738572470843792  and accuracy is =  0.3364\n",
            "At step  10  and at epoch =  6  the loss is =  0.026050185784697533  and accuracy is =  0.38\n",
            "At step  10  and at epoch =  7  the loss is =  0.028815289959311485  and accuracy is =  0.4126\n",
            "At step  10  and at epoch =  8  the loss is =  0.031098095700144768  and accuracy is =  0.4288\n",
            "At step  10  and at epoch =  9  the loss is =  0.024499936029314995  and accuracy is =  0.4458\n",
            "At step  10  and at epoch =  10  the loss is =  0.02655823342502117  and accuracy is =  0.4646\n",
            "At step  10  and at epoch =  11  the loss is =  0.020908288657665253  and accuracy is =  0.4794\n",
            "At step  10  and at epoch =  12  the loss is =  0.023898212239146233  and accuracy is =  0.4848\n",
            "At step  10  and at epoch =  13  the loss is =  0.028794148936867714  and accuracy is =  0.5054\n",
            "At step  10  and at epoch =  14  the loss is =  0.022632569074630737  and accuracy is =  0.5132\n",
            "At step  10  and at epoch =  15  the loss is =  0.022101745009422302  and accuracy is =  0.5186\n",
            "At step  10  and at epoch =  16  the loss is =  0.02601861022412777  and accuracy is =  0.5394\n",
            "At step  10  and at epoch =  17  the loss is =  0.023416852578520775  and accuracy is =  0.5486\n",
            "At step  10  and at epoch =  18  the loss is =  0.018187154084444046  and accuracy is =  0.5504\n",
            "At step  10  and at epoch =  19  the loss is =  0.01832408644258976  and accuracy is =  0.5598\n",
            "At step  10  and at epoch =  20  the loss is =  0.0209799837321043  and accuracy is =  0.5722\n",
            "At step  10  and at epoch =  21  the loss is =  0.030998140573501587  and accuracy is =  0.5802\n",
            "At step  10  and at epoch =  22  the loss is =  0.017182139679789543  and accuracy is =  0.5918\n",
            "At step  10  and at epoch =  23  the loss is =  0.025524472817778587  and accuracy is =  0.5976\n",
            "At step  10  and at epoch =  24  the loss is =  0.020460020750761032  and accuracy is =  0.612\n",
            "At step  10  and at epoch =  25  the loss is =  0.018084533512592316  and accuracy is =  0.6156\n",
            "At step  10  and at epoch =  26  the loss is =  0.013628573156893253  and accuracy is =  0.6318\n",
            "At step  10  and at epoch =  27  the loss is =  0.02149284817278385  and accuracy is =  0.6356\n",
            "At step  10  and at epoch =  28  the loss is =  0.015788795426487923  and accuracy is =  0.652\n",
            "At step  10  and at epoch =  29  the loss is =  0.030378462746739388  and accuracy is =  0.6576\n",
            "At step  10  and at epoch =  30  the loss is =  0.02750767208635807  and accuracy is =  0.6684\n",
            "At step  10  and at epoch =  31  the loss is =  0.020037688314914703  and accuracy is =  0.6744\n",
            "At step  10  and at epoch =  32  the loss is =  0.02039198763668537  and accuracy is =  0.6856\n",
            "At step  10  and at epoch =  33  the loss is =  0.021092098206281662  and accuracy is =  0.6982\n",
            "At step  10  and at epoch =  34  the loss is =  0.017983414232730865  and accuracy is =  0.7096\n",
            "At step  10  and at epoch =  35  the loss is =  0.02386149764060974  and accuracy is =  0.7082\n",
            "At step  10  and at epoch =  36  the loss is =  0.02609390765428543  and accuracy is =  0.7212\n",
            "At step  10  and at epoch =  37  the loss is =  0.02187686786055565  and accuracy is =  0.734\n",
            "At step  10  and at epoch =  38  the loss is =  0.017263781279325485  and accuracy is =  0.745\n",
            "At step  10  and at epoch =  39  the loss is =  0.017127515748143196  and accuracy is =  0.7474\n",
            "At step  10  and at epoch =  40  the loss is =  0.012286493554711342  and accuracy is =  0.7588\n",
            "At step  10  and at epoch =  41  the loss is =  0.011201421730220318  and accuracy is =  0.7704\n",
            "At step  10  and at epoch =  42  the loss is =  0.01405609492212534  and accuracy is =  0.7764\n",
            "At step  10  and at epoch =  43  the loss is =  0.015011250972747803  and accuracy is =  0.7844\n",
            "At step  10  and at epoch =  44  the loss is =  0.010867742821574211  and accuracy is =  0.7952\n",
            "At step  10  and at epoch =  45  the loss is =  0.01736002415418625  and accuracy is =  0.7998\n",
            "At step  10  and at epoch =  46  the loss is =  0.02608742192387581  and accuracy is =  0.8112\n",
            "At step  10  and at epoch =  47  the loss is =  0.008483662270009518  and accuracy is =  0.821\n",
            "At step  10  and at epoch =  48  the loss is =  0.012835146859288216  and accuracy is =  0.826\n",
            "At step  10  and at epoch =  49  the loss is =  0.014871122315526009  and accuracy is =  0.838\n",
            "At step  10  and at epoch =  50  the loss is =  0.019188927486538887  and accuracy is =  0.8414\n",
            "At step  10  and at epoch =  51  the loss is =  0.021740755066275597  and accuracy is =  0.8544\n",
            "At step  10  and at epoch =  52  the loss is =  0.01939823292195797  and accuracy is =  0.854\n",
            "At step  10  and at epoch =  53  the loss is =  0.011969027109444141  and accuracy is =  0.8612\n",
            "At step  10  and at epoch =  54  the loss is =  0.01180392224341631  and accuracy is =  0.8762\n",
            "At step  10  and at epoch =  55  the loss is =  0.01911603845655918  and accuracy is =  0.878\n",
            "At step  10  and at epoch =  56  the loss is =  0.008861901238560677  and accuracy is =  0.8822\n",
            "At step  10  and at epoch =  57  the loss is =  0.01762525364756584  and accuracy is =  0.8958\n",
            "At step  10  and at epoch =  58  the loss is =  0.014463181607425213  and accuracy is =  0.899\n",
            "At step  10  and at epoch =  59  the loss is =  0.011815980076789856  and accuracy is =  0.9058\n",
            "At step  10  and at epoch =  60  the loss is =  0.021559394896030426  and accuracy is =  0.9112\n",
            "At step  10  and at epoch =  61  the loss is =  0.014737343415617943  and accuracy is =  0.918\n",
            "At step  10  and at epoch =  62  the loss is =  0.01969074085354805  and accuracy is =  0.9274\n",
            "At step  10  and at epoch =  63  the loss is =  0.011277975514531136  and accuracy is =  0.9284\n",
            "At step  10  and at epoch =  64  the loss is =  0.014998745173215866  and accuracy is =  0.9352\n",
            "At step  10  and at epoch =  65  the loss is =  0.014181887730956078  and accuracy is =  0.9446\n",
            "At step  10  and at epoch =  66  the loss is =  0.01155303604900837  and accuracy is =  0.9468\n",
            "At step  10  and at epoch =  67  the loss is =  0.017258668318390846  and accuracy is =  0.9534\n",
            "At step  10  and at epoch =  68  the loss is =  0.009739022701978683  and accuracy is =  0.9582\n",
            "At step  10  and at epoch =  69  the loss is =  0.02269013039767742  and accuracy is =  0.958\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "80\n",
            "Validation Loss: 0.053177278488874435 Validation Accuracy : 0.3285\n",
            "At step  20  and at epoch =  0  the loss is =  0.08332700282335281  and accuracy is =  0.1442\n",
            "At step  20  and at epoch =  1  the loss is =  0.05934435874223709  and accuracy is =  0.1678\n",
            "At step  20  and at epoch =  2  the loss is =  0.036951079964637756  and accuracy is =  0.1926\n",
            "At step  20  and at epoch =  3  the loss is =  0.027719024568796158  and accuracy is =  0.26\n",
            "At step  20  and at epoch =  4  the loss is =  0.02672324888408184  and accuracy is =  0.3686\n",
            "At step  20  and at epoch =  5  the loss is =  0.026441846042871475  and accuracy is =  0.436\n",
            "At step  20  and at epoch =  6  the loss is =  0.028782252222299576  and accuracy is =  0.4622\n",
            "At step  20  and at epoch =  7  the loss is =  0.02017875574529171  and accuracy is =  0.4874\n",
            "At step  20  and at epoch =  8  the loss is =  0.025224413722753525  and accuracy is =  0.5048\n",
            "At step  20  and at epoch =  9  the loss is =  0.027601923793554306  and accuracy is =  0.525\n",
            "At step  20  and at epoch =  10  the loss is =  0.026888946071267128  and accuracy is =  0.5432\n",
            "At step  20  and at epoch =  11  the loss is =  0.019055146723985672  and accuracy is =  0.5502\n",
            "At step  20  and at epoch =  12  the loss is =  0.026330294087529182  and accuracy is =  0.5686\n",
            "At step  20  and at epoch =  13  the loss is =  0.02154112048447132  and accuracy is =  0.5816\n",
            "At step  20  and at epoch =  14  the loss is =  0.01742689311504364  and accuracy is =  0.6004\n",
            "At step  20  and at epoch =  15  the loss is =  0.02376685105264187  and accuracy is =  0.6078\n",
            "At step  20  and at epoch =  16  the loss is =  0.01996740512549877  and accuracy is =  0.6214\n",
            "At step  20  and at epoch =  17  the loss is =  0.014842631295323372  and accuracy is =  0.64\n",
            "At step  20  and at epoch =  18  the loss is =  0.02133019082248211  and accuracy is =  0.649\n",
            "At step  20  and at epoch =  19  the loss is =  0.01826619915664196  and accuracy is =  0.66\n",
            "At step  20  and at epoch =  20  the loss is =  0.012444344349205494  and accuracy is =  0.673\n",
            "At step  20  and at epoch =  21  the loss is =  0.02372228540480137  and accuracy is =  0.6834\n",
            "At step  20  and at epoch =  22  the loss is =  0.018010925501585007  and accuracy is =  0.6946\n",
            "At step  20  and at epoch =  23  the loss is =  0.01645098812878132  and accuracy is =  0.7092\n",
            "At step  20  and at epoch =  24  the loss is =  0.01282102894037962  and accuracy is =  0.7176\n",
            "At step  20  and at epoch =  25  the loss is =  0.024255013093352318  and accuracy is =  0.7234\n",
            "At step  20  and at epoch =  26  the loss is =  0.01565014384686947  and accuracy is =  0.7454\n",
            "At step  20  and at epoch =  27  the loss is =  0.025351915508508682  and accuracy is =  0.7538\n",
            "At step  20  and at epoch =  28  the loss is =  0.018082911148667336  and accuracy is =  0.7644\n",
            "At step  20  and at epoch =  29  the loss is =  0.015417358838021755  and accuracy is =  0.7706\n",
            "At step  20  and at epoch =  30  the loss is =  0.01797989197075367  and accuracy is =  0.779\n",
            "At step  20  and at epoch =  31  the loss is =  0.0232088603079319  and accuracy is =  0.7966\n",
            "At step  20  and at epoch =  32  the loss is =  0.02328634262084961  and accuracy is =  0.8024\n",
            "At step  20  and at epoch =  33  the loss is =  0.015827864408493042  and accuracy is =  0.819\n",
            "At step  20  and at epoch =  34  the loss is =  0.014657058753073215  and accuracy is =  0.8238\n",
            "At step  20  and at epoch =  35  the loss is =  0.020156674087047577  and accuracy is =  0.8388\n",
            "At step  20  and at epoch =  36  the loss is =  0.018070492893457413  and accuracy is =  0.8462\n",
            "At step  20  and at epoch =  37  the loss is =  0.02360142208635807  and accuracy is =  0.8554\n",
            "At step  20  and at epoch =  38  the loss is =  0.014657150022685528  and accuracy is =  0.8628\n",
            "At step  20  and at epoch =  39  the loss is =  0.012245397083461285  and accuracy is =  0.8718\n",
            "At step  20  and at epoch =  40  the loss is =  0.014037702232599258  and accuracy is =  0.8776\n",
            "At step  20  and at epoch =  41  the loss is =  0.011261668056249619  and accuracy is =  0.8876\n",
            "At step  20  and at epoch =  42  the loss is =  0.021571887657046318  and accuracy is =  0.8976\n",
            "At step  20  and at epoch =  43  the loss is =  0.012064683251082897  and accuracy is =  0.9036\n",
            "At step  20  and at epoch =  44  the loss is =  0.017722750082612038  and accuracy is =  0.9104\n",
            "At step  20  and at epoch =  45  the loss is =  0.01344958133995533  and accuracy is =  0.9162\n",
            "At step  20  and at epoch =  46  the loss is =  0.015235044993460178  and accuracy is =  0.9226\n",
            "At step  20  and at epoch =  47  the loss is =  0.021225914359092712  and accuracy is =  0.928\n",
            "At step  20  and at epoch =  48  the loss is =  0.02409621700644493  and accuracy is =  0.9346\n",
            "At step  20  and at epoch =  49  the loss is =  0.015126509591937065  and accuracy is =  0.9382\n",
            "At step  20  and at epoch =  50  the loss is =  0.01538905594497919  and accuracy is =  0.9382\n",
            "At step  20  and at epoch =  51  the loss is =  0.011438403278589249  and accuracy is =  0.9456\n",
            "At step  20  and at epoch =  52  the loss is =  0.005026998929679394  and accuracy is =  0.9522\n",
            "At step  20  and at epoch =  53  the loss is =  0.018087448552250862  and accuracy is =  0.9602\n",
            "At step  20  and at epoch =  54  the loss is =  0.017394063994288445  and accuracy is =  0.9582\n",
            "At step  20  and at epoch =  55  the loss is =  0.009476814419031143  and accuracy is =  0.9598\n",
            "At step  20  and at epoch =  56  the loss is =  0.011933987028896809  and accuracy is =  0.967\n",
            "At step  20  and at epoch =  57  the loss is =  0.007145141251385212  and accuracy is =  0.9684\n",
            "At step  20  and at epoch =  58  the loss is =  0.007835257798433304  and accuracy is =  0.9722\n",
            "At step  20  and at epoch =  59  the loss is =  0.0031858570873737335  and accuracy is =  0.9748\n",
            "At step  20  and at epoch =  60  the loss is =  0.014468327164649963  and accuracy is =  0.9766\n",
            "At step  20  and at epoch =  61  the loss is =  0.027951711788773537  and accuracy is =  0.9764\n",
            "At step  20  and at epoch =  62  the loss is =  0.009140322916209698  and accuracy is =  0.9828\n",
            "At step  20  and at epoch =  63  the loss is =  0.014031125232577324  and accuracy is =  0.9822\n",
            "At step  20  and at epoch =  64  the loss is =  0.004506862256675959  and accuracy is =  0.9832\n",
            "At step  20  and at epoch =  65  the loss is =  0.011659304611384869  and accuracy is =  0.987\n",
            "At step  20  and at epoch =  66  the loss is =  0.02002086117863655  and accuracy is =  0.9868\n",
            "At step  20  and at epoch =  67  the loss is =  0.004817931912839413  and accuracy is =  0.9896\n",
            "At step  20  and at epoch =  68  the loss is =  0.00896978285163641  and accuracy is =  0.9902\n",
            "At step  20  and at epoch =  69  the loss is =  0.006134858820587397  and accuracy is =  0.9906\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "56\n",
            "Validation Loss: 0.0700792595744133 Validation Accuracy : 0.19566666666666666\n",
            "At step  30  and at epoch =  0  the loss is =  0.08754169940948486  and accuracy is =  0.1226\n",
            "At step  30  and at epoch =  1  the loss is =  0.060731858015060425  and accuracy is =  0.1998\n",
            "At step  30  and at epoch =  2  the loss is =  0.035896752029657364  and accuracy is =  0.2618\n",
            "At step  30  and at epoch =  3  the loss is =  0.029079768806695938  and accuracy is =  0.3136\n",
            "At step  30  and at epoch =  4  the loss is =  0.026969997212290764  and accuracy is =  0.4346\n",
            "At step  30  and at epoch =  5  the loss is =  0.03379637002944946  and accuracy is =  0.4848\n",
            "At step  30  and at epoch =  6  the loss is =  0.02471804991364479  and accuracy is =  0.5168\n",
            "At step  30  and at epoch =  7  the loss is =  0.023180555552244186  and accuracy is =  0.5492\n",
            "At step  30  and at epoch =  8  the loss is =  0.0229421965777874  and accuracy is =  0.58\n",
            "At step  30  and at epoch =  9  the loss is =  0.021358082070946693  and accuracy is =  0.5886\n",
            "At step  30  and at epoch =  10  the loss is =  0.018675023689866066  and accuracy is =  0.6076\n",
            "At step  30  and at epoch =  11  the loss is =  0.021747974678874016  and accuracy is =  0.6258\n",
            "At step  30  and at epoch =  12  the loss is =  0.018300913274288177  and accuracy is =  0.641\n",
            "At step  30  and at epoch =  13  the loss is =  0.02074427157640457  and accuracy is =  0.6588\n",
            "At step  30  and at epoch =  14  the loss is =  0.024591676890850067  and accuracy is =  0.6728\n",
            "At step  30  and at epoch =  15  the loss is =  0.01908821240067482  and accuracy is =  0.6858\n",
            "At step  30  and at epoch =  16  the loss is =  0.02235804684460163  and accuracy is =  0.7042\n",
            "At step  30  and at epoch =  17  the loss is =  0.021287009119987488  and accuracy is =  0.7154\n",
            "At step  30  and at epoch =  18  the loss is =  0.01975489966571331  and accuracy is =  0.7376\n",
            "At step  30  and at epoch =  19  the loss is =  0.016710937023162842  and accuracy is =  0.756\n",
            "At step  30  and at epoch =  20  the loss is =  0.019905561581254005  and accuracy is =  0.769\n",
            "At step  30  and at epoch =  21  the loss is =  0.01195475086569786  and accuracy is =  0.7774\n",
            "At step  30  and at epoch =  22  the loss is =  0.017256250604987144  and accuracy is =  0.7938\n",
            "At step  30  and at epoch =  23  the loss is =  0.02056189812719822  and accuracy is =  0.8034\n",
            "At step  30  and at epoch =  24  the loss is =  0.02959870733320713  and accuracy is =  0.8206\n",
            "At step  30  and at epoch =  25  the loss is =  0.01958366297185421  and accuracy is =  0.8394\n",
            "At step  30  and at epoch =  26  the loss is =  0.01895677112042904  and accuracy is =  0.8436\n",
            "At step  30  and at epoch =  27  the loss is =  0.01822039857506752  and accuracy is =  0.8544\n",
            "At step  30  and at epoch =  28  the loss is =  0.02121342532336712  and accuracy is =  0.8636\n",
            "At step  30  and at epoch =  29  the loss is =  0.017680663615465164  and accuracy is =  0.8778\n",
            "At step  30  and at epoch =  30  the loss is =  0.010228480212390423  and accuracy is =  0.8888\n",
            "At step  30  and at epoch =  31  the loss is =  0.01630580797791481  and accuracy is =  0.898\n",
            "At step  30  and at epoch =  32  the loss is =  0.014658703468739986  and accuracy is =  0.9058\n",
            "At step  30  and at epoch =  33  the loss is =  0.01587473414838314  and accuracy is =  0.9128\n",
            "At step  30  and at epoch =  34  the loss is =  0.020150158554315567  and accuracy is =  0.9196\n",
            "At step  30  and at epoch =  35  the loss is =  0.008711987175047398  and accuracy is =  0.9262\n",
            "At step  30  and at epoch =  36  the loss is =  0.008692708797752857  and accuracy is =  0.9334\n",
            "At step  30  and at epoch =  37  the loss is =  0.017520835623145103  and accuracy is =  0.9434\n",
            "At step  30  and at epoch =  38  the loss is =  0.029347660019993782  and accuracy is =  0.943\n",
            "At step  30  and at epoch =  39  the loss is =  0.005615856032818556  and accuracy is =  0.956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pomxiRbnUNq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotTask(pars_tasks)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}