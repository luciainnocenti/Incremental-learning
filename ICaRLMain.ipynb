{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ICaRLMain.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2580e659a2af4176978c1951c7f0f1f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8eadfa62d70b41b399e4a38a1adfae2d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1356918af1cd457392b6f89fb41f2cf3",
              "IPY_MODEL_b0eca3ae84c9466a89ae2523347ce06b"
            ]
          }
        },
        "8eadfa62d70b41b399e4a38a1adfae2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1356918af1cd457392b6f89fb41f2cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_74a04d047d2445bd9ec23c6be4693029",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8adc3b0576ff4123a623be51264e2a3c"
          }
        },
        "b0eca3ae84c9466a89ae2523347ce06b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f15f76279f042f4b7288e5b907ab8a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169009152/? [00:20&lt;00:00, 53173958.59it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61e6087e72d64a2daae5fff0f960d4bc"
          }
        },
        "74a04d047d2445bd9ec23c6be4693029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8adc3b0576ff4123a623be51264e2a3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f15f76279f042f4b7288e5b907ab8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61e6087e72d64a2daae5fff0f960d4bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciainnocenti/IncrementalLearning/blob/daRunnareFrancy/ICaRLMain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLMLAOPyrR1K",
        "colab_type": "text"
      },
      "source": [
        "# Import GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LqwZJLUlcYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVa_FlnxrXIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "d53a3e6f-b624-41ec-881c-adde4c42933c"
      },
      "source": [
        "if not os.path.isdir('./DatasetCIFAR'):\n",
        "  !git clone -b daRunnareFrancy https://github.com/luciainnocenti/IncrementalLearning.git\n",
        "  !mv 'IncrementalLearning' 'DatasetCIFAR'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IncrementalLearning'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 1552 (delta 30), reused 0 (delta 0), pack-reused 1499\u001b[K\n",
            "Receiving objects: 100% (1552/1552), 1016.68 KiB | 23.11 MiB/s, done.\n",
            "Resolving deltas: 100% (994/994), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXQyHMXzrZ5A",
        "colab_type": "text"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c24pdNxurdv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from DatasetCIFAR.data_set import Dataset \n",
        "from DatasetCIFAR.data_set import Subset\n",
        "from DatasetCIFAR import ResNet\n",
        "from DatasetCIFAR import utils\n",
        "from DatasetCIFAR import params\n",
        "from DatasetCIFAR import ICaRLModel\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import functional as F\n",
        "import random\n",
        "random.seed(params.SEED)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2rkcBbIKfUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a4f23d60-a192-4e58-e1ec-3f99f8371007"
      },
      "source": [
        "print(params.SEED)\n",
        "print(params.NUM_WORKERS)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "653\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FlAkShyryrf",
        "colab_type": "text"
      },
      "source": [
        "# Define Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP2iR2vl3Wiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transformer = transforms.Compose([transforms.RandomCrop(size = 32, padding=4),\n",
        "                                         transforms.RandomHorizontalFlip(),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transformer = transforms.Compose([transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CSNk0NlrvAL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "2580e659a2af4176978c1951c7f0f1f2",
            "8eadfa62d70b41b399e4a38a1adfae2d",
            "1356918af1cd457392b6f89fb41f2cf3",
            "b0eca3ae84c9466a89ae2523347ce06b",
            "74a04d047d2445bd9ec23c6be4693029",
            "8adc3b0576ff4123a623be51264e2a3c",
            "3f15f76279f042f4b7288e5b907ab8a1",
            "61e6087e72d64a2daae5fff0f960d4bc"
          ]
        },
        "outputId": "821a6ea1-993a-45a6-ab7e-b372996a79cb"
      },
      "source": [
        "trainDS = Dataset(train=True)\n",
        "testDS = Dataset(train=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2580e659a2af4176978c1951c7f0f1f2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3ge3VayryJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_splits = trainDS.splits\n",
        "test_splits = testDS.splits"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzxTlFF_rkfe",
        "colab_type": "text"
      },
      "source": [
        "# Define Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgZtPkiPrmQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ICaRL = ResNet.resnet32(num_classes=100)\n",
        "ICaRL =  ICaRL.to(params.DEVICE)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI8EyFmpOikN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exemplars = [None]*100\n",
        "\n",
        "test_indexes =  []"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcFjbBGrOMz6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f07ad41-e65c-4985-c705-e9ce77f6dabb"
      },
      "source": [
        "for task in range(0, 100, params.TASK_SIZE):\n",
        "  train_indexes = trainDS.__getIndexesGroups__(task)\n",
        "  test_indexes = test_indexes + testDS.__getIndexesGroups__(task)\n",
        "\n",
        "  train_dataset = Subset(trainDS, train_indexes, transform = train_transformer)\n",
        "  test_dataset = Subset(testDS, test_indexes, transform = test_transformer)\n",
        "\n",
        "  train_loader = DataLoader( train_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE, shuffle=True)\n",
        "  test_loader = DataLoader( test_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE , shuffle=True )\n",
        "  \n",
        "  ICaRL, exemplars = ICaRLModel.incrementalTrain(task, trainDS, ICaRL, exemplars, train_transformer)\n",
        "\n",
        "  col = []\n",
        "  for i,x in enumerate( train_splits[ :int(task/10) + 1]) : \n",
        "    v = np.array(x)\n",
        "    col = np.concatenate( (col,v), axis = None)\n",
        "    col = col.astype(int)\n",
        "  mean = None\n",
        "  total = 0.0\n",
        "  running_corrects = 0.0\n",
        "  for img, lbl, _ in train_loader:\n",
        "      img = img.float().to(params.DEVICE)\n",
        "      preds, mean = ICaRLModel.classify(img, exemplars, ICaRL, task, trainDS, mean)\n",
        "      preds = preds.to(params.DEVICE)\n",
        "      labels = utils.mapFunction(lbl, col).to(params.DEVICE)\n",
        "\n",
        "      total += len(lbl)\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "  accuracy = float(running_corrects/total)\n",
        "  print(f'task: {task}', f'train accuracy = {accuracy}')\n",
        "\n",
        "  total = 0.0\n",
        "  running_corrects = 0.0\n",
        "  for img, lbl, _ in test_loader:\n",
        "      img = img.float().to(params.DEVICE)\n",
        "      preds, _ = ICaRLModel.classify(img, exemplars, ICaRL, task, trainDS, mean)\n",
        "      preds = preds.to(params.DEVICE)\n",
        "      labels = utils.mapFunction(lbl, col).to(params.DEVICE)\n",
        "\n",
        "      total += len(lbl)\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "  accuracy = float(running_corrects/total)\n",
        "  print(f'task: {task}', f'test accuracy = {accuracy}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "At step  0  and at epoch =  0  the loss is =  0.030729804188013077  and accuracy is =  0.17\n",
            "At step  0  and at epoch =  1  the loss is =  0.028716010972857475  and accuracy is =  0.3508\n",
            "At step  0  and at epoch =  2  the loss is =  0.024211449548602104  and accuracy is =  0.4414\n",
            "At step  0  and at epoch =  3  the loss is =  0.020557448267936707  and accuracy is =  0.5018\n",
            "At step  0  and at epoch =  4  the loss is =  0.02769937925040722  and accuracy is =  0.56\n",
            "At step  0  and at epoch =  5  the loss is =  0.012778152711689472  and accuracy is =  0.589\n",
            "At step  0  and at epoch =  6  the loss is =  0.011257588863372803  and accuracy is =  0.6296\n",
            "At step  0  and at epoch =  7  the loss is =  0.012235315516591072  and accuracy is =  0.6604\n",
            "At step  0  and at epoch =  8  the loss is =  0.01599155366420746  and accuracy is =  0.661\n",
            "At step  0  and at epoch =  9  the loss is =  0.009063873440027237  and accuracy is =  0.696\n",
            "At step  0  and at epoch =  10  the loss is =  0.01519876066595316  and accuracy is =  0.728\n",
            "At step  0  and at epoch =  11  the loss is =  0.022770237177610397  and accuracy is =  0.714\n",
            "At step  0  and at epoch =  12  the loss is =  0.02455729991197586  and accuracy is =  0.72\n",
            "At step  0  and at epoch =  13  the loss is =  0.040818408131599426  and accuracy is =  0.7366\n",
            "At step  0  and at epoch =  14  the loss is =  0.018693380057811737  and accuracy is =  0.7396\n",
            "At step  0  and at epoch =  15  the loss is =  0.026208311319351196  and accuracy is =  0.757\n",
            "At step  0  and at epoch =  16  the loss is =  0.01830093376338482  and accuracy is =  0.7634\n",
            "At step  0  and at epoch =  17  the loss is =  0.014710596762597561  and accuracy is =  0.7606\n",
            "At step  0  and at epoch =  18  the loss is =  0.01118820533156395  and accuracy is =  0.8002\n",
            "At step  0  and at epoch =  19  the loss is =  0.014624346978962421  and accuracy is =  0.7984\n",
            "At step  0  and at epoch =  20  the loss is =  0.018264388665556908  and accuracy is =  0.81\n",
            "At step  0  and at epoch =  21  the loss is =  0.02104571834206581  and accuracy is =  0.8122\n",
            "At step  0  and at epoch =  22  the loss is =  0.0037155693862587214  and accuracy is =  0.8244\n",
            "At step  0  and at epoch =  23  the loss is =  0.0024794847704470158  and accuracy is =  0.8304\n",
            "At step  0  and at epoch =  24  the loss is =  0.00880408938974142  and accuracy is =  0.855\n",
            "At step  0  and at epoch =  25  the loss is =  0.020849499851465225  and accuracy is =  0.8422\n",
            "At step  0  and at epoch =  26  the loss is =  0.012184836901724339  and accuracy is =  0.8338\n",
            "At step  0  and at epoch =  27  the loss is =  0.030547793954610825  and accuracy is =  0.825\n",
            "At step  0  and at epoch =  28  the loss is =  0.010411343537271023  and accuracy is =  0.8216\n",
            "At step  0  and at epoch =  29  the loss is =  0.015307909809052944  and accuracy is =  0.8408\n",
            "At step  0  and at epoch =  30  the loss is =  0.017188003286719322  and accuracy is =  0.8526\n",
            "At step  0  and at epoch =  31  the loss is =  0.013091799803078175  and accuracy is =  0.8538\n",
            "At step  0  and at epoch =  32  the loss is =  0.01181762758642435  and accuracy is =  0.8538\n",
            "At step  0  and at epoch =  33  the loss is =  0.02996334433555603  and accuracy is =  0.8778\n",
            "At step  0  and at epoch =  34  the loss is =  0.014646983705461025  and accuracy is =  0.848\n",
            "At step  0  and at epoch =  35  the loss is =  0.018310176208615303  and accuracy is =  0.8668\n",
            "At step  0  and at epoch =  36  the loss is =  0.006383701227605343  and accuracy is =  0.86\n",
            "At step  0  and at epoch =  37  the loss is =  0.006668906193226576  and accuracy is =  0.8892\n",
            "At step  0  and at epoch =  38  the loss is =  0.021303823217749596  and accuracy is =  0.8862\n",
            "At step  0  and at epoch =  39  the loss is =  0.010211928747594357  and accuracy is =  0.8464\n",
            "At step  0  and at epoch =  40  the loss is =  0.004797092638909817  and accuracy is =  0.8858\n",
            "At step  0  and at epoch =  41  the loss is =  0.006320221349596977  and accuracy is =  0.8936\n",
            "At step  0  and at epoch =  42  the loss is =  0.01034137699753046  and accuracy is =  0.9002\n",
            "At step  0  and at epoch =  43  the loss is =  0.017063364386558533  and accuracy is =  0.8852\n",
            "At step  0  and at epoch =  44  the loss is =  0.002921219915151596  and accuracy is =  0.8784\n",
            "At step  0  and at epoch =  45  the loss is =  0.00477262306958437  and accuracy is =  0.9108\n",
            "At step  0  and at epoch =  46  the loss is =  0.014662892557680607  and accuracy is =  0.9112\n",
            "At step  0  and at epoch =  47  the loss is =  0.004156898241490126  and accuracy is =  0.9134\n",
            "At step  0  and at epoch =  48  the loss is =  0.005564896855503321  and accuracy is =  0.9102\n",
            "At step  0  and at epoch =  49  the loss is =  0.02018304541707039  and accuracy is =  0.9304\n",
            "At step  0  and at epoch =  50  the loss is =  0.005786295514553785  and accuracy is =  0.9448\n",
            "At step  0  and at epoch =  51  the loss is =  0.00997336208820343  and accuracy is =  0.9582\n",
            "At step  0  and at epoch =  52  the loss is =  0.004077243618667126  and accuracy is =  0.9526\n",
            "At step  0  and at epoch =  53  the loss is =  0.007925097830593586  and accuracy is =  0.9528\n",
            "At step  0  and at epoch =  54  the loss is =  0.027751317247748375  and accuracy is =  0.9598\n",
            "At step  0  and at epoch =  55  the loss is =  0.0006889835349284112  and accuracy is =  0.952\n",
            "At step  0  and at epoch =  56  the loss is =  0.006922826636582613  and accuracy is =  0.9632\n",
            "At step  0  and at epoch =  57  the loss is =  0.004264947026968002  and accuracy is =  0.959\n",
            "At step  0  and at epoch =  58  the loss is =  0.001839962205849588  and accuracy is =  0.9668\n",
            "At step  0  and at epoch =  59  the loss is =  0.005231001414358616  and accuracy is =  0.9676\n",
            "At step  0  and at epoch =  60  the loss is =  0.010599170811474323  and accuracy is =  0.963\n",
            "At step  0  and at epoch =  61  the loss is =  0.007640664465725422  and accuracy is =  0.9654\n",
            "At step  0  and at epoch =  62  the loss is =  0.005663628224283457  and accuracy is =  0.9646\n",
            "At step  0  and at epoch =  63  the loss is =  0.0065867225639522076  and accuracy is =  0.973\n",
            "At step  0  and at epoch =  64  the loss is =  0.00575387105345726  and accuracy is =  0.9736\n",
            "At step  0  and at epoch =  65  the loss is =  0.007060281932353973  and accuracy is =  0.978\n",
            "At step  0  and at epoch =  66  the loss is =  0.010174314491450787  and accuracy is =  0.9776\n",
            "At step  0  and at epoch =  67  the loss is =  0.006373797543346882  and accuracy is =  0.9734\n",
            "At step  0  and at epoch =  68  the loss is =  0.005490942392498255  and accuracy is =  0.9746\n",
            "At step  0  and at epoch =  69  the loss is =  0.01306227408349514  and accuracy is =  0.9782\n",
            "task: 0 train accuracy = 0.9822\n",
            "task: 0 test accuracy = 0.883\n",
            "At step  10  and at epoch =  0  the loss is =  0.03474899008870125  and accuracy is =  0.3078459343794579\n",
            "At step  10  and at epoch =  1  the loss is =  0.024885602295398712  and accuracy is =  0.3970042796005706\n",
            "At step  10  and at epoch =  2  the loss is =  0.02354881726205349  and accuracy is =  0.48687589158345224\n",
            "At step  10  and at epoch =  3  the loss is =  0.024920454248785973  and accuracy is =  0.5479315263908702\n",
            "At step  10  and at epoch =  4  the loss is =  0.02164551429450512  and accuracy is =  0.5877318116975749\n",
            "At step  10  and at epoch =  5  the loss is =  0.022641140967607498  and accuracy is =  0.6102710413694722\n",
            "At step  10  and at epoch =  6  the loss is =  0.02127636969089508  and accuracy is =  0.6379457917261055\n",
            "At step  10  and at epoch =  7  the loss is =  0.01953376643359661  and accuracy is =  0.6589158345221112\n",
            "At step  10  and at epoch =  8  the loss is =  0.02242574654519558  and accuracy is =  0.6670470756062767\n",
            "At step  10  and at epoch =  9  the loss is =  0.02393816038966179  and accuracy is =  0.6880171184022824\n",
            "At step  10  and at epoch =  10  the loss is =  0.02008775994181633  and accuracy is =  0.7019971469329529\n",
            "At step  10  and at epoch =  11  the loss is =  0.02018626593053341  and accuracy is =  0.7075606276747504\n",
            "At step  10  and at epoch =  12  the loss is =  0.021505603566765785  and accuracy is =  0.7232524964336662\n",
            "At step  10  and at epoch =  13  the loss is =  0.01995575800538063  and accuracy is =  0.733095577746077\n",
            "At step  10  and at epoch =  14  the loss is =  0.01872725412249565  and accuracy is =  0.7425106990014265\n",
            "At step  10  and at epoch =  15  the loss is =  0.01934666372835636  and accuracy is =  0.7496433666191156\n",
            "At step  10  and at epoch =  16  the loss is =  0.01956881210207939  and accuracy is =  0.7432239657631954\n",
            "At step  10  and at epoch =  17  the loss is =  0.020919952541589737  and accuracy is =  0.7644793152639087\n",
            "At step  10  and at epoch =  18  the loss is =  0.021378634497523308  and accuracy is =  0.769472182596291\n",
            "At step  10  and at epoch =  19  the loss is =  0.016450265422463417  and accuracy is =  0.7718972895863053\n",
            "At step  10  and at epoch =  20  the loss is =  0.02197514846920967  and accuracy is =  0.7754636233951497\n",
            "At step  10  and at epoch =  21  the loss is =  0.01744706742465496  and accuracy is =  0.7827389443651925\n",
            "At step  10  and at epoch =  22  the loss is =  0.018543187528848648  and accuracy is =  0.7871611982881598\n",
            "At step  10  and at epoch =  23  the loss is =  0.02020745538175106  and accuracy is =  0.7918687589158345\n",
            "At step  10  and at epoch =  24  the loss is =  0.01774481311440468  and accuracy is =  0.8009985734664765\n",
            "At step  10  and at epoch =  25  the loss is =  0.02015506476163864  and accuracy is =  0.8008559201141227\n",
            "At step  10  and at epoch =  26  the loss is =  0.02245231345295906  and accuracy is =  0.8161198288159772\n",
            "At step  10  and at epoch =  27  the loss is =  0.022550947964191437  and accuracy is =  0.8108416547788873\n",
            "At step  10  and at epoch =  28  the loss is =  0.019370201975107193  and accuracy is =  0.8154065620542083\n",
            "At step  10  and at epoch =  29  the loss is =  0.02042507380247116  and accuracy is =  0.8203994293865906\n",
            "At step  10  and at epoch =  30  the loss is =  0.017789030447602272  and accuracy is =  0.8241084165477889\n",
            "At step  10  and at epoch =  31  the loss is =  0.01783321425318718  and accuracy is =  0.827246790299572\n",
            "At step  10  and at epoch =  32  the loss is =  0.01657436229288578  and accuracy is =  0.8303851640513552\n",
            "At step  10  and at epoch =  33  the loss is =  0.017192773520946503  and accuracy is =  0.8266761768901569\n",
            "At step  10  and at epoch =  34  the loss is =  0.01714569330215454  and accuracy is =  0.8323823109843081\n",
            "At step  10  and at epoch =  35  the loss is =  0.017598440870642662  and accuracy is =  0.8409415121255349\n",
            "At step  10  and at epoch =  36  the loss is =  0.01575898751616478  and accuracy is =  0.8308131241084166\n",
            "At step  10  and at epoch =  37  the loss is =  0.0169028639793396  and accuracy is =  0.8487874465049928\n",
            "At step  10  and at epoch =  38  the loss is =  0.015684276819229126  and accuracy is =  0.8398002853067047\n",
            "At step  10  and at epoch =  39  the loss is =  0.019987646490335464  and accuracy is =  0.8412268188302425\n",
            "At step  10  and at epoch =  40  the loss is =  0.01954207755625248  and accuracy is =  0.846077032810271\n",
            "At step  10  and at epoch =  41  the loss is =  0.01631048135459423  and accuracy is =  0.8620542082738945\n",
            "At step  10  and at epoch =  42  the loss is =  0.01659846492111683  and accuracy is =  0.8540656205420828\n",
            "At step  10  and at epoch =  43  the loss is =  0.015313303098082542  and accuracy is =  0.8616262482168331\n",
            "At step  10  and at epoch =  44  the loss is =  0.017138253897428513  and accuracy is =  0.8643366619115549\n",
            "At step  10  and at epoch =  45  the loss is =  0.015733489766716957  and accuracy is =  0.8601997146932953\n",
            "At step  10  and at epoch =  46  the loss is =  0.01747029833495617  and accuracy is =  0.8601997146932953\n",
            "At step  10  and at epoch =  47  the loss is =  0.016824642196297646  and accuracy is =  0.8643366619115549\n",
            "At step  10  and at epoch =  48  the loss is =  0.016123706474900246  and accuracy is =  0.8687589158345221\n",
            "At step  10  and at epoch =  49  the loss is =  0.0147479809820652  and accuracy is =  0.9008559201141226\n",
            "At step  10  and at epoch =  50  the loss is =  0.011668041348457336  and accuracy is =  0.9174037089871612\n",
            "At step  10  and at epoch =  51  the loss is =  0.013966288417577744  and accuracy is =  0.9203994293865906\n",
            "At step  10  and at epoch =  52  the loss is =  0.012448064051568508  and accuracy is =  0.92339514978602\n",
            "At step  10  and at epoch =  53  the loss is =  0.013274360448122025  and accuracy is =  0.9211126961483594\n",
            "At step  10  and at epoch =  54  the loss is =  0.011979709379374981  and accuracy is =  0.9278174037089871\n",
            "At step  10  and at epoch =  55  the loss is =  0.013710196129977703  and accuracy is =  0.9295292439372326\n",
            "At step  10  and at epoch =  56  the loss is =  0.011482219211757183  and accuracy is =  0.9298145506419401\n",
            "At step  10  and at epoch =  57  the loss is =  0.01270384807139635  and accuracy is =  0.9366619115549215\n",
            "At step  10  and at epoch =  58  the loss is =  0.013530852273106575  and accuracy is =  0.9366619115549215\n",
            "At step  10  and at epoch =  59  the loss is =  0.011424430646002293  and accuracy is =  0.9365192582025678\n",
            "At step  10  and at epoch =  60  the loss is =  0.01279369369149208  and accuracy is =  0.9409415121255349\n",
            "At step  10  and at epoch =  61  the loss is =  0.014465908519923687  and accuracy is =  0.940228245363766\n",
            "At step  10  and at epoch =  62  the loss is =  0.013528809882700443  and accuracy is =  0.9332382310984308\n",
            "At step  10  and at epoch =  63  the loss is =  0.01166630070656538  and accuracy is =  0.9426533523537803\n",
            "At step  10  and at epoch =  64  the loss is =  0.012127596884965897  and accuracy is =  0.9446504992867333\n",
            "At step  10  and at epoch =  65  the loss is =  0.011544259265065193  and accuracy is =  0.9436519258202568\n",
            "At step  10  and at epoch =  66  the loss is =  0.012751499190926552  and accuracy is =  0.9455064194008559\n",
            "At step  10  and at epoch =  67  the loss is =  0.013234206475317478  and accuracy is =  0.9433666191155492\n",
            "At step  10  and at epoch =  68  the loss is =  0.011933133006095886  and accuracy is =  0.9499286733238231\n",
            "At step  10  and at epoch =  69  the loss is =  0.012884063646197319  and accuracy is =  0.9452211126961484\n",
            "task: 10 train accuracy = 0.959\n",
            "task: 10 test accuracy = 0.8095\n",
            "At step  20  and at epoch =  0  the loss is =  0.039869289845228195  and accuracy is =  0.26695156695156697\n",
            "At step  20  and at epoch =  1  the loss is =  0.03437227010726929  and accuracy is =  0.34444444444444444\n",
            "At step  20  and at epoch =  2  the loss is =  0.03805330768227577  and accuracy is =  0.4455840455840456\n",
            "At step  20  and at epoch =  3  the loss is =  0.03437872976064682  and accuracy is =  0.5102564102564102\n",
            "At step  20  and at epoch =  4  the loss is =  0.03237656131386757  and accuracy is =  0.5471509971509971\n",
            "At step  20  and at epoch =  5  the loss is =  0.033134233206510544  and accuracy is =  0.5696581196581196\n",
            "At step  20  and at epoch =  6  the loss is =  0.034334082156419754  and accuracy is =  0.5964387464387464\n",
            "At step  20  and at epoch =  7  the loss is =  0.032765354961156845  and accuracy is =  0.6269230769230769\n",
            "At step  20  and at epoch =  8  the loss is =  0.0316363200545311  and accuracy is =  0.648005698005698\n",
            "At step  20  and at epoch =  9  the loss is =  0.02959759160876274  and accuracy is =  0.6646723646723647\n",
            "At step  20  and at epoch =  10  the loss is =  0.028153060004115105  and accuracy is =  0.6713675213675213\n",
            "At step  20  and at epoch =  11  the loss is =  0.03234948217868805  and accuracy is =  0.6901709401709402\n",
            "At step  20  and at epoch =  12  the loss is =  0.030001791194081306  and accuracy is =  0.697008547008547\n",
            "At step  20  and at epoch =  13  the loss is =  0.030354175716638565  and accuracy is =  0.7002849002849003\n",
            "At step  20  and at epoch =  14  the loss is =  0.030315108597278595  and accuracy is =  0.7126780626780627\n",
            "At step  20  and at epoch =  15  the loss is =  0.030332161113619804  and accuracy is =  0.7311965811965812\n",
            "At step  20  and at epoch =  16  the loss is =  0.02819574996829033  and accuracy is =  0.7254985754985755\n",
            "At step  20  and at epoch =  17  the loss is =  0.030732693150639534  and accuracy is =  0.7394586894586894\n",
            "At step  20  and at epoch =  18  the loss is =  0.02969096228480339  and accuracy is =  0.7502849002849002\n",
            "At step  20  and at epoch =  19  the loss is =  0.029713891446590424  and accuracy is =  0.7494301994301994\n",
            "At step  20  and at epoch =  20  the loss is =  0.029008733108639717  and accuracy is =  0.7598290598290598\n",
            "At step  20  and at epoch =  21  the loss is =  0.030383063480257988  and accuracy is =  0.7632478632478632\n",
            "At step  20  and at epoch =  22  the loss is =  0.0291243027895689  and accuracy is =  0.7616809116809117\n",
            "At step  20  and at epoch =  23  the loss is =  0.02962324395775795  and accuracy is =  0.7772079772079772\n",
            "At step  20  and at epoch =  24  the loss is =  0.02739410474896431  and accuracy is =  0.7841880341880342\n",
            "At step  20  and at epoch =  25  the loss is =  0.02877269871532917  and accuracy is =  0.777920227920228\n",
            "At step  20  and at epoch =  26  the loss is =  0.026432115584611893  and accuracy is =  0.7833333333333333\n",
            "At step  20  and at epoch =  27  the loss is =  0.025208409875631332  and accuracy is =  0.7843304843304844\n",
            "At step  20  and at epoch =  28  the loss is =  0.025551384314894676  and accuracy is =  0.7905982905982906\n",
            "At step  20  and at epoch =  29  the loss is =  0.027422044426202774  and accuracy is =  0.799002849002849\n",
            "At step  20  and at epoch =  30  the loss is =  0.02835235558450222  and accuracy is =  0.8005698005698005\n",
            "At step  20  and at epoch =  31  the loss is =  0.027286672964692116  and accuracy is =  0.793019943019943\n",
            "At step  20  and at epoch =  32  the loss is =  0.027208885177969933  and accuracy is =  0.8066951566951567\n",
            "At step  20  and at epoch =  33  the loss is =  0.029334766790270805  and accuracy is =  0.8086894586894587\n",
            "At step  20  and at epoch =  34  the loss is =  0.027065051719546318  and accuracy is =  0.8037037037037037\n",
            "At step  20  and at epoch =  35  the loss is =  0.027683919295668602  and accuracy is =  0.8222222222222222\n",
            "At step  20  and at epoch =  36  the loss is =  0.027948975563049316  and accuracy is =  0.8226495726495726\n",
            "At step  20  and at epoch =  37  the loss is =  0.024927543476223946  and accuracy is =  0.8179487179487179\n",
            "At step  20  and at epoch =  38  the loss is =  0.026256734505295753  and accuracy is =  0.8112535612535613\n",
            "At step  20  and at epoch =  39  the loss is =  0.025897782295942307  and accuracy is =  0.83005698005698\n",
            "At step  20  and at epoch =  40  the loss is =  0.02579433098435402  and accuracy is =  0.8280626780626781\n",
            "At step  20  and at epoch =  41  the loss is =  0.02424095757305622  and accuracy is =  0.8316239316239317\n",
            "At step  20  and at epoch =  42  the loss is =  0.028272798284888268  and accuracy is =  0.82991452991453\n",
            "At step  20  and at epoch =  43  the loss is =  0.02525325119495392  and accuracy is =  0.8277777777777777\n",
            "At step  20  and at epoch =  44  the loss is =  0.026942703872919083  and accuracy is =  0.836039886039886\n",
            "At step  20  and at epoch =  45  the loss is =  0.026621336117386818  and accuracy is =  0.8353276353276353\n",
            "At step  20  and at epoch =  46  the loss is =  0.02784355916082859  and accuracy is =  0.8405982905982906\n",
            "At step  20  and at epoch =  47  the loss is =  0.026846975088119507  and accuracy is =  0.844017094017094\n",
            "At step  20  and at epoch =  48  the loss is =  0.025492390617728233  and accuracy is =  0.8437321937321938\n",
            "At step  20  and at epoch =  49  the loss is =  0.022680457681417465  and accuracy is =  0.8716524216524216\n",
            "At step  20  and at epoch =  50  the loss is =  0.02341945469379425  and accuracy is =  0.8833333333333333\n",
            "At step  20  and at epoch =  51  the loss is =  0.021378368139266968  and accuracy is =  0.892022792022792\n",
            "At step  20  and at epoch =  52  the loss is =  0.02269597165286541  and accuracy is =  0.8945868945868946\n",
            "At step  20  and at epoch =  53  the loss is =  0.02419240027666092  and accuracy is =  0.8977207977207977\n",
            "At step  20  and at epoch =  54  the loss is =  0.02096753939986229  and accuracy is =  0.8974358974358975\n",
            "At step  20  and at epoch =  55  the loss is =  0.021411454305052757  and accuracy is =  0.8907407407407407\n",
            "At step  20  and at epoch =  56  the loss is =  0.021324358880519867  and accuracy is =  0.9014245014245015\n",
            "At step  20  and at epoch =  57  the loss is =  0.024147111922502518  and accuracy is =  0.899002849002849\n",
            "At step  20  and at epoch =  58  the loss is =  0.02125760167837143  and accuracy is =  0.9071225071225071\n",
            "At step  20  and at epoch =  59  the loss is =  0.023272139951586723  and accuracy is =  0.9101139601139601\n",
            "At step  20  and at epoch =  60  the loss is =  0.022007392719388008  and accuracy is =  0.905982905982906\n",
            "At step  20  and at epoch =  61  the loss is =  0.020734470337629318  and accuracy is =  0.9054131054131054\n",
            "At step  20  and at epoch =  62  the loss is =  0.02114899642765522  and accuracy is =  0.9102564102564102\n",
            "At step  20  and at epoch =  63  the loss is =  0.022210726514458656  and accuracy is =  0.9121082621082621\n",
            "At step  20  and at epoch =  64  the loss is =  0.02152353711426258  and accuracy is =  0.9146723646723647\n",
            "At step  20  and at epoch =  65  the loss is =  0.02055630087852478  and accuracy is =  0.9168091168091168\n",
            "At step  20  and at epoch =  66  the loss is =  0.02076413668692112  and accuracy is =  0.9118233618233619\n",
            "At step  20  and at epoch =  67  the loss is =  0.02012665756046772  and accuracy is =  0.9210826210826211\n",
            "At step  20  and at epoch =  68  the loss is =  0.020791757851839066  and accuracy is =  0.9125356125356126\n",
            "At step  20  and at epoch =  69  the loss is =  0.02240864560008049  and accuracy is =  0.9160968660968661\n",
            "task: 20 train accuracy = 0.9172\n",
            "task: 20 test accuracy = 0.7576666666666667\n",
            "At step  30  and at epoch =  0  the loss is =  0.04255266487598419  and accuracy is =  0.2804564907275321\n",
            "At step  30  and at epoch =  1  the loss is =  0.042686063796281815  and accuracy is =  0.3700427960057061\n",
            "At step  30  and at epoch =  2  the loss is =  0.04531869664788246  and accuracy is =  0.45620542082738946\n",
            "At step  30  and at epoch =  3  the loss is =  0.040309686213731766  and accuracy is =  0.5057061340941512\n",
            "At step  30  and at epoch =  4  the loss is =  0.04140576347708702  and accuracy is =  0.5416547788873038\n",
            "At step  30  and at epoch =  5  the loss is =  0.04302891343832016  and accuracy is =  0.5691868758915835\n",
            "At step  30  and at epoch =  6  the loss is =  0.04361282289028168  and accuracy is =  0.5917261055634807\n",
            "At step  30  and at epoch =  7  the loss is =  0.04106638953089714  and accuracy is =  0.6067047075606277\n",
            "At step  30  and at epoch =  8  the loss is =  0.03793530911207199  and accuracy is =  0.6291012838801712\n",
            "At step  30  and at epoch =  9  the loss is =  0.04068942368030548  and accuracy is =  0.6328102710413694\n",
            "At step  30  and at epoch =  10  the loss is =  0.038287945091724396  and accuracy is =  0.6373751783166904\n",
            "At step  30  and at epoch =  11  the loss is =  0.0404173843562603  and accuracy is =  0.6634807417974322\n",
            "At step  30  and at epoch =  12  the loss is =  0.03954625502228737  and accuracy is =  0.6634807417974322\n",
            "At step  30  and at epoch =  13  the loss is =  0.0393562838435173  and accuracy is =  0.6750356633380884\n",
            "At step  30  and at epoch =  14  the loss is =  0.03890445828437805  and accuracy is =  0.6890156918687589\n",
            "At step  30  and at epoch =  15  the loss is =  0.03617226332426071  and accuracy is =  0.6957203994293866\n",
            "At step  30  and at epoch =  16  the loss is =  0.03507637605071068  and accuracy is =  0.7\n",
            "At step  30  and at epoch =  17  the loss is =  0.034969110041856766  and accuracy is =  0.7011412268188303\n",
            "At step  30  and at epoch =  18  the loss is =  0.03921832516789436  and accuracy is =  0.7022824536376605\n",
            "At step  30  and at epoch =  19  the loss is =  0.03490850329399109  and accuracy is =  0.7198288159771755\n",
            "At step  30  and at epoch =  20  the loss is =  0.03654523193836212  and accuracy is =  0.7251069900142654\n",
            "At step  30  and at epoch =  21  the loss is =  0.0336943194270134  and accuracy is =  0.7205420827389444\n",
            "At step  30  and at epoch =  22  the loss is =  0.039342593401670456  and accuracy is =  0.7295292439372325\n",
            "At step  30  and at epoch =  23  the loss is =  0.03903539478778839  and accuracy is =  0.7328102710413694\n",
            "At step  30  and at epoch =  24  the loss is =  0.035207852721214294  and accuracy is =  0.7417974322396577\n",
            "At step  30  and at epoch =  25  the loss is =  0.03848029673099518  and accuracy is =  0.748074179743224\n",
            "At step  30  and at epoch =  26  the loss is =  0.037325989454984665  and accuracy is =  0.7573466476462197\n",
            "At step  30  and at epoch =  27  the loss is =  0.03381792828440666  and accuracy is =  0.7589158345221113\n",
            "At step  30  and at epoch =  28  the loss is =  0.037545494735240936  and accuracy is =  0.762339514978602\n",
            "At step  30  and at epoch =  29  the loss is =  0.03589567914605141  and accuracy is =  0.7676176890156918\n",
            "At step  30  and at epoch =  30  the loss is =  0.0362357497215271  and accuracy is =  0.7676176890156918\n",
            "At step  30  and at epoch =  31  the loss is =  0.03645206242799759  and accuracy is =  0.7797432239657632\n",
            "At step  30  and at epoch =  32  the loss is =  0.037449732422828674  and accuracy is =  0.769472182596291\n",
            "At step  30  and at epoch =  33  the loss is =  0.03877973183989525  and accuracy is =  0.7768901569186876\n",
            "At step  30  and at epoch =  34  the loss is =  0.03802041336894035  and accuracy is =  0.7841654778887304\n",
            "At step  30  and at epoch =  35  the loss is =  0.03496721386909485  and accuracy is =  0.7791726105563481\n",
            "At step  30  and at epoch =  36  the loss is =  0.03346335142850876  and accuracy is =  0.7865905848787447\n",
            "At step  30  and at epoch =  37  the loss is =  0.03512236848473549  and accuracy is =  0.7957203994293865\n",
            "At step  30  and at epoch =  38  the loss is =  0.03370916098356247  and accuracy is =  0.7965763195435093\n",
            "At step  30  and at epoch =  39  the loss is =  0.03539769724011421  and accuracy is =  0.8025677603423681\n",
            "At step  30  and at epoch =  40  the loss is =  0.03525242954492569  and accuracy is =  0.7904422253922967\n",
            "At step  30  and at epoch =  41  the loss is =  0.0359419547021389  and accuracy is =  0.8038516405135521\n",
            "At step  30  and at epoch =  42  the loss is =  0.03534610942006111  and accuracy is =  0.8034236804564907\n",
            "At step  30  and at epoch =  43  the loss is =  0.034756727516651154  and accuracy is =  0.8129814550641941\n",
            "At step  30  and at epoch =  44  the loss is =  0.030449505895376205  and accuracy is =  0.8135520684736092\n",
            "At step  30  and at epoch =  45  the loss is =  0.035873059183359146  and accuracy is =  0.8075606276747503\n",
            "At step  30  and at epoch =  46  the loss is =  0.03798966854810715  and accuracy is =  0.8059914407988588\n",
            "At step  30  and at epoch =  47  the loss is =  0.036832068115472794  and accuracy is =  0.8203994293865906\n",
            "At step  30  and at epoch =  48  the loss is =  0.03395415097475052  and accuracy is =  0.8174037089871612\n",
            "At step  30  and at epoch =  49  the loss is =  0.03204565495252609  and accuracy is =  0.8479315263908702\n",
            "At step  30  and at epoch =  50  the loss is =  0.03199378028512001  and accuracy is =  0.8654778887303851\n",
            "At step  30  and at epoch =  51  the loss is =  0.029879380017518997  and accuracy is =  0.8676176890156919\n",
            "At step  30  and at epoch =  52  the loss is =  0.03160179778933525  and accuracy is =  0.8677603423680457\n",
            "At step  30  and at epoch =  53  the loss is =  0.03020600602030754  and accuracy is =  0.8760342368045649\n",
            "At step  30  and at epoch =  54  the loss is =  0.03265155106782913  and accuracy is =  0.8808844507845934\n",
            "At step  30  and at epoch =  55  the loss is =  0.030486874282360077  and accuracy is =  0.8837375178316691\n",
            "At step  30  and at epoch =  56  the loss is =  0.02939632534980774  and accuracy is =  0.8810271041369472\n",
            "At step  30  and at epoch =  57  the loss is =  0.0297081358730793  and accuracy is =  0.882453637660485\n",
            "At step  30  and at epoch =  58  the loss is =  0.030420027673244476  and accuracy is =  0.8845934379457917\n",
            "At step  30  and at epoch =  59  the loss is =  0.030299339443445206  and accuracy is =  0.8823109843081313\n",
            "At step  30  and at epoch =  60  the loss is =  0.03327317163348198  and accuracy is =  0.8843081312410842\n",
            "At step  30  and at epoch =  61  the loss is =  0.030407244339585304  and accuracy is =  0.8860199714693295\n",
            "At step  30  and at epoch =  62  the loss is =  0.029785720631480217  and accuracy is =  0.8957203994293866\n",
            "At step  30  and at epoch =  63  the loss is =  0.0316295251250267  and accuracy is =  0.8907275320970043\n",
            "At step  30  and at epoch =  64  the loss is =  0.030625080689787865  and accuracy is =  0.8951497860199714\n",
            "At step  30  and at epoch =  65  the loss is =  0.031249389052391052  and accuracy is =  0.8924393723252496\n",
            "At step  30  and at epoch =  66  the loss is =  0.031311679631471634  and accuracy is =  0.892867332382311\n",
            "At step  30  and at epoch =  67  the loss is =  0.029680758714675903  and accuracy is =  0.8937232524964337\n",
            "At step  30  and at epoch =  68  the loss is =  0.029441406950354576  and accuracy is =  0.896718972895863\n",
            "At step  30  and at epoch =  69  the loss is =  0.028950506821274757  and accuracy is =  0.8987161198288159\n",
            "task: 30 train accuracy = 0.894\n",
            "task: 30 test accuracy = 0.6975\n",
            "At step  40  and at epoch =  0  the loss is =  0.055300261825323105  and accuracy is =  0.2728693181818182\n",
            "At step  40  and at epoch =  1  the loss is =  0.05166551470756531  and accuracy is =  0.33238636363636365\n",
            "At step  40  and at epoch =  2  the loss is =  0.05487801507115364  and accuracy is =  0.3784090909090909\n",
            "At step  40  and at epoch =  3  the loss is =  0.05709310248494148  and accuracy is =  0.42215909090909093\n",
            "At step  40  and at epoch =  4  the loss is =  0.05315369367599487  and accuracy is =  0.46178977272727273\n",
            "At step  40  and at epoch =  5  the loss is =  0.050591882318258286  and accuracy is =  0.5002840909090909\n",
            "At step  40  and at epoch =  6  the loss is =  0.047276999801397324  and accuracy is =  0.5191761363636364\n",
            "At step  40  and at epoch =  7  the loss is =  0.05349946767091751  and accuracy is =  0.5450284090909091\n",
            "At step  40  and at epoch =  8  the loss is =  0.05303359031677246  and accuracy is =  0.5505681818181818\n",
            "At step  40  and at epoch =  9  the loss is =  0.05214192345738411  and accuracy is =  0.5650568181818182\n",
            "At step  40  and at epoch =  10  the loss is =  0.04670773446559906  and accuracy is =  0.5863636363636363\n",
            "At step  40  and at epoch =  11  the loss is =  0.05105092003941536  and accuracy is =  0.6005681818181818\n",
            "At step  40  and at epoch =  12  the loss is =  0.05024140328168869  and accuracy is =  0.6098011363636363\n",
            "At step  40  and at epoch =  13  the loss is =  0.05111938342452049  and accuracy is =  0.6186079545454546\n",
            "At step  40  and at epoch =  14  the loss is =  0.04982824996113777  and accuracy is =  0.6299715909090909\n",
            "At step  40  and at epoch =  15  the loss is =  0.04804361239075661  and accuracy is =  0.6514204545454545\n",
            "At step  40  and at epoch =  16  the loss is =  0.049592260271310806  and accuracy is =  0.6501420454545455\n",
            "At step  40  and at epoch =  17  the loss is =  0.050718311220407486  and accuracy is =  0.6636363636363637\n",
            "At step  40  and at epoch =  18  the loss is =  0.049138594418764114  and accuracy is =  0.6708806818181818\n",
            "At step  40  and at epoch =  19  the loss is =  0.05471987649798393  and accuracy is =  0.6801136363636363\n",
            "At step  40  and at epoch =  20  the loss is =  0.04820452257990837  and accuracy is =  0.6769886363636364\n",
            "At step  40  and at epoch =  21  the loss is =  0.04933028668165207  and accuracy is =  0.6789772727272727\n",
            "At step  40  and at epoch =  22  the loss is =  0.05072423443198204  and accuracy is =  0.696875\n",
            "At step  40  and at epoch =  23  the loss is =  0.047981347888708115  and accuracy is =  0.7029829545454546\n",
            "At step  40  and at epoch =  24  the loss is =  0.045895710587501526  and accuracy is =  0.7112215909090909\n",
            "At step  40  and at epoch =  25  the loss is =  0.048064783215522766  and accuracy is =  0.704403409090909\n",
            "At step  40  and at epoch =  26  the loss is =  0.0487358383834362  and accuracy is =  0.7178977272727273\n",
            "At step  40  and at epoch =  27  the loss is =  0.049452561885118484  and accuracy is =  0.7177556818181818\n",
            "At step  40  and at epoch =  28  the loss is =  0.05121050775051117  and accuracy is =  0.7237215909090909\n",
            "At step  40  and at epoch =  29  the loss is =  0.04978055879473686  and accuracy is =  0.7276988636363636\n",
            "At step  40  and at epoch =  30  the loss is =  0.04747643321752548  and accuracy is =  0.7322443181818182\n",
            "At step  40  and at epoch =  31  the loss is =  0.046791281551122665  and accuracy is =  0.7269886363636363\n",
            "At step  40  and at epoch =  32  the loss is =  0.047475241124629974  and accuracy is =  0.73125\n",
            "At step  40  and at epoch =  33  the loss is =  0.048144493252038956  and accuracy is =  0.7267045454545454\n",
            "At step  40  and at epoch =  34  the loss is =  0.05046254023909569  and accuracy is =  0.7424715909090909\n",
            "At step  40  and at epoch =  35  the loss is =  0.045781105756759644  and accuracy is =  0.7498579545454546\n",
            "At step  40  and at epoch =  36  the loss is =  0.04723644256591797  and accuracy is =  0.7522727272727273\n",
            "At step  40  and at epoch =  37  the loss is =  0.046803511679172516  and accuracy is =  0.7504261363636363\n",
            "At step  40  and at epoch =  38  the loss is =  0.04659770429134369  and accuracy is =  0.7636363636363637\n",
            "At step  40  and at epoch =  39  the loss is =  0.04243817180395126  and accuracy is =  0.7579545454545454\n",
            "At step  40  and at epoch =  40  the loss is =  0.0466734878718853  and accuracy is =  0.7713068181818182\n",
            "At step  40  and at epoch =  41  the loss is =  0.0503946878015995  and accuracy is =  0.7701704545454545\n",
            "At step  40  and at epoch =  42  the loss is =  0.049634888768196106  and accuracy is =  0.7640625\n",
            "At step  40  and at epoch =  43  the loss is =  0.047728508710861206  and accuracy is =  0.7740056818181819\n",
            "At step  40  and at epoch =  44  the loss is =  0.04518190398812294  and accuracy is =  0.7740056818181819\n",
            "At step  40  and at epoch =  45  the loss is =  0.045657362788915634  and accuracy is =  0.774715909090909\n",
            "At step  40  and at epoch =  46  the loss is =  0.046175889670848846  and accuracy is =  0.7752840909090909\n",
            "At step  40  and at epoch =  47  the loss is =  0.04401197284460068  and accuracy is =  0.7900568181818182\n",
            "At step  40  and at epoch =  48  the loss is =  0.04741446301341057  and accuracy is =  0.7938920454545455\n",
            "At step  40  and at epoch =  49  the loss is =  0.0412064827978611  and accuracy is =  0.8258522727272727\n",
            "At step  40  and at epoch =  50  the loss is =  0.039655234664678574  and accuracy is =  0.850284090909091\n",
            "At step  40  and at epoch =  51  the loss is =  0.0417872816324234  and accuracy is =  0.8526988636363636\n",
            "At step  40  and at epoch =  52  the loss is =  0.04125840216875076  and accuracy is =  0.8561079545454545\n",
            "At step  40  and at epoch =  53  the loss is =  0.037937432527542114  and accuracy is =  0.8569602272727272\n",
            "At step  40  and at epoch =  54  the loss is =  0.04209576174616814  and accuracy is =  0.8568181818181818\n",
            "At step  40  and at epoch =  55  the loss is =  0.04169078916311264  and accuracy is =  0.8612215909090909\n",
            "At step  40  and at epoch =  56  the loss is =  0.0394565723836422  and accuracy is =  0.8629261363636364\n",
            "At step  40  and at epoch =  57  the loss is =  0.039538878947496414  and accuracy is =  0.8670454545454546\n",
            "At step  40  and at epoch =  58  the loss is =  0.04175642877817154  and accuracy is =  0.8650568181818182\n",
            "At step  40  and at epoch =  59  the loss is =  0.04058005288243294  and accuracy is =  0.8704545454545455\n",
            "At step  40  and at epoch =  60  the loss is =  0.03918751701712608  and accuracy is =  0.8741477272727273\n",
            "At step  40  and at epoch =  61  the loss is =  0.03979490324854851  and accuracy is =  0.8759943181818182\n",
            "At step  40  and at epoch =  62  the loss is =  0.04065319895744324  and accuracy is =  0.86875\n",
            "At step  40  and at epoch =  63  the loss is =  0.039654407650232315  and accuracy is =  0.8764204545454546\n",
            "At step  40  and at epoch =  64  the loss is =  0.04253669083118439  and accuracy is =  0.8805397727272727\n",
            "At step  40  and at epoch =  65  the loss is =  0.039241403341293335  and accuracy is =  0.8816761363636364\n",
            "At step  40  and at epoch =  66  the loss is =  0.042532943189144135  and accuracy is =  0.8799715909090909\n",
            "At step  40  and at epoch =  67  the loss is =  0.03867100924253464  and accuracy is =  0.8819602272727273\n",
            "At step  40  and at epoch =  68  the loss is =  0.042022667825222015  and accuracy is =  0.8838068181818182\n",
            "At step  40  and at epoch =  69  the loss is =  0.04020209237933159  and accuracy is =  0.8792613636363636\n",
            "task: 40 train accuracy = 0.8234\n",
            "task: 40 test accuracy = 0.6398\n",
            "At step  50  and at epoch =  0  the loss is =  0.07406207919120789  and accuracy is =  0.26\n",
            "At step  50  and at epoch =  1  the loss is =  0.07663051038980484  and accuracy is =  0.339290780141844\n",
            "At step  50  and at epoch =  2  the loss is =  0.0988001897931099  and accuracy is =  0.39063829787234045\n",
            "At step  50  and at epoch =  3  the loss is =  0.08076862245798111  and accuracy is =  0.4339007092198582\n",
            "At step  50  and at epoch =  4  the loss is =  0.06805162131786346  and accuracy is =  0.4683687943262411\n",
            "At step  50  and at epoch =  5  the loss is =  0.05202575773000717  and accuracy is =  0.4970212765957447\n",
            "At step  50  and at epoch =  6  the loss is =  0.06638741493225098  and accuracy is =  0.5146099290780142\n",
            "At step  50  and at epoch =  7  the loss is =  0.09076756238937378  and accuracy is =  0.54\n",
            "At step  50  and at epoch =  8  the loss is =  0.0761801078915596  and accuracy is =  0.5421276595744681\n",
            "At step  50  and at epoch =  9  the loss is =  0.07737439125776291  and accuracy is =  0.5480851063829787\n",
            "At step  50  and at epoch =  10  the loss is =  0.08632878214120865  and accuracy is =  0.5757446808510638\n",
            "At step  50  and at epoch =  11  the loss is =  0.05477193742990494  and accuracy is =  0.595886524822695\n",
            "At step  50  and at epoch =  12  the loss is =  0.07327786087989807  and accuracy is =  0.5974468085106382\n",
            "At step  50  and at epoch =  13  the loss is =  0.05810864269733429  and accuracy is =  0.6126241134751773\n",
            "At step  50  and at epoch =  14  the loss is =  0.06721806526184082  and accuracy is =  0.6218439716312056\n",
            "At step  50  and at epoch =  15  the loss is =  0.06631132960319519  and accuracy is =  0.6236879432624114\n",
            "At step  50  and at epoch =  16  the loss is =  0.06504183262586594  and accuracy is =  0.6365957446808511\n",
            "At step  50  and at epoch =  17  the loss is =  0.07692314684391022  and accuracy is =  0.6350354609929078\n",
            "At step  50  and at epoch =  18  the loss is =  0.06944058835506439  and accuracy is =  0.6449645390070922\n",
            "At step  50  and at epoch =  19  the loss is =  0.06481312960386276  and accuracy is =  0.6304964539007092\n",
            "At step  50  and at epoch =  20  the loss is =  0.07186894863843918  and accuracy is =  0.6485106382978724\n",
            "At step  50  and at epoch =  21  the loss is =  0.06804031878709793  and accuracy is =  0.659290780141844\n",
            "At step  50  and at epoch =  22  the loss is =  0.06510434299707413  and accuracy is =  0.6727659574468086\n",
            "At step  50  and at epoch =  23  the loss is =  0.06116392835974693  and accuracy is =  0.6767375886524822\n",
            "At step  50  and at epoch =  24  the loss is =  0.06610137969255447  and accuracy is =  0.6839716312056737\n",
            "At step  50  and at epoch =  25  the loss is =  0.07555383443832397  and accuracy is =  0.6971631205673758\n",
            "At step  50  and at epoch =  26  the loss is =  0.06696644425392151  and accuracy is =  0.6852482269503546\n",
            "At step  50  and at epoch =  27  the loss is =  0.07671969383955002  and accuracy is =  0.6574468085106383\n",
            "At step  50  and at epoch =  28  the loss is =  0.05823184549808502  and accuracy is =  0.6502127659574468\n",
            "At step  50  and at epoch =  29  the loss is =  0.08228177577257156  and accuracy is =  0.6934751773049646\n",
            "At step  50  and at epoch =  30  the loss is =  0.07448139786720276  and accuracy is =  0.6919148936170213\n",
            "At step  50  and at epoch =  31  the loss is =  0.0693175420165062  and accuracy is =  0.6912056737588652\n",
            "At step  50  and at epoch =  32  the loss is =  0.05722785368561745  and accuracy is =  0.7066666666666667\n",
            "At step  50  and at epoch =  33  the loss is =  0.08655019104480743  and accuracy is =  0.7082269503546099\n",
            "At step  50  and at epoch =  34  the loss is =  0.07300329953432083  and accuracy is =  0.6947517730496454\n",
            "At step  50  and at epoch =  35  the loss is =  0.0634881854057312  and accuracy is =  0.7021276595744681\n",
            "At step  50  and at epoch =  36  the loss is =  0.06738854199647903  and accuracy is =  0.725531914893617\n",
            "At step  50  and at epoch =  37  the loss is =  0.05773847550153732  and accuracy is =  0.7065248226950355\n",
            "At step  50  and at epoch =  38  the loss is =  0.0764838233590126  and accuracy is =  0.7167375886524823\n",
            "At step  50  and at epoch =  39  the loss is =  0.08961402624845505  and accuracy is =  0.7187234042553191\n",
            "At step  50  and at epoch =  40  the loss is =  0.05064263567328453  and accuracy is =  0.7095035460992908\n",
            "At step  50  and at epoch =  41  the loss is =  0.09341200441122055  and accuracy is =  0.7405673758865248\n",
            "At step  50  and at epoch =  42  the loss is =  0.06407901644706726  and accuracy is =  0.7276595744680852\n",
            "At step  50  and at epoch =  43  the loss is =  0.07166540622711182  and accuracy is =  0.7212765957446808\n",
            "At step  50  and at epoch =  44  the loss is =  0.055902399122714996  and accuracy is =  0.7516312056737589\n",
            "At step  50  and at epoch =  45  the loss is =  0.057873714715242386  and accuracy is =  0.737872340425532\n",
            "At step  50  and at epoch =  46  the loss is =  0.057440996170043945  and accuracy is =  0.7602836879432624\n",
            "At step  50  and at epoch =  47  the loss is =  0.06748814135789871  and accuracy is =  0.7428368794326241\n",
            "At step  50  and at epoch =  48  the loss is =  0.05480184406042099  and accuracy is =  0.7449645390070923\n",
            "At step  50  and at epoch =  49  the loss is =  0.07253797352313995  and accuracy is =  0.8116312056737589\n",
            "At step  50  and at epoch =  50  the loss is =  0.06041596829891205  and accuracy is =  0.8119148936170213\n",
            "At step  50  and at epoch =  51  the loss is =  0.06202290579676628  and accuracy is =  0.8121985815602837\n",
            "At step  50  and at epoch =  52  the loss is =  0.05536654219031334  and accuracy is =  0.8177304964539007\n",
            "At step  50  and at epoch =  53  the loss is =  0.09658414125442505  and accuracy is =  0.825531914893617\n",
            "At step  50  and at epoch =  54  the loss is =  0.07633467763662338  and accuracy is =  0.8253900709219858\n",
            "At step  50  and at epoch =  55  the loss is =  0.07889539003372192  and accuracy is =  0.8270921985815602\n",
            "At step  50  and at epoch =  56  the loss is =  0.056179676204919815  and accuracy is =  0.825531914893617\n",
            "At step  50  and at epoch =  57  the loss is =  0.05756543204188347  and accuracy is =  0.8265248226950355\n",
            "At step  50  and at epoch =  58  the loss is =  0.07003840804100037  and accuracy is =  0.8313475177304964\n",
            "At step  50  and at epoch =  59  the loss is =  0.06288841366767883  and accuracy is =  0.8395744680851064\n",
            "At step  50  and at epoch =  60  the loss is =  0.07880725711584091  and accuracy is =  0.8415602836879432\n",
            "At step  50  and at epoch =  61  the loss is =  0.0637078508734703  and accuracy is =  0.8278014184397163\n",
            "At step  50  and at epoch =  62  the loss is =  0.07097047567367554  and accuracy is =  0.844113475177305\n",
            "At step  50  and at epoch =  63  the loss is =  0.06360018253326416  and accuracy is =  0.8521985815602837\n",
            "At step  50  and at epoch =  64  the loss is =  0.05450086668133736  and accuracy is =  0.8513475177304964\n",
            "At step  50  and at epoch =  65  the loss is =  0.05816205218434334  and accuracy is =  0.8502127659574468\n",
            "At step  50  and at epoch =  66  the loss is =  0.05225396156311035  and accuracy is =  0.8543262411347518\n",
            "At step  50  and at epoch =  67  the loss is =  0.07513919472694397  and accuracy is =  0.8520567375886525\n",
            "At step  50  and at epoch =  68  the loss is =  0.0716656818985939  and accuracy is =  0.8560283687943262\n",
            "At step  50  and at epoch =  69  the loss is =  0.06853310018777847  and accuracy is =  0.8536170212765958\n",
            "task: 50 train accuracy = 0.8076\n",
            "task: 50 test accuracy = 0.5795\n",
            "At step  60  and at epoch =  0  the loss is =  0.06968708336353302  and accuracy is =  0.2521306818181818\n",
            "At step  60  and at epoch =  1  the loss is =  0.06812706589698792  and accuracy is =  0.32201704545454546\n",
            "At step  60  and at epoch =  2  the loss is =  0.0685153529047966  and accuracy is =  0.3625\n",
            "At step  60  and at epoch =  3  the loss is =  0.06934168934822083  and accuracy is =  0.40482954545454547\n",
            "At step  60  and at epoch =  4  the loss is =  0.06579127162694931  and accuracy is =  0.428125\n",
            "At step  60  and at epoch =  5  the loss is =  0.06370021402835846  and accuracy is =  0.4413352272727273\n",
            "At step  60  and at epoch =  6  the loss is =  0.06941267102956772  and accuracy is =  0.475\n",
            "At step  60  and at epoch =  7  the loss is =  0.06527932733297348  and accuracy is =  0.4865056818181818\n",
            "At step  60  and at epoch =  8  the loss is =  0.06938006728887558  and accuracy is =  0.509090909090909\n",
            "At step  60  and at epoch =  9  the loss is =  0.06474985927343369  and accuracy is =  0.5291193181818182\n",
            "At step  60  and at epoch =  10  the loss is =  0.06806577742099762  and accuracy is =  0.5372159090909091\n",
            "At step  60  and at epoch =  11  the loss is =  0.06474685668945312  and accuracy is =  0.5454545454545454\n",
            "At step  60  and at epoch =  12  the loss is =  0.06532992422580719  and accuracy is =  0.5613636363636364\n",
            "At step  60  and at epoch =  13  the loss is =  0.05984414741396904  and accuracy is =  0.5759943181818182\n",
            "At step  60  and at epoch =  14  the loss is =  0.06638648360967636  and accuracy is =  0.5786931818181819\n",
            "At step  60  and at epoch =  15  the loss is =  0.06666392087936401  and accuracy is =  0.5904829545454545\n",
            "At step  60  and at epoch =  16  the loss is =  0.06507018208503723  and accuracy is =  0.5954545454545455\n",
            "At step  60  and at epoch =  17  the loss is =  0.06429872661828995  and accuracy is =  0.6066761363636364\n",
            "At step  60  and at epoch =  18  the loss is =  0.0635727122426033  and accuracy is =  0.6144886363636364\n",
            "At step  60  and at epoch =  19  the loss is =  0.0641181617975235  and accuracy is =  0.6143465909090909\n",
            "At step  60  and at epoch =  20  the loss is =  0.06128053367137909  and accuracy is =  0.621875\n",
            "At step  60  and at epoch =  21  the loss is =  0.06390952318906784  and accuracy is =  0.6332386363636363\n",
            "At step  60  and at epoch =  22  the loss is =  0.061016883701086044  and accuracy is =  0.6509943181818182\n",
            "At step  60  and at epoch =  23  the loss is =  0.06448926031589508  and accuracy is =  0.6455965909090909\n",
            "At step  60  and at epoch =  24  the loss is =  0.06342315673828125  and accuracy is =  0.6481534090909091\n",
            "At step  60  and at epoch =  25  the loss is =  0.06269445270299911  and accuracy is =  0.6553977272727273\n",
            "At step  60  and at epoch =  26  the loss is =  0.06607984751462936  and accuracy is =  0.6481534090909091\n",
            "At step  60  and at epoch =  27  the loss is =  0.062256403267383575  and accuracy is =  0.6518465909090909\n",
            "At step  60  and at epoch =  28  the loss is =  0.06145336106419563  and accuracy is =  0.6660511363636363\n",
            "At step  60  and at epoch =  29  the loss is =  0.061946481466293335  and accuracy is =  0.6764204545454545\n",
            "At step  60  and at epoch =  30  the loss is =  0.06410124897956848  and accuracy is =  0.6694602272727272\n",
            "At step  60  and at epoch =  31  the loss is =  0.062429822981357574  and accuracy is =  0.6818181818181818\n",
            "At step  60  and at epoch =  32  the loss is =  0.06627661734819412  and accuracy is =  0.6852272727272727\n",
            "At step  60  and at epoch =  33  the loss is =  0.06300215423107147  and accuracy is =  0.6872159090909091\n",
            "At step  60  and at epoch =  34  the loss is =  0.06174929812550545  and accuracy is =  0.6938920454545454\n",
            "At step  60  and at epoch =  35  the loss is =  0.06367602199316025  and accuracy is =  0.6957386363636363\n",
            "At step  60  and at epoch =  36  the loss is =  0.06444418430328369  and accuracy is =  0.7026988636363637\n",
            "At step  60  and at epoch =  37  the loss is =  0.05872095376253128  and accuracy is =  0.6984375\n",
            "At step  60  and at epoch =  38  the loss is =  0.06404491513967514  and accuracy is =  0.7052556818181818\n",
            "At step  60  and at epoch =  39  the loss is =  0.07019311934709549  and accuracy is =  0.7\n",
            "At step  60  and at epoch =  40  the loss is =  0.06761534512042999  and accuracy is =  0.7025568181818181\n",
            "At step  60  and at epoch =  41  the loss is =  0.06435074657201767  and accuracy is =  0.7095170454545454\n",
            "At step  60  and at epoch =  42  the loss is =  0.06173485517501831  and accuracy is =  0.7205965909090909\n",
            "At step  60  and at epoch =  43  the loss is =  0.06263526529073715  and accuracy is =  0.7238636363636364\n",
            "At step  60  and at epoch =  44  the loss is =  0.06411581486463547  and accuracy is =  0.7207386363636363\n",
            "At step  60  and at epoch =  45  the loss is =  0.06059769541025162  and accuracy is =  0.7154829545454545\n",
            "At step  60  and at epoch =  46  the loss is =  0.06024715304374695  and accuracy is =  0.7291193181818182\n",
            "At step  60  and at epoch =  47  the loss is =  0.06492999196052551  and accuracy is =  0.7176136363636364\n",
            "At step  60  and at epoch =  48  the loss is =  0.07066606730222702  and accuracy is =  0.7151988636363636\n",
            "At step  60  and at epoch =  49  the loss is =  0.061320532113313675  and accuracy is =  0.76875\n",
            "At step  60  and at epoch =  50  the loss is =  0.0563601590692997  and accuracy is =  0.7862215909090909\n",
            "At step  60  and at epoch =  51  the loss is =  0.05617506429553032  and accuracy is =  0.798153409090909\n",
            "At step  60  and at epoch =  52  the loss is =  0.061048686504364014  and accuracy is =  0.8089488636363636\n",
            "At step  60  and at epoch =  53  the loss is =  0.05797623097896576  and accuracy is =  0.8063920454545455\n",
            "At step  60  and at epoch =  54  the loss is =  0.05495811253786087  and accuracy is =  0.8130681818181819\n",
            "At step  60  and at epoch =  55  the loss is =  0.06049417331814766  and accuracy is =  0.8163352272727272\n",
            "At step  60  and at epoch =  56  the loss is =  0.060679204761981964  and accuracy is =  0.8208806818181819\n",
            "At step  60  and at epoch =  57  the loss is =  0.0543794222176075  and accuracy is =  0.8207386363636363\n",
            "At step  60  and at epoch =  58  the loss is =  0.05942634493112564  and accuracy is =  0.8160511363636364\n",
            "At step  60  and at epoch =  59  the loss is =  0.05682985484600067  and accuracy is =  0.8208806818181819\n",
            "At step  60  and at epoch =  60  the loss is =  0.058187589049339294  and accuracy is =  0.8237215909090909\n",
            "At step  60  and at epoch =  61  the loss is =  0.057285699993371964  and accuracy is =  0.8284090909090909\n",
            "At step  60  and at epoch =  62  the loss is =  0.05611206591129303  and accuracy is =  0.8264204545454545\n",
            "At step  60  and at epoch =  63  the loss is =  0.058189038187265396  and accuracy is =  0.8352272727272727\n",
            "At step  60  and at epoch =  64  the loss is =  0.05574686825275421  and accuracy is =  0.8363636363636363\n",
            "At step  60  and at epoch =  65  the loss is =  0.05413539707660675  and accuracy is =  0.8365056818181819\n",
            "At step  60  and at epoch =  66  the loss is =  0.0534561350941658  and accuracy is =  0.8392045454545455\n",
            "At step  60  and at epoch =  67  the loss is =  0.05739825963973999  and accuracy is =  0.8407670454545455\n",
            "At step  60  and at epoch =  68  the loss is =  0.056625399738550186  and accuracy is =  0.8362215909090909\n",
            "At step  60  and at epoch =  69  the loss is =  0.05717482417821884  and accuracy is =  0.8316761363636364\n",
            "task: 60 train accuracy = 0.7898\n",
            "task: 60 test accuracy = 0.5394285714285715\n",
            "At step  70  and at epoch =  0  the loss is =  0.081307552754879  and accuracy is =  0.25647226173541965\n",
            "At step  70  and at epoch =  1  the loss is =  0.08033107221126556  and accuracy is =  0.37965860597439544\n",
            "At step  70  and at epoch =  2  the loss is =  0.07895807176828384  and accuracy is =  0.4483641536273115\n",
            "At step  70  and at epoch =  3  the loss is =  0.08259300887584686  and accuracy is =  0.4910384068278805\n",
            "At step  70  and at epoch =  4  the loss is =  0.07996394485235214  and accuracy is =  0.5233285917496444\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}