{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ICaRLMain.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8cca0fbd0b3147c28d70f934533c6ab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_99600c38c79a42238f87ffaa19683971",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8eb9e65723ef41dd8fe25275b60ed89f",
              "IPY_MODEL_2117fad4586c4c27b289080cd7210c1b"
            ]
          }
        },
        "99600c38c79a42238f87ffaa19683971": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8eb9e65723ef41dd8fe25275b60ed89f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_acf7f9a1679646ea9bab90ca518ce831",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2f2bd2b7bdb49508f7ef3e3ccb5f6ab"
          }
        },
        "2117fad4586c4c27b289080cd7210c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e15c6bb943bf4e92908f75a17933f844",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169009152/? [00:20&lt;00:00, 30367793.78it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e7d0e0b82e4476f851394794da4ea01"
          }
        },
        "acf7f9a1679646ea9bab90ca518ce831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2f2bd2b7bdb49508f7ef3e3ccb5f6ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e15c6bb943bf4e92908f75a17933f844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e7d0e0b82e4476f851394794da4ea01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciainnocenti/IncrementalLearning/blob/improvement_Lucia3/ICaRLMain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLMLAOPyrR1K",
        "colab_type": "text"
      },
      "source": [
        "# Import GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LqwZJLUlcYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVa_FlnxrXIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "9063a7be-de7d-49d5-e862-49b4e14c29b1"
      },
      "source": [
        "if not os.path.isdir('./DatasetCIFAR'):\n",
        "  !git clone -b improvement_Lucia3 https://github.com/luciainnocenti/IncrementalLearning.git\n",
        "  !mv 'IncrementalLearning' 'DatasetCIFAR'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IncrementalLearning'...\n",
            "remote: Enumerating objects: 89, done.\u001b[K\n",
            "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
            "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
            "remote: Total 2302 (delta 54), reused 0 (delta 0), pack-reused 2213\u001b[K\n",
            "Receiving objects: 100% (2302/2302), 2.47 MiB | 4.83 MiB/s, done.\n",
            "Resolving deltas: 100% (1474/1474), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXQyHMXzrZ5A",
        "colab_type": "text"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c24pdNxurdv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "955247c8-d181-4d8d-b37d-286d9ffb0139"
      },
      "source": [
        "from DatasetCIFAR.data_set import Dataset \n",
        "from DatasetCIFAR.data_set import Subset\n",
        "from DatasetCIFAR import ResNet\n",
        "from DatasetCIFAR import utils\n",
        "from DatasetCIFAR import params\n",
        "from DatasetCIFAR import ICaRLModel\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import functional as F\n",
        "import random\n",
        "random.seed(params.SEED)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2rkcBbIKfUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "56a26a9d-385c-4972-de1b-46c984fccf82"
      },
      "source": [
        "print(params.SEED)\n",
        "print(params.NUM_WORKERS)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "653\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FlAkShyryrf",
        "colab_type": "text"
      },
      "source": [
        "# Define Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP2iR2vl3Wiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transformer = transforms.Compose([transforms.RandomCrop(size = 32, padding=4),\n",
        "                                         transforms.RandomHorizontalFlip(),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transformer = transforms.Compose([transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CSNk0NlrvAL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "8cca0fbd0b3147c28d70f934533c6ab0",
            "99600c38c79a42238f87ffaa19683971",
            "8eb9e65723ef41dd8fe25275b60ed89f",
            "2117fad4586c4c27b289080cd7210c1b",
            "acf7f9a1679646ea9bab90ca518ce831",
            "c2f2bd2b7bdb49508f7ef3e3ccb5f6ab",
            "e15c6bb943bf4e92908f75a17933f844",
            "5e7d0e0b82e4476f851394794da4ea01"
          ]
        },
        "outputId": "017d9d31-c688-4860-df4b-b092548a5657"
      },
      "source": [
        "trainDS = Dataset(train=True)\n",
        "testDS = Dataset(train=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cca0fbd0b3147c28d70f934533c6ab0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3ge3VayryJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_splits = trainDS.splits\n",
        "test_splits = testDS.splits"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzxTlFF_rkfe",
        "colab_type": "text"
      },
      "source": [
        "# Define Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgZtPkiPrmQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ICaRL = ResNet.resnet32(num_classes=100)\n",
        "ICaRL =  ICaRL.to(params.DEVICE)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI8EyFmpOikN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exemplars = [None]*100\n",
        "\n",
        "test_indexes =  []\n",
        "accs = []"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcFjbBGrOMz6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8ee6f2e4-c37d-40d7-d89b-9b6bd5bdfaea"
      },
      "source": [
        "for task in range(0, 100, params.TASK_SIZE):\n",
        "  train_indexes = trainDS.__getIndexesGroups__(task)\n",
        "  test_indexes = test_indexes + testDS.__getIndexesGroups__(task)\n",
        "\n",
        "  train_dataset = Subset(trainDS, train_indexes, transform = train_transformer)\n",
        "  test_dataset = Subset(testDS, test_indexes, transform = test_transformer)\n",
        "\n",
        "  train_loader = DataLoader( train_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE, shuffle=True)\n",
        "  test_loader = DataLoader( test_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE , shuffle=True )\n",
        "  \n",
        "  ICaRL, exemplars = ICaRLModel.incrementalTrain(task, trainDS, ICaRL, exemplars, train_transformer)\n",
        "\n",
        "  col = []\n",
        "  for i,x in enumerate( train_splits[ :int(task/10) + 1]) : \n",
        "    v = np.array(x)\n",
        "    col = np.concatenate( (col,v), axis = None)\n",
        "    col = col.astype(int)\n",
        "  mean = None\n",
        "  total = 0.0\n",
        "  running_corrects = 0.0\n",
        "  for img, lbl, _ in train_loader:\n",
        "      img = img.float().to(params.DEVICE)\n",
        "      lbl = lbl.to(params.DEVICE)\n",
        "      preds = ICaRLModel.matchAndClassify(img, exemplars, ICaRL, trainDS, task)\n",
        "      preds = torch.tensor(preds).to(params.DEVICE)\n",
        "      total += len(lbl)\n",
        "      running_corrects += torch.sum(preds == lbl.data).data.item()\n",
        "\n",
        "  accuracy = float(running_corrects/total)\n",
        "  print(f'task: {task}', f'train accuracy = {accuracy}')\n",
        "  accs.append(accuracy)\n",
        "\n",
        "  total = 0.0\n",
        "  running_corrects = 0.0\n",
        "  tot_preds = []\n",
        "  tot_lab = []\n",
        "  for img, lbl, _ in test_loader:\n",
        "      img = img.float().to(params.DEVICE)\n",
        "      lbl = lbl.to(params.DEVICE)\n",
        "      preds = ICaRLModel.matchAndClassify(img, exemplars, ICaRL, trainDS, task)\n",
        "      preds = torch.tensor(preds).to(params.DEVICE)\n",
        "      total += len(lbl)\n",
        "      running_corrects += torch.sum(preds == lbl.data).data.item()\n",
        "\n",
        "  accuracy = float(running_corrects/total)\n",
        "  print(f'task: {task}', f'test accuracy = {accuracy}')\n",
        "  #cf = confusion_matrix(tot_lab, tot_preds)\n",
        "  #df_cm = pd.DataFrame(cf, range(task + params.TASK_SIZE), range(task + params.TASK_SIZE))\n",
        "  #sn.set(font_scale = .5) # for label size\n",
        "  #sn.heatmap(df_cm, annot=False)\n",
        "  #plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "At step  0  and at epoch =  0  the loss is =  0.03099367581307888  and accuracy is =  0.1816\n",
            "At step  0  and at epoch =  1  the loss is =  0.02117651328444481  and accuracy is =  0.3996\n",
            "At step  0  and at epoch =  2  the loss is =  0.022216729819774628  and accuracy is =  0.4938\n",
            "At step  0  and at epoch =  3  the loss is =  0.020300621166825294  and accuracy is =  0.5398\n",
            "At step  0  and at epoch =  4  the loss is =  0.016004592180252075  and accuracy is =  0.595\n",
            "At step  0  and at epoch =  5  the loss is =  0.018728122115135193  and accuracy is =  0.6374\n",
            "At step  0  and at epoch =  6  the loss is =  0.02630101703107357  and accuracy is =  0.6568\n",
            "At step  0  and at epoch =  7  the loss is =  0.021686382591724396  and accuracy is =  0.6362\n",
            "At step  0  and at epoch =  8  the loss is =  0.0226923655718565  and accuracy is =  0.6982\n",
            "At step  0  and at epoch =  9  the loss is =  0.03185119479894638  and accuracy is =  0.7084\n",
            "At step  0  and at epoch =  10  the loss is =  0.021375689655542374  and accuracy is =  0.7088\n",
            "At step  0  and at epoch =  11  the loss is =  0.023887505754828453  and accuracy is =  0.7286\n",
            "At step  0  and at epoch =  12  the loss is =  0.009122383780777454  and accuracy is =  0.7562\n",
            "At step  0  and at epoch =  13  the loss is =  0.008755090646445751  and accuracy is =  0.7844\n",
            "At step  0  and at epoch =  14  the loss is =  0.014299253933131695  and accuracy is =  0.7884\n",
            "At step  0  and at epoch =  15  the loss is =  0.026479797437787056  and accuracy is =  0.7916\n",
            "At step  0  and at epoch =  16  the loss is =  0.022592544555664062  and accuracy is =  0.7692\n",
            "At step  0  and at epoch =  17  the loss is =  0.011418475769460201  and accuracy is =  0.788\n",
            "At step  0  and at epoch =  18  the loss is =  0.032916080206632614  and accuracy is =  0.8102\n",
            "At step  0  and at epoch =  19  the loss is =  0.014960827305912971  and accuracy is =  0.7814\n",
            "At step  0  and at epoch =  20  the loss is =  0.016231466084718704  and accuracy is =  0.8056\n",
            "At step  0  and at epoch =  21  the loss is =  0.018610527738928795  and accuracy is =  0.8196\n",
            "At step  0  and at epoch =  22  the loss is =  0.011241001076996326  and accuracy is =  0.8326\n",
            "At step  0  and at epoch =  23  the loss is =  0.007076981011778116  and accuracy is =  0.8276\n",
            "At step  0  and at epoch =  24  the loss is =  0.02356307953596115  and accuracy is =  0.85\n",
            "At step  0  and at epoch =  25  the loss is =  0.03452597185969353  and accuracy is =  0.8408\n",
            "At step  0  and at epoch =  26  the loss is =  0.005057083442807198  and accuracy is =  0.8302\n",
            "At step  0  and at epoch =  27  the loss is =  0.025183672085404396  and accuracy is =  0.8572\n",
            "At step  0  and at epoch =  28  the loss is =  0.003914619795978069  and accuracy is =  0.848\n",
            "At step  0  and at epoch =  29  the loss is =  0.02731817401945591  and accuracy is =  0.8708\n",
            "At step  0  and at epoch =  30  the loss is =  0.013252835720777512  and accuracy is =  0.8664\n",
            "At step  0  and at epoch =  31  the loss is =  0.032697949558496475  and accuracy is =  0.8698\n",
            "At step  0  and at epoch =  32  the loss is =  0.01966170035302639  and accuracy is =  0.8458\n",
            "At step  0  and at epoch =  33  the loss is =  0.0053516291081905365  and accuracy is =  0.8682\n",
            "At step  0  and at epoch =  34  the loss is =  0.0017593571683391929  and accuracy is =  0.8896\n",
            "At step  0  and at epoch =  35  the loss is =  0.01003036368638277  and accuracy is =  0.8924\n",
            "At step  0  and at epoch =  36  the loss is =  0.01912105828523636  and accuracy is =  0.878\n",
            "At step  0  and at epoch =  37  the loss is =  0.017958475276827812  and accuracy is =  0.8394\n",
            "At step  0  and at epoch =  38  the loss is =  0.009554991498589516  and accuracy is =  0.883\n",
            "At step  0  and at epoch =  39  the loss is =  0.014612999744713306  and accuracy is =  0.8892\n",
            "At step  0  and at epoch =  40  the loss is =  0.0042619286105036736  and accuracy is =  0.8476\n",
            "At step  0  and at epoch =  41  the loss is =  0.017552731558680534  and accuracy is =  0.9046\n",
            "At step  0  and at epoch =  42  the loss is =  0.016511661931872368  and accuracy is =  0.8862\n",
            "At step  0  and at epoch =  43  the loss is =  0.014404146000742912  and accuracy is =  0.9066\n",
            "At step  0  and at epoch =  44  the loss is =  0.006300644017755985  and accuracy is =  0.9028\n",
            "At step  0  and at epoch =  45  the loss is =  0.019527344033122063  and accuracy is =  0.9126\n",
            "At step  0  and at epoch =  46  the loss is =  0.021570924669504166  and accuracy is =  0.8754\n",
            "At step  0  and at epoch =  47  the loss is =  0.0145804975181818  and accuracy is =  0.8956\n",
            "At step  0  and at epoch =  48  the loss is =  0.006721069570630789  and accuracy is =  0.8924\n",
            "At step  0  and at epoch =  49  the loss is =  0.014720164239406586  and accuracy is =  0.931\n",
            "At step  0  and at epoch =  50  the loss is =  0.008009085431694984  and accuracy is =  0.942\n",
            "At step  0  and at epoch =  51  the loss is =  0.010505522601306438  and accuracy is =  0.949\n",
            "At step  0  and at epoch =  52  the loss is =  0.017230750992894173  and accuracy is =  0.955\n",
            "At step  0  and at epoch =  53  the loss is =  0.011076119728386402  and accuracy is =  0.9494\n",
            "At step  0  and at epoch =  54  the loss is =  0.004838993307203054  and accuracy is =  0.9488\n",
            "At step  0  and at epoch =  55  the loss is =  0.011740840040147305  and accuracy is =  0.9584\n",
            "At step  0  and at epoch =  56  the loss is =  0.0035768686793744564  and accuracy is =  0.9612\n",
            "At step  0  and at epoch =  57  the loss is =  0.006391977425664663  and accuracy is =  0.9632\n",
            "At step  0  and at epoch =  58  the loss is =  0.00048503762809559703  and accuracy is =  0.9626\n",
            "At step  0  and at epoch =  59  the loss is =  0.019548093900084496  and accuracy is =  0.9668\n",
            "At step  0  and at epoch =  60  the loss is =  0.004443981219083071  and accuracy is =  0.9568\n",
            "At step  0  and at epoch =  61  the loss is =  0.016774175688624382  and accuracy is =  0.965\n",
            "At step  0  and at epoch =  62  the loss is =  0.01204907987266779  and accuracy is =  0.9572\n",
            "At step  0  and at epoch =  63  the loss is =  0.01661008596420288  and accuracy is =  0.9636\n",
            "At step  0  and at epoch =  64  the loss is =  0.024940073490142822  and accuracy is =  0.9666\n",
            "At step  0  and at epoch =  65  the loss is =  0.008769671432673931  and accuracy is =  0.9668\n",
            "At step  0  and at epoch =  66  the loss is =  0.003784274449571967  and accuracy is =  0.9764\n",
            "At step  0  and at epoch =  67  the loss is =  0.0021742626558989286  and accuracy is =  0.974\n",
            "At step  0  and at epoch =  68  the loss is =  0.009151604026556015  and accuracy is =  0.9736\n",
            "At step  0  and at epoch =  69  the loss is =  0.002190611558035016  and accuracy is =  0.9716\n",
            "task: 0 train accuracy = 0.7236\n",
            "task: 0 test accuracy = 0.665\n",
            "At step  10  and at epoch =  0  the loss is =  0.02864351123571396  and accuracy is =  0.29928571428571427\n",
            "At step  10  and at epoch =  1  the loss is =  0.02925008349120617  and accuracy is =  0.38785714285714284\n",
            "At step  10  and at epoch =  2  the loss is =  0.025994058698415756  and accuracy is =  0.4845714285714286\n",
            "At step  10  and at epoch =  3  the loss is =  0.023620042949914932  and accuracy is =  0.5387142857142857\n",
            "At step  10  and at epoch =  4  the loss is =  0.020983539521694183  and accuracy is =  0.5678571428571428\n",
            "At step  10  and at epoch =  5  the loss is =  0.018719371408224106  and accuracy is =  0.5925714285714285\n",
            "At step  10  and at epoch =  6  the loss is =  0.020905613899230957  and accuracy is =  0.609\n",
            "At step  10  and at epoch =  7  the loss is =  0.021025195717811584  and accuracy is =  0.6407142857142857\n",
            "At step  10  and at epoch =  8  the loss is =  0.022926677018404007  and accuracy is =  0.6532857142857142\n",
            "At step  10  and at epoch =  9  the loss is =  0.023157963529229164  and accuracy is =  0.6767142857142857\n",
            "At step  10  and at epoch =  10  the loss is =  0.02208927646279335  and accuracy is =  0.6805714285714286\n",
            "At step  10  and at epoch =  11  the loss is =  0.0224294476211071  and accuracy is =  0.695\n",
            "At step  10  and at epoch =  12  the loss is =  0.019297877326607704  and accuracy is =  0.7051428571428572\n",
            "At step  10  and at epoch =  13  the loss is =  0.018839431926608086  and accuracy is =  0.714\n",
            "At step  10  and at epoch =  14  the loss is =  0.019732346758246422  and accuracy is =  0.724\n",
            "At step  10  and at epoch =  15  the loss is =  0.019372884184122086  and accuracy is =  0.7327142857142858\n",
            "At step  10  and at epoch =  16  the loss is =  0.02088187076151371  and accuracy is =  0.7375714285714285\n",
            "At step  10  and at epoch =  17  the loss is =  0.018999777734279633  and accuracy is =  0.7432857142857143\n",
            "At step  10  and at epoch =  18  the loss is =  0.017642788589000702  and accuracy is =  0.7538571428571429\n",
            "At step  10  and at epoch =  19  the loss is =  0.019119707867503166  and accuracy is =  0.7635714285714286\n",
            "At step  10  and at epoch =  20  the loss is =  0.020192943513393402  and accuracy is =  0.753\n",
            "At step  10  and at epoch =  21  the loss is =  0.01907339319586754  and accuracy is =  0.7717142857142857\n",
            "At step  10  and at epoch =  22  the loss is =  0.016785284504294395  and accuracy is =  0.7825714285714286\n",
            "At step  10  and at epoch =  23  the loss is =  0.017876138910651207  and accuracy is =  0.7802857142857142\n",
            "At step  10  and at epoch =  24  the loss is =  0.019458729773759842  and accuracy is =  0.7911428571428571\n",
            "At step  10  and at epoch =  25  the loss is =  0.0216474961489439  and accuracy is =  0.7881428571428571\n",
            "At step  10  and at epoch =  26  the loss is =  0.015884382650256157  and accuracy is =  0.7992857142857143\n",
            "At step  10  and at epoch =  27  the loss is =  0.016652874648571014  and accuracy is =  0.7968571428571428\n",
            "At step  10  and at epoch =  28  the loss is =  0.019845133647322655  and accuracy is =  0.8115714285714286\n",
            "At step  10  and at epoch =  29  the loss is =  0.01864021271467209  and accuracy is =  0.812\n",
            "At step  10  and at epoch =  30  the loss is =  0.017972933128476143  and accuracy is =  0.8155714285714286\n",
            "At step  10  and at epoch =  31  the loss is =  0.01923297718167305  and accuracy is =  0.8174285714285714\n",
            "At step  10  and at epoch =  32  the loss is =  0.019642652943730354  and accuracy is =  0.8167142857142857\n",
            "At step  10  and at epoch =  33  the loss is =  0.018803957849740982  and accuracy is =  0.8282857142857143\n",
            "At step  10  and at epoch =  34  the loss is =  0.015921209007501602  and accuracy is =  0.8145714285714286\n",
            "At step  10  and at epoch =  35  the loss is =  0.01695816032588482  and accuracy is =  0.8301428571428572\n",
            "At step  10  and at epoch =  36  the loss is =  0.02139480970799923  and accuracy is =  0.8238571428571428\n",
            "At step  10  and at epoch =  37  the loss is =  0.015839340165257454  and accuracy is =  0.8328571428571429\n",
            "At step  10  and at epoch =  38  the loss is =  0.01640903204679489  and accuracy is =  0.836\n",
            "At step  10  and at epoch =  39  the loss is =  0.017581768333911896  and accuracy is =  0.8407142857142857\n",
            "At step  10  and at epoch =  40  the loss is =  0.01747591607272625  and accuracy is =  0.842\n",
            "At step  10  and at epoch =  41  the loss is =  0.0163855142891407  and accuracy is =  0.8408571428571429\n",
            "At step  10  and at epoch =  42  the loss is =  0.015187935903668404  and accuracy is =  0.8368571428571429\n",
            "At step  10  and at epoch =  43  the loss is =  0.017322227358818054  and accuracy is =  0.8352857142857143\n",
            "At step  10  and at epoch =  44  the loss is =  0.015027455054223537  and accuracy is =  0.8518571428571429\n",
            "At step  10  and at epoch =  45  the loss is =  0.016730787232518196  and accuracy is =  0.8558571428571429\n",
            "At step  10  and at epoch =  46  the loss is =  0.017344821244478226  and accuracy is =  0.8481428571428572\n",
            "At step  10  and at epoch =  47  the loss is =  0.016966620460152626  and accuracy is =  0.8544285714285714\n",
            "At step  10  and at epoch =  48  the loss is =  0.015193786472082138  and accuracy is =  0.8464285714285714\n",
            "At step  10  and at epoch =  49  the loss is =  0.012849230319261551  and accuracy is =  0.8821428571428571\n",
            "At step  10  and at epoch =  50  the loss is =  0.014527572318911552  and accuracy is =  0.9065714285714286\n",
            "At step  10  and at epoch =  51  the loss is =  0.011829490773379803  and accuracy is =  0.9125714285714286\n",
            "At step  10  and at epoch =  52  the loss is =  0.013012048788368702  and accuracy is =  0.9078571428571428\n",
            "At step  10  and at epoch =  53  the loss is =  0.011654380708932877  and accuracy is =  0.9147142857142857\n",
            "At step  10  and at epoch =  54  the loss is =  0.011742856353521347  and accuracy is =  0.9204285714285714\n",
            "At step  10  and at epoch =  55  the loss is =  0.01453875657171011  and accuracy is =  0.9234285714285714\n",
            "At step  10  and at epoch =  56  the loss is =  0.012151285074651241  and accuracy is =  0.9197142857142857\n",
            "At step  10  and at epoch =  57  the loss is =  0.011926023289561272  and accuracy is =  0.9224285714285714\n",
            "At step  10  and at epoch =  58  the loss is =  0.01358343567699194  and accuracy is =  0.9258571428571428\n",
            "At step  10  and at epoch =  59  the loss is =  0.012812064029276371  and accuracy is =  0.92\n",
            "At step  10  and at epoch =  60  the loss is =  0.013768407516181469  and accuracy is =  0.9271428571428572\n",
            "At step  10  and at epoch =  61  the loss is =  0.01152191124856472  and accuracy is =  0.9275714285714286\n",
            "At step  10  and at epoch =  62  the loss is =  0.011773858219385147  and accuracy is =  0.9285714285714286\n",
            "At step  10  and at epoch =  63  the loss is =  0.011091348715126514  and accuracy is =  0.9334285714285714\n",
            "At step  10  and at epoch =  64  the loss is =  0.011187048628926277  and accuracy is =  0.9341428571428572\n",
            "At step  10  and at epoch =  65  the loss is =  0.011966127902269363  and accuracy is =  0.9345714285714286\n",
            "At step  10  and at epoch =  66  the loss is =  0.012755638919770718  and accuracy is =  0.9392857142857143\n",
            "At step  10  and at epoch =  67  the loss is =  0.01126726996153593  and accuracy is =  0.9377142857142857\n",
            "At step  10  and at epoch =  68  the loss is =  0.011526690796017647  and accuracy is =  0.9362857142857143\n",
            "At step  10  and at epoch =  69  the loss is =  0.012937921099364758  and accuracy is =  0.9358571428571428\n",
            "task: 10 train accuracy = 0.4166\n",
            "task: 10 test accuracy = 0.398\n",
            "At step  20  and at epoch =  0  the loss is =  0.03621070459485054  and accuracy is =  0.27185714285714285\n",
            "At step  20  and at epoch =  1  the loss is =  0.03470927104353905  and accuracy is =  0.3455714285714286\n",
            "At step  20  and at epoch =  2  the loss is =  0.035482704639434814  and accuracy is =  0.44057142857142856\n",
            "At step  20  and at epoch =  3  the loss is =  0.03312520682811737  and accuracy is =  0.48814285714285716\n",
            "At step  20  and at epoch =  4  the loss is =  0.03639863431453705  and accuracy is =  0.5372857142857143\n",
            "At step  20  and at epoch =  5  the loss is =  0.03195549175143242  and accuracy is =  0.5581428571428572\n",
            "At step  20  and at epoch =  6  the loss is =  0.028862465173006058  and accuracy is =  0.5888571428571429\n",
            "At step  20  and at epoch =  7  the loss is =  0.03560549393296242  and accuracy is =  0.6134285714285714\n",
            "At step  20  and at epoch =  8  the loss is =  0.027388516813516617  and accuracy is =  0.6187142857142857\n",
            "At step  20  and at epoch =  9  the loss is =  0.026635710150003433  and accuracy is =  0.6451428571428571\n",
            "At step  20  and at epoch =  10  the loss is =  0.031257469207048416  and accuracy is =  0.6645714285714286\n",
            "At step  20  and at epoch =  11  the loss is =  0.029315948486328125  and accuracy is =  0.6701428571428572\n",
            "At step  20  and at epoch =  12  the loss is =  0.029635107144713402  and accuracy is =  0.6768571428571428\n",
            "At step  20  and at epoch =  13  the loss is =  0.029420658946037292  and accuracy is =  0.6857142857142857\n",
            "At step  20  and at epoch =  14  the loss is =  0.02954164333641529  and accuracy is =  0.6975714285714286\n",
            "At step  20  and at epoch =  15  the loss is =  0.028963793069124222  and accuracy is =  0.6922857142857143\n",
            "At step  20  and at epoch =  16  the loss is =  0.03080049715936184  and accuracy is =  0.7185714285714285\n",
            "At step  20  and at epoch =  17  the loss is =  0.03189373016357422  and accuracy is =  0.7222857142857143\n",
            "At step  20  and at epoch =  18  the loss is =  0.025999709963798523  and accuracy is =  0.7292857142857143\n",
            "At step  20  and at epoch =  19  the loss is =  0.025655338540673256  and accuracy is =  0.7338571428571429\n",
            "At step  20  and at epoch =  20  the loss is =  0.02784070558845997  and accuracy is =  0.7385714285714285\n",
            "At step  20  and at epoch =  21  the loss is =  0.02955526113510132  and accuracy is =  0.7472857142857143\n",
            "At step  20  and at epoch =  22  the loss is =  0.02823379449546337  and accuracy is =  0.7487142857142857\n",
            "At step  20  and at epoch =  23  the loss is =  0.025307118892669678  and accuracy is =  0.7592857142857142\n",
            "At step  20  and at epoch =  24  the loss is =  0.02633650042116642  and accuracy is =  0.7554285714285714\n",
            "At step  20  and at epoch =  25  the loss is =  0.026429763063788414  and accuracy is =  0.7642857142857142\n",
            "At step  20  and at epoch =  26  the loss is =  0.027078570798039436  and accuracy is =  0.769\n",
            "At step  20  and at epoch =  27  the loss is =  0.02559526264667511  and accuracy is =  0.7665714285714286\n",
            "At step  20  and at epoch =  28  the loss is =  0.026714570820331573  and accuracy is =  0.7641428571428571\n",
            "At step  20  and at epoch =  29  the loss is =  0.028243325650691986  and accuracy is =  0.7721428571428571\n",
            "At step  20  and at epoch =  30  the loss is =  0.027318062260746956  and accuracy is =  0.7937142857142857\n",
            "At step  20  and at epoch =  31  the loss is =  0.027620762586593628  and accuracy is =  0.7822857142857143\n",
            "At step  20  and at epoch =  32  the loss is =  0.025431767106056213  and accuracy is =  0.792\n",
            "At step  20  and at epoch =  33  the loss is =  0.02769326977431774  and accuracy is =  0.7818571428571428\n",
            "At step  20  and at epoch =  34  the loss is =  0.025006461888551712  and accuracy is =  0.7904285714285715\n",
            "At step  20  and at epoch =  35  the loss is =  0.02623962052166462  and accuracy is =  0.8015714285714286\n",
            "At step  20  and at epoch =  36  the loss is =  0.02804516814649105  and accuracy is =  0.7942857142857143\n",
            "At step  20  and at epoch =  37  the loss is =  0.02516787126660347  and accuracy is =  0.8007142857142857\n",
            "At step  20  and at epoch =  38  the loss is =  0.026223883032798767  and accuracy is =  0.7978571428571428\n",
            "At step  20  and at epoch =  39  the loss is =  0.02713119424879551  and accuracy is =  0.8011428571428572\n",
            "At step  20  and at epoch =  40  the loss is =  0.024087922647595406  and accuracy is =  0.7967142857142857\n",
            "At step  20  and at epoch =  41  the loss is =  0.02550634928047657  and accuracy is =  0.8044285714285714\n",
            "At step  20  and at epoch =  42  the loss is =  0.025589097291231155  and accuracy is =  0.8124285714285714\n",
            "At step  20  and at epoch =  43  the loss is =  0.02413099631667137  and accuracy is =  0.819\n",
            "At step  20  and at epoch =  44  the loss is =  0.025013018399477005  and accuracy is =  0.8182857142857143\n",
            "At step  20  and at epoch =  45  the loss is =  0.027043307200074196  and accuracy is =  0.8125714285714286\n",
            "At step  20  and at epoch =  46  the loss is =  0.02687237784266472  and accuracy is =  0.82\n",
            "At step  20  and at epoch =  47  the loss is =  0.02679930068552494  and accuracy is =  0.8281428571428572\n",
            "At step  20  and at epoch =  48  the loss is =  0.02435433119535446  and accuracy is =  0.832\n",
            "At step  20  and at epoch =  49  the loss is =  0.021167168393731117  and accuracy is =  0.8644285714285714\n",
            "At step  20  and at epoch =  50  the loss is =  0.0207508634775877  and accuracy is =  0.8791428571428571\n",
            "At step  20  and at epoch =  51  the loss is =  0.022752858698368073  and accuracy is =  0.8775714285714286\n",
            "At step  20  and at epoch =  52  the loss is =  0.022601939737796783  and accuracy is =  0.8804285714285714\n",
            "At step  20  and at epoch =  53  the loss is =  0.023754511028528214  and accuracy is =  0.8831428571428571\n",
            "At step  20  and at epoch =  54  the loss is =  0.021747905761003494  and accuracy is =  0.8828571428571429\n",
            "At step  20  and at epoch =  55  the loss is =  0.021346868947148323  and accuracy is =  0.8821428571428571\n",
            "At step  20  and at epoch =  56  the loss is =  0.023482559248805046  and accuracy is =  0.8838571428571429\n",
            "At step  20  and at epoch =  57  the loss is =  0.02179368957877159  and accuracy is =  0.8892857142857142\n",
            "At step  20  and at epoch =  58  the loss is =  0.022036775946617126  and accuracy is =  0.8825714285714286\n",
            "At step  20  and at epoch =  59  the loss is =  0.02346174232661724  and accuracy is =  0.896\n",
            "At step  20  and at epoch =  60  the loss is =  0.018654217943549156  and accuracy is =  0.8878571428571429\n",
            "At step  20  and at epoch =  61  the loss is =  0.021214094012975693  and accuracy is =  0.9005714285714286\n",
            "At step  20  and at epoch =  62  the loss is =  0.019359085708856583  and accuracy is =  0.8901428571428571\n",
            "At step  20  and at epoch =  63  the loss is =  0.021839680150151253  and accuracy is =  0.8947142857142857\n",
            "At step  20  and at epoch =  64  the loss is =  0.022410143166780472  and accuracy is =  0.9062857142857143\n",
            "At step  20  and at epoch =  65  the loss is =  0.02103435806930065  and accuracy is =  0.9048571428571428\n",
            "At step  20  and at epoch =  66  the loss is =  0.022387469187378883  and accuracy is =  0.8947142857142857\n",
            "At step  20  and at epoch =  67  the loss is =  0.022159835323691368  and accuracy is =  0.9014285714285715\n",
            "At step  20  and at epoch =  68  the loss is =  0.020572248846292496  and accuracy is =  0.9058571428571428\n",
            "At step  20  and at epoch =  69  the loss is =  0.02125522680580616  and accuracy is =  0.9027142857142857\n",
            "task: 20 train accuracy = 0.3098\n",
            "task: 20 test accuracy = 0.2866666666666667\n",
            "At step  30  and at epoch =  0  the loss is =  0.04619542136788368  and accuracy is =  0.27303851640513555\n",
            "At step  30  and at epoch =  1  the loss is =  0.04168582707643509  and accuracy is =  0.35905848787446504\n",
            "At step  30  and at epoch =  2  the loss is =  0.042762063443660736  and accuracy is =  0.4356633380884451\n",
            "At step  30  and at epoch =  3  the loss is =  0.04092073440551758  and accuracy is =  0.4944365192582026\n",
            "At step  30  and at epoch =  4  the loss is =  0.039419520646333694  and accuracy is =  0.5273894436519259\n",
            "At step  30  and at epoch =  5  the loss is =  0.0385146401822567  and accuracy is =  0.5497860199714694\n",
            "At step  30  and at epoch =  6  the loss is =  0.04298367723822594  and accuracy is =  0.57660485021398\n",
            "At step  30  and at epoch =  7  the loss is =  0.03637894243001938  and accuracy is =  0.5855920114122682\n",
            "At step  30  and at epoch =  8  the loss is =  0.038900136947631836  and accuracy is =  0.6131241084165477\n",
            "At step  30  and at epoch =  9  the loss is =  0.04062098264694214  and accuracy is =  0.6239657631954351\n",
            "At step  30  and at epoch =  10  the loss is =  0.03782176598906517  and accuracy is =  0.636376604850214\n",
            "At step  30  and at epoch =  11  the loss is =  0.0364665612578392  and accuracy is =  0.6445078459343795\n",
            "At step  30  and at epoch =  12  the loss is =  0.03844126686453819  and accuracy is =  0.6639087018544936\n",
            "At step  30  and at epoch =  13  the loss is =  0.03805715590715408  and accuracy is =  0.6746077032810271\n",
            "At step  30  and at epoch =  14  the loss is =  0.03719716519117355  and accuracy is =  0.6767475035663338\n",
            "At step  30  and at epoch =  15  the loss is =  0.039365462958812714  and accuracy is =  0.6864479315263908\n",
            "At step  30  and at epoch =  16  the loss is =  0.03713610768318176  and accuracy is =  0.6905848787446505\n",
            "At step  30  and at epoch =  17  the loss is =  0.03676920011639595  and accuracy is =  0.6931526390870185\n",
            "At step  30  and at epoch =  18  the loss is =  0.03819875046610832  and accuracy is =  0.7047075606276747\n",
            "At step  30  and at epoch =  19  the loss is =  0.03481583669781685  and accuracy is =  0.7119828815977175\n",
            "At step  30  and at epoch =  20  the loss is =  0.037170421332120895  and accuracy is =  0.7216833095577746\n",
            "At step  30  and at epoch =  21  the loss is =  0.03694266080856323  and accuracy is =  0.7229671897289587\n",
            "At step  30  and at epoch =  22  the loss is =  0.036534205079078674  and accuracy is =  0.7248216833095578\n",
            "At step  30  and at epoch =  23  the loss is =  0.041245102882385254  and accuracy is =  0.7302425106990015\n",
            "At step  30  and at epoch =  24  the loss is =  0.0365181639790535  and accuracy is =  0.7382310984308131\n",
            "At step  30  and at epoch =  25  the loss is =  0.03654463216662407  and accuracy is =  0.7386590584878745\n",
            "At step  30  and at epoch =  26  the loss is =  0.03775366395711899  and accuracy is =  0.7485021398002853\n",
            "At step  30  and at epoch =  27  the loss is =  0.03793682903051376  and accuracy is =  0.7566333808844508\n",
            "At step  30  and at epoch =  28  the loss is =  0.03662368655204773  and accuracy is =  0.7562054208273894\n",
            "At step  30  and at epoch =  29  the loss is =  0.03540413826704025  and accuracy is =  0.7527817403708987\n",
            "At step  30  and at epoch =  30  the loss is =  0.03717535361647606  and accuracy is =  0.7613409415121255\n",
            "At step  30  and at epoch =  31  the loss is =  0.03546098247170448  and accuracy is =  0.7659058487874465\n",
            "At step  30  and at epoch =  32  the loss is =  0.03229380398988724  and accuracy is =  0.7679029957203994\n",
            "At step  30  and at epoch =  33  the loss is =  0.03592221066355705  and accuracy is =  0.7691868758915834\n",
            "At step  30  and at epoch =  34  the loss is =  0.03746093064546585  and accuracy is =  0.787018544935806\n",
            "At step  30  and at epoch =  35  the loss is =  0.03563098609447479  and accuracy is =  0.7750356633380885\n",
            "At step  30  and at epoch =  36  the loss is =  0.03638656809926033  and accuracy is =  0.7858773181169757\n",
            "At step  30  and at epoch =  37  the loss is =  0.03354865685105324  and accuracy is =  0.7808844507845935\n",
            "At step  30  and at epoch =  38  the loss is =  0.036590825766325  and accuracy is =  0.7840228245363766\n",
            "At step  30  and at epoch =  39  the loss is =  0.0342593677341938  and accuracy is =  0.7845934379457917\n",
            "At step  30  and at epoch =  40  the loss is =  0.036843761801719666  and accuracy is =  0.785734664764622\n",
            "At step  30  and at epoch =  41  the loss is =  0.03674480319023132  and accuracy is =  0.7935805991440799\n",
            "At step  30  and at epoch =  42  the loss is =  0.03584510460495949  and accuracy is =  0.7898716119828816\n",
            "At step  30  and at epoch =  43  the loss is =  0.033619146794080734  and accuracy is =  0.7961483594864479\n",
            "At step  30  and at epoch =  44  the loss is =  0.0340755470097065  and accuracy is =  0.8084165477888731\n",
            "At step  30  and at epoch =  45  the loss is =  0.03808381408452988  and accuracy is =  0.8091298145506419\n",
            "At step  30  and at epoch =  46  the loss is =  0.034909654408693314  and accuracy is =  0.7978601997146932\n",
            "At step  30  and at epoch =  47  the loss is =  0.03271554782986641  and accuracy is =  0.7992867332382311\n",
            "At step  30  and at epoch =  48  the loss is =  0.03784666582942009  and accuracy is =  0.7971469329529244\n",
            "At step  30  and at epoch =  49  the loss is =  0.030502017587423325  and accuracy is =  0.8402282453637661\n",
            "At step  30  and at epoch =  50  the loss is =  0.033996496349573135  and accuracy is =  0.8537803138373752\n",
            "At step  30  and at epoch =  51  the loss is =  0.028653975576162338  and accuracy is =  0.8593437945791726\n",
            "At step  30  and at epoch =  52  the loss is =  0.03303731232881546  and accuracy is =  0.8629101283880172\n",
            "At step  30  and at epoch =  53  the loss is =  0.031566448509693146  and accuracy is =  0.8708987161198288\n",
            "At step  30  and at epoch =  54  the loss is =  0.030969757586717606  and accuracy is =  0.869472182596291\n",
            "At step  30  and at epoch =  55  the loss is =  0.02788953110575676  and accuracy is =  0.8707560627674751\n",
            "At step  30  and at epoch =  56  the loss is =  0.03456037491559982  and accuracy is =  0.877888730385164\n",
            "At step  30  and at epoch =  57  the loss is =  0.028923626989126205  and accuracy is =  0.8754636233951498\n",
            "At step  30  and at epoch =  58  the loss is =  0.030529111623764038  and accuracy is =  0.8810271041369472\n",
            "At step  30  and at epoch =  59  the loss is =  0.029370203614234924  and accuracy is =  0.8805991440798859\n",
            "At step  30  and at epoch =  60  the loss is =  0.02817952074110508  and accuracy is =  0.8838801711840228\n",
            "At step  30  and at epoch =  61  the loss is =  0.029566612094640732  and accuracy is =  0.8818830242510699\n",
            "At step  30  and at epoch =  62  the loss is =  0.030328337103128433  and accuracy is =  0.8777460770328103\n",
            "At step  30  and at epoch =  63  the loss is =  0.028965653851628304  and accuracy is =  0.8854493580599144\n",
            "At step  30  and at epoch =  64  the loss is =  0.028586121276021004  and accuracy is =  0.8838801711840228\n",
            "At step  30  and at epoch =  65  the loss is =  0.027141353115439415  and accuracy is =  0.88830242510699\n",
            "At step  30  and at epoch =  66  the loss is =  0.029758518561720848  and accuracy is =  0.8911554921540656\n",
            "At step  30  and at epoch =  67  the loss is =  0.028587456792593002  and accuracy is =  0.8895863052781741\n",
            "At step  30  and at epoch =  68  the loss is =  0.031239870935678482  and accuracy is =  0.889015691868759\n",
            "At step  30  and at epoch =  69  the loss is =  0.03142617270350456  and accuracy is =  0.8942938659058488\n",
            "task: 30 train accuracy = 0.2362\n",
            "task: 30 test accuracy = 0.26175\n",
            "At step  40  and at epoch =  0  the loss is =  0.05519827827811241  and accuracy is =  0.26471428571428574\n",
            "At step  40  and at epoch =  1  the loss is =  0.05441681668162346  and accuracy is =  0.3078571428571429\n",
            "At step  40  and at epoch =  2  the loss is =  0.05516519024968147  and accuracy is =  0.35528571428571426\n",
            "At step  40  and at epoch =  3  the loss is =  0.05748777091503143  and accuracy is =  0.3987142857142857\n",
            "At step  40  and at epoch =  4  the loss is =  0.05368183180689812  and accuracy is =  0.43257142857142855\n",
            "At step  40  and at epoch =  5  the loss is =  0.04903748631477356  and accuracy is =  0.4675714285714286\n",
            "At step  40  and at epoch =  6  the loss is =  0.05303844064474106  and accuracy is =  0.49742857142857144\n",
            "At step  40  and at epoch =  7  the loss is =  0.054351821541786194  and accuracy is =  0.5132857142857142\n",
            "At step  40  and at epoch =  8  the loss is =  0.04750507324934006  and accuracy is =  0.5352857142857143\n",
            "At step  40  and at epoch =  9  the loss is =  0.050359826534986496  and accuracy is =  0.553\n",
            "At step  40  and at epoch =  10  the loss is =  0.04655430093407631  and accuracy is =  0.5651428571428572\n",
            "At step  40  and at epoch =  11  the loss is =  0.0503833182156086  and accuracy is =  0.5804285714285714\n",
            "At step  40  and at epoch =  12  the loss is =  0.05035071447491646  and accuracy is =  0.5898571428571429\n",
            "At step  40  and at epoch =  13  the loss is =  0.054184943437576294  and accuracy is =  0.611\n",
            "At step  40  and at epoch =  14  the loss is =  0.04910587519407272  and accuracy is =  0.6117142857142858\n",
            "At step  40  and at epoch =  15  the loss is =  0.048574917018413544  and accuracy is =  0.6355714285714286\n",
            "At step  40  and at epoch =  16  the loss is =  0.04828796535730362  and accuracy is =  0.6402857142857142\n",
            "At step  40  and at epoch =  17  the loss is =  0.05284491181373596  and accuracy is =  0.6391428571428571\n",
            "At step  40  and at epoch =  18  the loss is =  0.05031498149037361  and accuracy is =  0.6518571428571428\n",
            "At step  40  and at epoch =  19  the loss is =  0.05018724501132965  and accuracy is =  0.66\n",
            "At step  40  and at epoch =  20  the loss is =  0.049189623445272446  and accuracy is =  0.6652857142857143\n",
            "At step  40  and at epoch =  21  the loss is =  0.04459041357040405  and accuracy is =  0.6694285714285715\n",
            "At step  40  and at epoch =  22  the loss is =  0.051050443202257156  and accuracy is =  0.6807142857142857\n",
            "At step  40  and at epoch =  23  the loss is =  0.047350864857435226  and accuracy is =  0.6831428571428572\n",
            "At step  40  and at epoch =  24  the loss is =  0.051055505871772766  and accuracy is =  0.6902857142857143\n",
            "At step  40  and at epoch =  25  the loss is =  0.048869796097278595  and accuracy is =  0.6981428571428572\n",
            "At step  40  and at epoch =  26  the loss is =  0.04782688245177269  and accuracy is =  0.7051428571428572\n",
            "At step  40  and at epoch =  27  the loss is =  0.04784044995903969  and accuracy is =  0.7117142857142857\n",
            "At step  40  and at epoch =  28  the loss is =  0.04699937254190445  and accuracy is =  0.7167142857142857\n",
            "At step  40  and at epoch =  29  the loss is =  0.04510340467095375  and accuracy is =  0.7115714285714285\n",
            "At step  40  and at epoch =  30  the loss is =  0.049718018621206284  and accuracy is =  0.7264285714285714\n",
            "At step  40  and at epoch =  31  the loss is =  0.048138536512851715  and accuracy is =  0.728\n",
            "At step  40  and at epoch =  32  the loss is =  0.04686914011836052  and accuracy is =  0.7384285714285714\n",
            "At step  40  and at epoch =  33  the loss is =  0.04621044546365738  and accuracy is =  0.7332857142857143\n",
            "At step  40  and at epoch =  34  the loss is =  0.04893331229686737  and accuracy is =  0.732\n",
            "At step  40  and at epoch =  35  the loss is =  0.04657147079706192  and accuracy is =  0.7414285714285714\n",
            "At step  40  and at epoch =  36  the loss is =  0.05017811059951782  and accuracy is =  0.7461428571428571\n",
            "At step  40  and at epoch =  37  the loss is =  0.04753483459353447  and accuracy is =  0.7494285714285714\n",
            "At step  40  and at epoch =  38  the loss is =  0.047323547303676605  and accuracy is =  0.7572857142857143\n",
            "At step  40  and at epoch =  39  the loss is =  0.044370491057634354  and accuracy is =  0.7641428571428571\n",
            "At step  40  and at epoch =  40  the loss is =  0.046469546854496  and accuracy is =  0.7562857142857143\n",
            "At step  40  and at epoch =  41  the loss is =  0.04909753426909447  and accuracy is =  0.7465714285714286\n",
            "At step  40  and at epoch =  42  the loss is =  0.04327114298939705  and accuracy is =  0.755\n",
            "At step  40  and at epoch =  43  the loss is =  0.047173816710710526  and accuracy is =  0.7588571428571429\n",
            "At step  40  and at epoch =  44  the loss is =  0.04875558614730835  and accuracy is =  0.7668571428571429\n",
            "At step  40  and at epoch =  45  the loss is =  0.04864078387618065  and accuracy is =  0.7668571428571429\n",
            "At step  40  and at epoch =  46  the loss is =  0.04861076921224594  and accuracy is =  0.7752857142857142\n",
            "At step  40  and at epoch =  47  the loss is =  0.04712258651852608  and accuracy is =  0.7792857142857142\n",
            "At step  40  and at epoch =  48  the loss is =  0.04736068844795227  and accuracy is =  0.7691428571428571\n",
            "At step  40  and at epoch =  49  the loss is =  0.043050020933151245  and accuracy is =  0.8157142857142857\n",
            "At step  40  and at epoch =  50  the loss is =  0.04215861111879349  and accuracy is =  0.8405714285714285\n",
            "At step  40  and at epoch =  51  the loss is =  0.039220865815877914  and accuracy is =  0.8465714285714285\n",
            "At step  40  and at epoch =  52  the loss is =  0.039172012358903885  and accuracy is =  0.8511428571428571\n",
            "At step  40  and at epoch =  53  the loss is =  0.04208596795797348  and accuracy is =  0.8514285714285714\n",
            "At step  40  and at epoch =  54  the loss is =  0.04455329850316048  and accuracy is =  0.8575714285714285\n",
            "At step  40  and at epoch =  55  the loss is =  0.04213492572307587  and accuracy is =  0.8594285714285714\n",
            "At step  40  and at epoch =  56  the loss is =  0.041271843016147614  and accuracy is =  0.8624285714285714\n",
            "At step  40  and at epoch =  57  the loss is =  0.04161209613084793  and accuracy is =  0.8574285714285714\n",
            "At step  40  and at epoch =  58  the loss is =  0.03991830721497536  and accuracy is =  0.86\n",
            "At step  40  and at epoch =  59  the loss is =  0.043805696070194244  and accuracy is =  0.8612857142857143\n",
            "At step  40  and at epoch =  60  the loss is =  0.043337881565093994  and accuracy is =  0.864\n",
            "At step  40  and at epoch =  61  the loss is =  0.039376284927129745  and accuracy is =  0.8665714285714285\n",
            "At step  40  and at epoch =  62  the loss is =  0.03954940289258957  and accuracy is =  0.8662857142857143\n",
            "At step  40  and at epoch =  63  the loss is =  0.040811046957969666  and accuracy is =  0.8765714285714286\n",
            "At step  40  and at epoch =  64  the loss is =  0.03887009620666504  and accuracy is =  0.8738571428571429\n",
            "At step  40  and at epoch =  65  the loss is =  0.03913763538002968  and accuracy is =  0.8734285714285714\n",
            "At step  40  and at epoch =  66  the loss is =  0.03888005018234253  and accuracy is =  0.8747142857142857\n",
            "At step  40  and at epoch =  67  the loss is =  0.03946724534034729  and accuracy is =  0.8765714285714286\n",
            "At step  40  and at epoch =  68  the loss is =  0.03918575495481491  and accuracy is =  0.8817142857142857\n",
            "At step  40  and at epoch =  69  the loss is =  0.038518697023391724  and accuracy is =  0.8754285714285714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4_a4Ut-Or2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accs = [.897,.80,.76,.69,.64,.58,.54,.52,.48,.46]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAayIE_aPFWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "def plotTask(pars_tasks):\n",
        "\n",
        "  x_tasks =  np.linspace(10, 100, 10)\n",
        "\n",
        "  plt.plot(x_tasks, pars_tasks, label=['Accuracy'])\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylim(0,1)\n",
        "  plt.title('Accuracy over tasks')\n",
        "  plt.legend(['Accuracy'])\n",
        "  plt.grid(True)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RnKOCdaPM9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotTask(accs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06OjJ60-H0SI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.diagonal(cf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCn6mP7FH6w_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true = np.sum(cf, axis=1)\n",
        "true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dzn4m6VIYfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = np.sum(cf, axis=0)\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1QrlS0-Xiga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = np.array([137,  98, 142, 112,  39,  82, 116,  96, 145, 112,  84, 110,  59,\n",
        "        96,  73,  78,  50,  91,  98,  92,  64, 109,  91,  72,  38,  70,\n",
        "        76,  81,  89, 102,  81, 116,  72,  59, 177,  59,  62,  63,  93,\n",
        "        90,  72,  79, 102,  52, 162,  68,  67,  80,  65,  98,  80,  65,\n",
        "        84,  96, 121,  53,  77, 136,  69, 103,  76,  94, 109,  79, 126,\n",
        "        61, 126, 106, 182,  68, 122,  94,  90,  80,  80, 159,  98, 132,\n",
        "       145,  88, 170,  77,  79,  78, 131,  74, 149,  70, 149, 114, 102,\n",
        "       172, 212, 134, 124, 187, 189, 114, 126, 131])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlRx8JD01HDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 0\n",
        "for el, name in zip(pred,trainDS.__getClassesNames__()) :\n",
        "  print('classe', i, 'name', name, ',preds', el)\n",
        "  i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeuEDFid1qOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_splits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3bivRc41rd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainDS.__getClassesNames__()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}