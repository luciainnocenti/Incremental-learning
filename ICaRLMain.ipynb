{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ICaRLMain.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e8eeb35dbf94477286f049f43a84ce0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e4acd1b00e2d48a1a8cce60ee23fc866",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_86a1802f4d584a3aa730f458774a4cec",
              "IPY_MODEL_071f1e08de5c4560ae0151a238338801"
            ]
          }
        },
        "e4acd1b00e2d48a1a8cce60ee23fc866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86a1802f4d584a3aa730f458774a4cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a1c4db07cec4a6c85bdf1df7d86980b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_616a17e93918448794a9ef43cc2cb7de"
          }
        },
        "071f1e08de5c4560ae0151a238338801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a78542340a134c64a11b3cbaf465b0c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169009152/? [00:20&lt;00:00, 31951750.63it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_efec8dc4841045f383a655be8c974942"
          }
        },
        "6a1c4db07cec4a6c85bdf1df7d86980b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "616a17e93918448794a9ef43cc2cb7de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a78542340a134c64a11b3cbaf465b0c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "efec8dc4841045f383a655be8c974942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciainnocenti/IncrementalLearning/blob/master/ICaRLMain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLMLAOPyrR1K",
        "colab_type": "text"
      },
      "source": [
        "# Import GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LqwZJLUlcYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVa_FlnxrXIk",
        "colab_type": "code",
        "outputId": "e42d6adc-ff1f-46ad-8977-79aa40920daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "if not os.path.isdir('./DatasetCIFAR'):\n",
        "  !git clone https://github.com/luciainnocenti/IncrementalLearning.git\n",
        "  !mv 'IncrementalLearning' 'DatasetCIFAR'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IncrementalLearning'...\n",
            "remote: Enumerating objects: 242, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/242)\u001b[K\rremote: Counting objects:   1% (3/242)\u001b[K\rremote: Counting objects:   2% (5/242)\u001b[K\rremote: Counting objects:   3% (8/242)\u001b[K\rremote: Counting objects:   4% (10/242)\u001b[K\rremote: Counting objects:   5% (13/242)\u001b[K\rremote: Counting objects:   6% (15/242)\u001b[K\rremote: Counting objects:   7% (17/242)\u001b[K\rremote: Counting objects:   8% (20/242)\u001b[K\rremote: Counting objects:   9% (22/242)\u001b[K\rremote: Counting objects:  10% (25/242)\u001b[K\rremote: Counting objects:  11% (27/242)\u001b[K\rremote: Counting objects:  12% (30/242)\u001b[K\rremote: Counting objects:  13% (32/242)\u001b[K\rremote: Counting objects:  14% (34/242)\u001b[K\rremote: Counting objects:  15% (37/242)\u001b[K\rremote: Counting objects:  16% (39/242)\u001b[K\rremote: Counting objects:  17% (42/242)\u001b[K\rremote: Counting objects:  18% (44/242)\u001b[K\rremote: Counting objects:  19% (46/242)\u001b[K\rremote: Counting objects:  20% (49/242)\u001b[K\rremote: Counting objects:  21% (51/242)\u001b[K\rremote: Counting objects:  22% (54/242)\u001b[K\rremote: Counting objects:  23% (56/242)\u001b[K\rremote: Counting objects:  24% (59/242)\u001b[K\rremote: Counting objects:  25% (61/242)\u001b[K\rremote: Counting objects:  26% (63/242)\u001b[K\rremote: Counting objects:  27% (66/242)\u001b[K\rremote: Counting objects:  28% (68/242)\u001b[K\rremote: Counting objects:  29% (71/242)\u001b[K\rremote: Counting objects:  30% (73/242)\u001b[K\rremote: Counting objects:  31% (76/242)\u001b[K\rremote: Counting objects:  32% (78/242)\u001b[K\rremote: Counting objects:  33% (80/242)\u001b[K\rremote: Counting objects:  34% (83/242)\u001b[K\rremote: Counting objects:  35% (85/242)\u001b[K\rremote: Counting objects:  36% (88/242)\u001b[K\rremote: Counting objects:  37% (90/242)\u001b[K\rremote: Counting objects:  38% (92/242)\u001b[K\rremote: Counting objects:  39% (95/242)\u001b[K\rremote: Counting objects:  40% (97/242)\u001b[K\rremote: Counting objects:  41% (100/242)\u001b[K\rremote: Counting objects:  42% (102/242)\u001b[K\rremote: Counting objects:  43% (105/242)\u001b[K\rremote: Counting objects:  44% (107/242)\u001b[K\rremote: Counting objects:  45% (109/242)\u001b[K\rremote: Counting objects:  46% (112/242)\u001b[K\rremote: Counting objects:  47% (114/242)\u001b[K\rremote: Counting objects:  48% (117/242)\u001b[K\rremote: Counting objects:  49% (119/242)\u001b[K\rremote: Counting objects:  50% (121/242)\u001b[K\rremote: Counting objects:  51% (124/242)\u001b[K\rremote: Counting objects:  52% (126/242)\u001b[K\rremote: Counting objects:  53% (129/242)\u001b[K\rremote: Counting objects:  54% (131/242)\u001b[K\rremote: Counting objects:  55% (134/242)\u001b[K\rremote: Counting objects:  56% (136/242)\u001b[K\rremote: Counting objects:  57% (138/242)\u001b[K\rremote: Counting objects:  58% (141/242)\u001b[K\rremote: Counting objects:  59% (143/242)\u001b[K\rremote: Counting objects:  60% (146/242)\u001b[K\rremote: Counting objects:  61% (148/242)\u001b[K\rremote: Counting objects:  62% (151/242)\u001b[K\rremote: Counting objects:  63% (153/242)\u001b[K\rremote: Counting objects:  64% (155/242)\u001b[K\rremote: Counting objects:  65% (158/242)\u001b[K\rremote: Counting objects:  66% (160/242)\u001b[K\rremote: Counting objects:  67% (163/242)\u001b[K\rremote: Counting objects:  68% (165/242)\u001b[K\rremote: Counting objects:  69% (167/242)\u001b[K\rremote: Counting objects:  70% (170/242)\u001b[K\rremote: Counting objects:  71% (172/242)\u001b[K\rremote: Counting objects:  72% (175/242)\u001b[K\rremote: Counting objects:  73% (177/242)\u001b[K\rremote: Counting objects:  74% (180/242)\u001b[K\rremote: Counting objects:  75% (182/242)\u001b[K\rremote: Counting objects:  76% (184/242)\u001b[K\rremote: Counting objects:  77% (187/242)\u001b[K\rremote: Counting objects:  78% (189/242)\u001b[K\rremote: Counting objects:  79% (192/242)\u001b[K\rremote: Counting objects:  80% (194/242)\u001b[K\rremote: Counting objects:  81% (197/242)\u001b[K\rremote: Counting objects:  82% (199/242)\u001b[K\rremote: Counting objects:  83% (201/242)\u001b[K\rremote: Counting objects:  84% (204/242)\u001b[K\rremote: Counting objects:  85% (206/242)\u001b[K\rremote: Counting objects:  86% (209/242)\u001b[K\rremote: Counting objects:  87% (211/242)\u001b[K\rremote: Counting objects:  88% (213/242)\u001b[K\rremote: Counting objects:  89% (216/242)\u001b[K\rremote: Counting objects:  90% (218/242)\u001b[K\rremote: Counting objects:  91% (221/242)\u001b[K\rremote: Counting objects:  92% (223/242)\u001b[K\rremote: Counting objects:  93% (226/242)\u001b[K\rremote: Counting objects:  94% (228/242)\u001b[K\rremote: Counting objects:  95% (230/242)\u001b[K\rremote: Counting objects:  96% (233/242)\u001b[K\rremote: Counting objects:  97% (235/242)\u001b[K\rremote: Counting objects:  98% (238/242)\u001b[K\rremote: Counting objects:  99% (240/242)\u001b[K\rremote: Counting objects: 100% (242/242)\u001b[K\rremote: Counting objects: 100% (242/242), done.\u001b[K\n",
            "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
            "remote: Total 1101 (delta 189), reused 98 (delta 98), pack-reused 859\u001b[K\n",
            "Receiving objects: 100% (1101/1101), 732.25 KiB | 2.02 MiB/s, done.\n",
            "Resolving deltas: 100% (697/697), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXQyHMXzrZ5A",
        "colab_type": "text"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c24pdNxurdv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from DatasetCIFAR.data_set import Dataset \n",
        "from DatasetCIFAR import ResNet\n",
        "from DatasetCIFAR import utils\n",
        "from DatasetCIFAR import params\n",
        "from DatasetCIFAR import ICaRLModel\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.nn import functional as F\n",
        "import random\n",
        "random.seed(params.SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FlAkShyryrf",
        "colab_type": "text"
      },
      "source": [
        "# Define Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP2iR2vl3Wiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transformer = transforms.Compose([transforms.RandomCrop(size = 32, padding=4),\n",
        "                                         transforms.RandomHorizontalFlip(),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transformer = transforms.Compose([transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CSNk0NlrvAL",
        "colab_type": "code",
        "outputId": "82545f65-ef05-407f-8639-86bc0ef7819b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "e8eeb35dbf94477286f049f43a84ce0f",
            "e4acd1b00e2d48a1a8cce60ee23fc866",
            "86a1802f4d584a3aa730f458774a4cec",
            "071f1e08de5c4560ae0151a238338801",
            "6a1c4db07cec4a6c85bdf1df7d86980b",
            "616a17e93918448794a9ef43cc2cb7de",
            "a78542340a134c64a11b3cbaf465b0c8",
            "efec8dc4841045f383a655be8c974942"
          ]
        }
      },
      "source": [
        "trainDS = Dataset(train=True, transform = train_transformer)\n",
        "testDS = Dataset(train=False, transform = test_transformer)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8eeb35dbf94477286f049f43a84ce0f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3ge3VayryJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_splits = trainDS.splits\n",
        "test_splits = testDS.splits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzxTlFF_rkfe",
        "colab_type": "text"
      },
      "source": [
        "# Define Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgZtPkiPrmQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ICaRL = ResNet.resnet32(num_classes=100)\n",
        "ICaRL =  ICaRL.to(params.DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI8EyFmpOikN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exemplars = [None]*100\n",
        "\n",
        "test_indexes =  []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcFjbBGrOMz6",
        "colab_type": "code",
        "outputId": "372cfc9f-23b0-424d-cdd1-6e7c82f9f04b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for task in range(0, 100, params.TASK_SIZE):\n",
        "  train_indexes = trainDS.__getIndexesGroups__(task)\n",
        "  test_indexes = test_indexes + testDS.__getIndexesGroups__(task)\n",
        "\n",
        "  train_dataset = Subset(trainDS, train_indexes)\n",
        "  test_dataset = Subset(testDS, test_indexes)\n",
        "\n",
        "  train_loader = DataLoader( train_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE)\n",
        "  test_loader = DataLoader( test_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE )\n",
        "\n",
        "  ICaRL, exemplars = ICaRLModel.incrementalTrain(task, trainDS, ICaRL, exemplars)\n",
        "\n",
        "  col = []\n",
        "  for i,x in enumerate( train_splits[ :int(task/10) + 1]) : \n",
        "    v = np.array(x)\n",
        "    col = np.concatenate( (col,v), axis = None)\n",
        "    col = col.astype(int)\n",
        "\n",
        "  total = 0.0\n",
        "  running_corrects = 0.0\n",
        "  for img, lbl, _ in train_loader:\n",
        "      img = img.float().to(params.DEVICE)\n",
        "      preds = ICaRLModel.classify(img, exemplars, ICaRL, task, trainDS)\n",
        "      preds = preds.to(params.DEVICE)\n",
        "      labels = utils.mapFunction(lbl, col).to(params.DEVICE)\n",
        "      #print(\"preds: \", preds.data)\n",
        "      #print(\"mapped labels: \", labels)\n",
        "      #print(\"labels: \", lbl)\n",
        "      total += len(lbl)\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "      #print(running_corrects)\n",
        "  accuracy = float(running_corrects/total)\n",
        "  print(f'task: {task}', f'train accuracy = {accuracy}')\n",
        "\n",
        "  total = 0.0\n",
        "  running_corrects = 0.0\n",
        "  for img, lbl, _ in test_loader:\n",
        "      img = img.float().to(params.DEVICE)\n",
        "      preds = ICaRLModel.classify(img, exemplars, ICaRL, task, trainDS)\n",
        "      preds = preds.to(params.DEVICE)\n",
        "      labels = utils.mapFunction(lbl, col).to(params.DEVICE)\n",
        "      #print(\"preds: \", preds.data)\n",
        "      #print(\"mapped labels: \", labels)\n",
        "      #print(\"labels: \", lbl)\n",
        "      total += len(lbl)\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "      #print(running_corrects)\n",
        "  accuracy = float(running_corrects/total)\n",
        "  print(f'task: {task}', f'test accuracy = {accuracy}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "col =  [94 63 74 21 35 56 91 96 87 48]\n",
            "col[:10] [94 63 74 21 35 56 91 96 87 48]\n",
            "At step  0  and at epoch =  0  the loss is =  0.0329253226518631  and accuracy is =  0.2016\n",
            "At step  0  and at epoch =  1  the loss is =  0.02331097237765789  and accuracy is =  0.4308\n",
            "At step  0  and at epoch =  2  the loss is =  0.022890929132699966  and accuracy is =  0.5354\n",
            "At step  0  and at epoch =  3  the loss is =  0.019808627665042877  and accuracy is =  0.5984\n",
            "At step  0  and at epoch =  4  the loss is =  0.028068995103240013  and accuracy is =  0.6618\n",
            "At step  0  and at epoch =  5  the loss is =  0.013831224292516708  and accuracy is =  0.6922\n",
            "At step  0  and at epoch =  6  the loss is =  0.018730686977505684  and accuracy is =  0.7268\n",
            "At step  0  and at epoch =  7  the loss is =  0.014727297239005566  and accuracy is =  0.73\n",
            "At step  0  and at epoch =  8  the loss is =  0.012814468704164028  and accuracy is =  0.7652\n",
            "At step  0  and at epoch =  9  the loss is =  0.02235836535692215  and accuracy is =  0.8002\n",
            "At step  0  and at epoch =  10  the loss is =  0.009562671184539795  and accuracy is =  0.7508\n",
            "At step  0  and at epoch =  11  the loss is =  0.019769418984651566  and accuracy is =  0.844\n",
            "At step  0  and at epoch =  12  the loss is =  0.008517228998243809  and accuracy is =  0.8166\n",
            "At step  0  and at epoch =  13  the loss is =  0.005407988093793392  and accuracy is =  0.8682\n",
            "At step  0  and at epoch =  14  the loss is =  0.013131272047758102  and accuracy is =  0.9066\n",
            "At step  0  and at epoch =  15  the loss is =  0.006811586674302816  and accuracy is =  0.864\n",
            "At step  0  and at epoch =  16  the loss is =  0.017339926213026047  and accuracy is =  0.9174\n",
            "At step  0  and at epoch =  17  the loss is =  0.008039012551307678  and accuracy is =  0.9166\n",
            "At step  0  and at epoch =  18  the loss is =  0.003230544738471508  and accuracy is =  0.9222\n",
            "At step  0  and at epoch =  19  the loss is =  0.0011488082818686962  and accuracy is =  0.952\n",
            "At step  0  and at epoch =  20  the loss is =  0.004836477804929018  and accuracy is =  0.982\n",
            "At step  0  and at epoch =  21  the loss is =  0.008323789574205875  and accuracy is =  0.9566\n",
            "At step  0  and at epoch =  22  the loss is =  0.009220329113304615  and accuracy is =  0.9426\n",
            "At step  0  and at epoch =  23  the loss is =  0.013300185091793537  and accuracy is =  0.8458\n",
            "At step  0  and at epoch =  24  the loss is =  0.004668640438467264  and accuracy is =  0.939\n",
            "At step  0  and at epoch =  25  the loss is =  0.006628200877457857  and accuracy is =  0.965\n",
            "At step  0  and at epoch =  26  the loss is =  0.0026658193673938513  and accuracy is =  0.9294\n",
            "At step  0  and at epoch =  27  the loss is =  0.010159347206354141  and accuracy is =  0.9768\n",
            "At step  0  and at epoch =  28  the loss is =  0.0018426378956064582  and accuracy is =  0.9826\n",
            "At step  0  and at epoch =  29  the loss is =  0.0037800425197929144  and accuracy is =  0.9866\n",
            "At step  0  and at epoch =  30  the loss is =  0.005869605578482151  and accuracy is =  0.9788\n",
            "At step  0  and at epoch =  31  the loss is =  0.026740053668618202  and accuracy is =  0.9512\n",
            "At step  0  and at epoch =  32  the loss is =  0.020356837660074234  and accuracy is =  0.8044\n",
            "At step  0  and at epoch =  33  the loss is =  0.010771430097520351  and accuracy is =  0.9064\n",
            "At step  0  and at epoch =  34  the loss is =  0.010540448129177094  and accuracy is =  0.9634\n",
            "At step  0  and at epoch =  35  the loss is =  0.005843364633619785  and accuracy is =  0.977\n",
            "At step  0  and at epoch =  36  the loss is =  0.009770995937287807  and accuracy is =  0.9856\n",
            "At step  0  and at epoch =  37  the loss is =  0.007943170145154  and accuracy is =  0.9788\n",
            "At step  0  and at epoch =  38  the loss is =  0.010168801061809063  and accuracy is =  0.9534\n",
            "At step  0  and at epoch =  39  the loss is =  0.023643633350729942  and accuracy is =  0.9232\n",
            "At step  0  and at epoch =  40  the loss is =  0.01765698939561844  and accuracy is =  0.8916\n",
            "At step  0  and at epoch =  41  the loss is =  0.004499050322920084  and accuracy is =  0.9496\n",
            "At step  0  and at epoch =  42  the loss is =  0.0030134343542158604  and accuracy is =  0.9814\n",
            "At step  0  and at epoch =  43  the loss is =  0.007843390107154846  and accuracy is =  0.9908\n",
            "At step  0  and at epoch =  44  the loss is =  0.009466390125453472  and accuracy is =  0.974\n",
            "At step  0  and at epoch =  45  the loss is =  0.016783254221081734  and accuracy is =  0.96\n",
            "At step  0  and at epoch =  46  the loss is =  0.012758765369653702  and accuracy is =  0.9546\n",
            "At step  0  and at epoch =  47  the loss is =  0.004241905175149441  and accuracy is =  0.9646\n",
            "At step  0  and at epoch =  48  the loss is =  0.006761111319065094  and accuracy is =  0.9806\n",
            "At step  0  and at epoch =  49  the loss is =  0.004096790682524443  and accuracy is =  0.9776\n",
            "At step  0  and at epoch =  50  the loss is =  0.008087120950222015  and accuracy is =  0.9648\n",
            "At step  0  and at epoch =  51  the loss is =  0.002360233571380377  and accuracy is =  0.9748\n",
            "At step  0  and at epoch =  52  the loss is =  0.0022980712819844484  and accuracy is =  0.9928\n",
            "At step  0  and at epoch =  53  the loss is =  0.0008289511315524578  and accuracy is =  0.9896\n",
            "At step  0  and at epoch =  54  the loss is =  0.0012795600341632962  and accuracy is =  0.9974\n",
            "At step  0  and at epoch =  55  the loss is =  0.005596700124442577  and accuracy is =  0.9972\n",
            "At step  0  and at epoch =  56  the loss is =  0.008054688572883606  and accuracy is =  0.9902\n",
            "At step  0  and at epoch =  57  the loss is =  0.018866801634430885  and accuracy is =  0.955\n",
            "At step  0  and at epoch =  58  the loss is =  0.014365771785378456  and accuracy is =  0.9348\n",
            "At step  0  and at epoch =  59  the loss is =  0.0024217755999416113  and accuracy is =  0.9436\n",
            "At step  0  and at epoch =  60  the loss is =  0.003195806173607707  and accuracy is =  0.9768\n",
            "At step  0  and at epoch =  61  the loss is =  0.0015734032494947314  and accuracy is =  0.9862\n",
            "At step  0  and at epoch =  62  the loss is =  0.007323790807276964  and accuracy is =  0.9948\n",
            "At step  0  and at epoch =  63  the loss is =  0.00373338395729661  and accuracy is =  0.9794\n",
            "At step  0  and at epoch =  64  the loss is =  0.020613521337509155  and accuracy is =  0.9894\n",
            "At step  0  and at epoch =  65  the loss is =  0.006710948888212442  and accuracy is =  0.953\n",
            "At step  0  and at epoch =  66  the loss is =  0.01419007033109665  and accuracy is =  0.954\n",
            "At step  0  and at epoch =  67  the loss is =  0.003277190262451768  and accuracy is =  0.968\n",
            "At step  0  and at epoch =  68  the loss is =  0.0009234884055331349  and accuracy is =  0.9888\n",
            "At step  0  and at epoch =  69  the loss is =  0.01317943911999464  and accuracy is =  0.9966\n",
            "task: 0 train accuracy = 0.9988\n",
            "task: 0 test accuracy = 0.781\n",
            "col =  [94 63 74 21 35 56 91 96 87 48 68 80 22 37 60 97 51 62 92 76]\n",
            "col[:10] [94 63 74 21 35 56 91 96 87 48]\n",
            "At step  10  and at epoch =  0  the loss is =  0.03048131801187992  and accuracy is =  0.3139800285306705\n",
            "At step  10  and at epoch =  1  the loss is =  0.025369465351104736  and accuracy is =  0.38487874465049926\n",
            "At step  10  and at epoch =  2  the loss is =  0.024496424943208694  and accuracy is =  0.46619115549215406\n",
            "At step  10  and at epoch =  3  the loss is =  0.021181907504796982  and accuracy is =  0.5306704707560628\n",
            "At step  10  and at epoch =  4  the loss is =  0.019797522574663162  and accuracy is =  0.5904422253922967\n",
            "At step  10  and at epoch =  5  the loss is =  0.015444559045135975  and accuracy is =  0.630527817403709\n",
            "At step  10  and at epoch =  6  the loss is =  0.018357133492827415  and accuracy is =  0.6861626248216833\n",
            "At step  10  and at epoch =  7  the loss is =  0.015134713612496853  and accuracy is =  0.7326676176890157\n",
            "At step  10  and at epoch =  8  the loss is =  0.013576040044426918  and accuracy is =  0.7728958630527818\n",
            "At step  10  and at epoch =  9  the loss is =  0.014297924004495144  and accuracy is =  0.8152639087018545\n",
            "At step  10  and at epoch =  10  the loss is =  0.01447361521422863  and accuracy is =  0.8355206847360913\n",
            "At step  10  and at epoch =  11  the loss is =  0.013010155409574509  and accuracy is =  0.8626248216833096\n",
            "At step  10  and at epoch =  12  the loss is =  0.012589983642101288  and accuracy is =  0.8701854493580599\n",
            "At step  10  and at epoch =  13  the loss is =  0.01349677238613367  and accuracy is =  0.8760342368045649\n",
            "At step  10  and at epoch =  14  the loss is =  0.01058977097272873  and accuracy is =  0.8777460770328103\n",
            "At step  10  and at epoch =  15  the loss is =  0.012613354250788689  and accuracy is =  0.8847360912981455\n",
            "At step  10  and at epoch =  16  the loss is =  0.011957280337810516  and accuracy is =  0.9051355206847361\n",
            "At step  10  and at epoch =  17  the loss is =  0.008794927969574928  and accuracy is =  0.9054208273894436\n",
            "At step  10  and at epoch =  18  the loss is =  0.01046706736087799  and accuracy is =  0.9211126961483594\n",
            "At step  10  and at epoch =  19  the loss is =  0.008913910016417503  and accuracy is =  0.9293865905848787\n",
            "At step  10  and at epoch =  20  the loss is =  0.010211671702563763  and accuracy is =  0.92339514978602\n",
            "At step  10  and at epoch =  21  the loss is =  0.008807992562651634  and accuracy is =  0.933095577746077\n",
            "At step  10  and at epoch =  22  the loss is =  0.010301115922629833  and accuracy is =  0.943509272467903\n",
            "At step  10  and at epoch =  23  the loss is =  0.008497615344822407  and accuracy is =  0.9452211126961484\n",
            "At step  10  and at epoch =  24  the loss is =  0.009532304480671883  and accuracy is =  0.9480741797432239\n",
            "At step  10  and at epoch =  25  the loss is =  0.008308004587888718  and accuracy is =  0.9495007132667618\n",
            "At step  10  and at epoch =  26  the loss is =  0.00774732930585742  and accuracy is =  0.9399429386590585\n",
            "At step  10  and at epoch =  27  the loss is =  0.00934221874922514  and accuracy is =  0.9405135520684736\n",
            "At step  10  and at epoch =  28  the loss is =  0.00952103827148676  and accuracy is =  0.9293865905848787\n",
            "At step  10  and at epoch =  29  the loss is =  0.011363234370946884  and accuracy is =  0.891583452211127\n",
            "At step  10  and at epoch =  30  the loss is =  0.012997846119105816  and accuracy is =  0.8673323823109843\n",
            "At step  10  and at epoch =  31  the loss is =  0.009959674440324306  and accuracy is =  0.9081312410841654\n",
            "At step  10  and at epoch =  32  the loss is =  0.010165566578507423  and accuracy is =  0.9342368045649073\n",
            "At step  10  and at epoch =  33  the loss is =  0.00839625671505928  and accuracy is =  0.9439372325249643\n",
            "At step  10  and at epoch =  34  the loss is =  0.007333616726100445  and accuracy is =  0.9549215406562054\n",
            "At step  10  and at epoch =  35  the loss is =  0.00778087368234992  and accuracy is =  0.9651925820256776\n",
            "At step  10  and at epoch =  36  the loss is =  0.009046770632266998  and accuracy is =  0.9583452211126962\n",
            "At step  10  and at epoch =  37  the loss is =  0.008053437806665897  and accuracy is =  0.9644793152639087\n",
            "At step  10  and at epoch =  38  the loss is =  0.008261993527412415  and accuracy is =  0.9620542082738944\n",
            "At step  10  and at epoch =  39  the loss is =  0.008421964012086391  and accuracy is =  0.9630527817403709\n",
            "At step  10  and at epoch =  40  the loss is =  0.008853219449520111  and accuracy is =  0.9747503566333808\n",
            "At step  10  and at epoch =  41  the loss is =  0.00703267939388752  and accuracy is =  0.9736091298145506\n",
            "At step  10  and at epoch =  42  the loss is =  0.006883316207677126  and accuracy is =  0.9728958630527818\n",
            "At step  10  and at epoch =  43  the loss is =  0.007875910960137844  and accuracy is =  0.9744650499286733\n",
            "At step  10  and at epoch =  44  the loss is =  0.008256340399384499  and accuracy is =  0.9767475035663338\n",
            "At step  10  and at epoch =  45  the loss is =  0.00739296805113554  and accuracy is =  0.9764621968616263\n",
            "At step  10  and at epoch =  46  the loss is =  0.00786616001278162  and accuracy is =  0.9756062767475036\n",
            "At step  10  and at epoch =  47  the loss is =  0.0076874028891325  and accuracy is =  0.9734664764621969\n",
            "At step  10  and at epoch =  48  the loss is =  0.007818405516445637  and accuracy is =  0.9707560627674751\n",
            "At step  10  and at epoch =  49  the loss is =  0.007544269785284996  and accuracy is =  0.9778887303851641\n",
            "At step  10  and at epoch =  50  the loss is =  0.007003461010754108  and accuracy is =  0.9748930099857347\n",
            "At step  10  and at epoch =  51  the loss is =  0.007115417160093784  and accuracy is =  0.9773181169757489\n",
            "At step  10  and at epoch =  52  the loss is =  0.007099640555679798  and accuracy is =  0.9734664764621969\n",
            "At step  10  and at epoch =  53  the loss is =  0.006794322282075882  and accuracy is =  0.9640513552068474\n",
            "At step  10  and at epoch =  54  the loss is =  0.00891588069498539  and accuracy is =  0.9617689015691869\n",
            "At step  10  and at epoch =  55  the loss is =  0.012610471807420254  and accuracy is =  0.9298145506419401\n",
            "At step  10  and at epoch =  56  the loss is =  0.01591348648071289  and accuracy is =  0.7964336661911555\n",
            "At step  10  and at epoch =  57  the loss is =  0.014064401388168335  and accuracy is =  0.8477888730385164\n",
            "At step  10  and at epoch =  58  the loss is =  0.010926229879260063  and accuracy is =  0.9067047075606277\n",
            "At step  10  and at epoch =  59  the loss is =  0.010150239802896976  and accuracy is =  0.9263908701854494\n",
            "At step  10  and at epoch =  60  the loss is =  0.010217777453362942  and accuracy is =  0.9412268188302425\n",
            "At step  10  and at epoch =  61  the loss is =  0.008704612962901592  and accuracy is =  0.9556348074179744\n",
            "At step  10  and at epoch =  62  the loss is =  0.008077282458543777  and accuracy is =  0.9593437945791726\n",
            "At step  10  and at epoch =  63  the loss is =  0.00802849791944027  and accuracy is =  0.965620542082739\n",
            "At step  10  and at epoch =  64  the loss is =  0.00682178745046258  and accuracy is =  0.968188302425107\n",
            "At step  10  and at epoch =  65  the loss is =  0.00691382959485054  and accuracy is =  0.9736091298145506\n",
            "At step  10  and at epoch =  66  the loss is =  0.008415602147579193  and accuracy is =  0.9734664764621969\n",
            "At step  10  and at epoch =  67  the loss is =  0.007103274576365948  and accuracy is =  0.9718972895863053\n",
            "At step  10  and at epoch =  68  the loss is =  0.008232967928051949  and accuracy is =  0.9763195435092724\n",
            "At step  10  and at epoch =  69  the loss is =  0.00934535264968872  and accuracy is =  0.9761768901569187\n",
            "task: 10 train accuracy = 0.9692\n",
            "task: 10 test accuracy = 0.64\n",
            "col =  [94 63 74 21 35 56 91 96 87 48 68 80 22 37 60 97 51 62 92 76 75 89 23 99\n",
            " 39 66 54 69 84 61]\n",
            "col[:10] [94 63 74 21 35 56 91 96 87 48]\n",
            "At step  20  and at epoch =  0  the loss is =  0.0402495414018631  and accuracy is =  0.27507122507122506\n",
            "At step  20  and at epoch =  1  the loss is =  0.034450870007276535  and accuracy is =  0.33632478632478635\n",
            "At step  20  and at epoch =  2  the loss is =  0.03310764580965042  and accuracy is =  0.4292022792022792\n",
            "At step  20  and at epoch =  3  the loss is =  0.029647279530763626  and accuracy is =  0.5119658119658119\n",
            "At step  20  and at epoch =  4  the loss is =  0.02833900786936283  and accuracy is =  0.5787749287749288\n",
            "At step  20  and at epoch =  5  the loss is =  0.0245054941624403  and accuracy is =  0.6487179487179487\n",
            "At step  20  and at epoch =  6  the loss is =  0.026067329570651054  and accuracy is =  0.7106837606837607\n",
            "At step  20  and at epoch =  7  the loss is =  0.02482098899781704  and accuracy is =  0.7418803418803419\n",
            "At step  20  and at epoch =  8  the loss is =  0.02348097413778305  and accuracy is =  0.7636752136752136\n",
            "At step  20  and at epoch =  9  the loss is =  0.020974760875105858  and accuracy is =  0.7951566951566952\n",
            "At step  20  and at epoch =  10  the loss is =  0.021856257691979408  and accuracy is =  0.8212250712250713\n",
            "At step  20  and at epoch =  11  the loss is =  0.023053722456097603  and accuracy is =  0.8209401709401709\n",
            "At step  20  and at epoch =  12  the loss is =  0.018697112798690796  and accuracy is =  0.848005698005698\n",
            "At step  20  and at epoch =  13  the loss is =  0.021643931046128273  and accuracy is =  0.8502849002849003\n",
            "At step  20  and at epoch =  14  the loss is =  0.021656466647982597  and accuracy is =  0.854985754985755\n",
            "At step  20  and at epoch =  15  the loss is =  0.019852694123983383  and accuracy is =  0.8643874643874644\n",
            "At step  20  and at epoch =  16  the loss is =  0.019684482365846634  and accuracy is =  0.870940170940171\n",
            "At step  20  and at epoch =  17  the loss is =  0.017557980492711067  and accuracy is =  0.8747863247863248\n",
            "At step  20  and at epoch =  18  the loss is =  0.018603503704071045  and accuracy is =  0.8951566951566952\n",
            "At step  20  and at epoch =  19  the loss is =  0.01885266788303852  and accuracy is =  0.9015669515669515\n",
            "At step  20  and at epoch =  20  the loss is =  0.017848530784249306  and accuracy is =  0.9035612535612536\n",
            "At step  20  and at epoch =  21  the loss is =  0.01721721515059471  and accuracy is =  0.9138176638176638\n",
            "At step  20  and at epoch =  22  the loss is =  0.017779797315597534  and accuracy is =  0.9153846153846154\n",
            "At step  20  and at epoch =  23  the loss is =  0.019220897927880287  and accuracy is =  0.911965811965812\n",
            "At step  20  and at epoch =  24  the loss is =  0.017458634451031685  and accuracy is =  0.9128205128205128\n",
            "At step  20  and at epoch =  25  the loss is =  0.018508464097976685  and accuracy is =  0.9113960113960113\n",
            "At step  20  and at epoch =  26  the loss is =  0.01930934563279152  and accuracy is =  0.9074074074074074\n",
            "At step  20  and at epoch =  27  the loss is =  0.018809949979186058  and accuracy is =  0.8982905982905983\n",
            "At step  20  and at epoch =  28  the loss is =  0.020277444273233414  and accuracy is =  0.8811965811965812\n",
            "At step  20  and at epoch =  29  the loss is =  0.02146655134856701  and accuracy is =  0.8722222222222222\n",
            "At step  20  and at epoch =  30  the loss is =  0.020521605387330055  and accuracy is =  0.8535612535612536\n",
            "At step  20  and at epoch =  31  the loss is =  0.021642202511429787  and accuracy is =  0.8717948717948718\n",
            "At step  20  and at epoch =  32  the loss is =  0.020181238651275635  and accuracy is =  0.8792022792022792\n",
            "At step  20  and at epoch =  33  the loss is =  0.017483169212937355  and accuracy is =  0.8971509971509971\n",
            "At step  20  and at epoch =  34  the loss is =  0.01934080757200718  and accuracy is =  0.9081196581196581\n",
            "At step  20  and at epoch =  35  the loss is =  0.017087602987885475  and accuracy is =  0.9233618233618234\n",
            "At step  20  and at epoch =  36  the loss is =  0.016122566536068916  and accuracy is =  0.9256410256410257\n",
            "At step  20  and at epoch =  37  the loss is =  0.018462704494595528  and accuracy is =  0.9361823361823362\n",
            "At step  20  and at epoch =  38  the loss is =  0.0171008612960577  and accuracy is =  0.9454415954415955\n",
            "At step  20  and at epoch =  39  the loss is =  0.01598483696579933  and accuracy is =  0.9454415954415955\n",
            "At step  20  and at epoch =  40  the loss is =  0.015477512031793594  and accuracy is =  0.9403133903133903\n",
            "At step  20  and at epoch =  41  the loss is =  0.017847083508968353  and accuracy is =  0.9467236467236467\n",
            "At step  20  and at epoch =  42  the loss is =  0.016730664297938347  and accuracy is =  0.9430199430199431\n",
            "At step  20  and at epoch =  43  the loss is =  0.015835819765925407  and accuracy is =  0.9487179487179487\n",
            "At step  20  and at epoch =  44  the loss is =  0.017547370865941048  and accuracy is =  0.9401709401709402\n",
            "At step  20  and at epoch =  45  the loss is =  0.017415616661310196  and accuracy is =  0.9411680911680912\n",
            "At step  20  and at epoch =  46  the loss is =  0.016848959028720856  and accuracy is =  0.9418803418803419\n",
            "At step  20  and at epoch =  47  the loss is =  0.014980075880885124  and accuracy is =  0.9434472934472935\n",
            "At step  20  and at epoch =  48  the loss is =  0.014847197569906712  and accuracy is =  0.9398860398860399\n",
            "At step  20  and at epoch =  49  the loss is =  0.01664438284933567  and accuracy is =  0.9393162393162393\n",
            "At step  20  and at epoch =  50  the loss is =  0.016962042078375816  and accuracy is =  0.9386039886039886\n",
            "At step  20  and at epoch =  51  the loss is =  0.015532092191278934  and accuracy is =  0.944017094017094\n",
            "At step  20  and at epoch =  52  the loss is =  0.015872536227107048  and accuracy is =  0.9319088319088319\n",
            "At step  20  and at epoch =  53  the loss is =  0.017879225313663483  and accuracy is =  0.9065527065527066\n",
            "At step  20  and at epoch =  54  the loss is =  0.03237610310316086  and accuracy is =  0.8280626780626781\n",
            "At step  20  and at epoch =  55  the loss is =  0.026234308257699013  and accuracy is =  0.7455840455840456\n",
            "At step  20  and at epoch =  56  the loss is =  0.019610125571489334  and accuracy is =  0.8428774928774929\n",
            "At step  20  and at epoch =  57  the loss is =  0.01899676024913788  and accuracy is =  0.8806267806267807\n",
            "At step  20  and at epoch =  58  the loss is =  0.01818128488957882  and accuracy is =  0.9116809116809117\n",
            "At step  20  and at epoch =  59  the loss is =  0.01755920611321926  and accuracy is =  0.9223646723646723\n",
            "At step  20  and at epoch =  60  the loss is =  0.016989940777420998  and accuracy is =  0.9260683760683761\n",
            "At step  20  and at epoch =  61  the loss is =  0.015002486295998096  and accuracy is =  0.9353276353276353\n",
            "At step  20  and at epoch =  62  the loss is =  0.016016339883208275  and accuracy is =  0.9427350427350427\n",
            "At step  20  and at epoch =  63  the loss is =  0.014955000951886177  and accuracy is =  0.9431623931623931\n",
            "At step  20  and at epoch =  64  the loss is =  0.015894832089543343  and accuracy is =  0.9404558404558404\n",
            "At step  20  and at epoch =  65  the loss is =  0.016553787514567375  and accuracy is =  0.946011396011396\n",
            "At step  20  and at epoch =  66  the loss is =  0.017285944893956184  and accuracy is =  0.9424501424501425\n",
            "At step  20  and at epoch =  67  the loss is =  0.015975618734955788  and accuracy is =  0.9417378917378917\n",
            "At step  20  and at epoch =  68  the loss is =  0.015402411110699177  and accuracy is =  0.9468660968660969\n",
            "At step  20  and at epoch =  69  the loss is =  0.015338835306465626  and accuracy is =  0.9458689458689459\n",
            "task: 20 train accuracy = 0.9308\n",
            "task: 20 test accuracy = 0.5546666666666666\n",
            "col =  [94 63 74 21 35 56 91 96 87 48 68 80 22 37 60 97 51 62 92 76 75 89 23 99\n",
            " 39 66 54 69 84 61 85 24 98 41 73 58 78 77 70 49]\n",
            "col[:10] [94 63 74 21 35 56 91 96 87 48]\n",
            "At step  30  and at epoch =  0  the loss is =  0.05155140906572342  and accuracy is =  0.25677603423680456\n",
            "At step  30  and at epoch =  1  the loss is =  0.04085521772503853  and accuracy is =  0.32895863052781743\n",
            "At step  30  and at epoch =  2  the loss is =  0.042357586324214935  and accuracy is =  0.40841654778887304\n",
            "At step  30  and at epoch =  3  the loss is =  0.03637894243001938  and accuracy is =  0.4841654778887304\n",
            "At step  30  and at epoch =  4  the loss is =  0.03398628905415535  and accuracy is =  0.5657631954350927\n",
            "At step  30  and at epoch =  5  the loss is =  0.03340285271406174  and accuracy is =  0.6276747503566333\n",
            "At step  30  and at epoch =  6  the loss is =  0.03519527614116669  and accuracy is =  0.6723252496433666\n",
            "At step  30  and at epoch =  7  the loss is =  0.03491821512579918  and accuracy is =  0.7299572039942939\n",
            "At step  30  and at epoch =  8  the loss is =  0.03142158314585686  and accuracy is =  0.7489300998573466\n",
            "At step  30  and at epoch =  9  the loss is =  0.03183405101299286  and accuracy is =  0.7804564907275321\n",
            "At step  30  and at epoch =  10  the loss is =  0.030500320717692375  and accuracy is =  0.8028530670470756\n",
            "At step  30  and at epoch =  11  the loss is =  0.030108243227005005  and accuracy is =  0.8131241084165478\n",
            "At step  30  and at epoch =  12  the loss is =  0.032283611595630646  and accuracy is =  0.8203994293865906\n",
            "At step  30  and at epoch =  13  the loss is =  0.028730172663927078  and accuracy is =  0.8316690442225392\n",
            "At step  30  and at epoch =  14  the loss is =  0.02780146338045597  and accuracy is =  0.8465049928673324\n",
            "At step  30  and at epoch =  15  the loss is =  0.029353437945246696  and accuracy is =  0.8554921540656205\n",
            "At step  30  and at epoch =  16  the loss is =  0.02729838527739048  and accuracy is =  0.8586305278174037\n",
            "At step  30  and at epoch =  17  the loss is =  0.02972862310707569  and accuracy is =  0.8587731811697575\n",
            "At step  30  and at epoch =  18  the loss is =  0.028750456869602203  and accuracy is =  0.8696148359486447\n",
            "At step  30  and at epoch =  19  the loss is =  0.026827774941921234  and accuracy is =  0.878601997146933\n",
            "At step  30  and at epoch =  20  the loss is =  0.02809254638850689  and accuracy is =  0.8894436519258203\n",
            "At step  30  and at epoch =  21  the loss is =  0.02645758166909218  and accuracy is =  0.8925820256776035\n",
            "At step  30  and at epoch =  22  the loss is =  0.02501550503075123  and accuracy is =  0.8935805991440798\n",
            "At step  30  and at epoch =  23  the loss is =  0.02650146558880806  and accuracy is =  0.8990014265335236\n",
            "At step  30  and at epoch =  24  the loss is =  0.025881662964820862  and accuracy is =  0.9015691868758916\n",
            "At step  30  and at epoch =  25  the loss is =  0.027985550463199615  and accuracy is =  0.8984308131241084\n",
            "At step  30  and at epoch =  26  the loss is =  0.028193477541208267  and accuracy is =  0.8997146932952924\n",
            "At step  30  and at epoch =  27  the loss is =  0.023600803688168526  and accuracy is =  0.9034236804564907\n",
            "At step  30  and at epoch =  28  the loss is =  0.02619488723576069  and accuracy is =  0.9048502139800285\n",
            "At step  30  and at epoch =  29  the loss is =  0.02660226635634899  and accuracy is =  0.9044222539229672\n",
            "At step  30  and at epoch =  30  the loss is =  0.02679404802620411  and accuracy is =  0.892867332382311\n",
            "At step  30  and at epoch =  31  the loss is =  0.029278505593538284  and accuracy is =  0.8947218259629102\n",
            "At step  30  and at epoch =  32  the loss is =  0.02732473611831665  and accuracy is =  0.865620542082739\n",
            "At step  30  and at epoch =  33  the loss is =  0.03214280679821968  and accuracy is =  0.8485021398002853\n",
            "At step  30  and at epoch =  34  the loss is =  0.032999180257320404  and accuracy is =  0.8286733238231099\n",
            "At step  30  and at epoch =  35  the loss is =  0.033228978514671326  and accuracy is =  0.8022824536376605\n",
            "At step  30  and at epoch =  36  the loss is =  0.029369257390499115  and accuracy is =  0.8366619115549215\n",
            "At step  30  and at epoch =  37  the loss is =  0.028698157519102097  and accuracy is =  0.8764621968616263\n",
            "At step  30  and at epoch =  38  the loss is =  0.02751290425658226  and accuracy is =  0.9011412268188302\n",
            "At step  30  and at epoch =  39  the loss is =  0.02762378565967083  and accuracy is =  0.9166904422253923\n",
            "At step  30  and at epoch =  40  the loss is =  0.024377217516303062  and accuracy is =  0.9268188302425107\n",
            "At step  30  and at epoch =  41  the loss is =  0.025260139256715775  and accuracy is =  0.9265335235378032\n",
            "At step  30  and at epoch =  42  the loss is =  0.024207917973399162  and accuracy is =  0.9265335235378032\n",
            "At step  30  and at epoch =  43  the loss is =  0.023220257833600044  and accuracy is =  0.933808844507846\n",
            "At step  30  and at epoch =  44  the loss is =  0.026563016697764397  and accuracy is =  0.9285306704707561\n",
            "At step  30  and at epoch =  45  the loss is =  0.023876970633864403  and accuracy is =  0.931811697574893\n",
            "At step  30  and at epoch =  46  the loss is =  0.02565203607082367  and accuracy is =  0.9312410841654779\n",
            "At step  30  and at epoch =  47  the loss is =  0.0249351616948843  and accuracy is =  0.9342368045649073\n",
            "At step  30  and at epoch =  48  the loss is =  0.024584319442510605  and accuracy is =  0.9313837375178317\n",
            "At step  30  and at epoch =  49  the loss is =  0.02467605285346508  and accuracy is =  0.931811697574893\n",
            "At step  30  and at epoch =  50  the loss is =  0.024788878858089447  and accuracy is =  0.931811697574893\n",
            "At step  30  and at epoch =  51  the loss is =  0.027576817199587822  and accuracy is =  0.9342368045649073\n",
            "At step  30  and at epoch =  52  the loss is =  0.02404256910085678  and accuracy is =  0.933095577746077\n",
            "At step  30  and at epoch =  53  the loss is =  0.02506554126739502  and accuracy is =  0.9350927246790299\n",
            "At step  30  and at epoch =  54  the loss is =  0.024561014026403427  and accuracy is =  0.9184022824536376\n",
            "At step  30  and at epoch =  55  the loss is =  0.02551983669400215  and accuracy is =  0.9256776034236804\n",
            "At step  30  and at epoch =  56  the loss is =  0.02660263329744339  and accuracy is =  0.9181169757489301\n",
            "At step  30  and at epoch =  57  the loss is =  0.028142213821411133  and accuracy is =  0.8918687589158345\n",
            "At step  30  and at epoch =  58  the loss is =  0.03255276381969452  and accuracy is =  0.8884450784593438\n",
            "At step  30  and at epoch =  59  the loss is =  0.0376334972679615  and accuracy is =  0.820827389443652\n",
            "At step  30  and at epoch =  60  the loss is =  0.03497207164764404  and accuracy is =  0.76490727532097\n",
            "At step  30  and at epoch =  61  the loss is =  0.02876187674701214  and accuracy is =  0.8024251069900142\n",
            "At step  30  and at epoch =  62  the loss is =  0.026408299803733826  and accuracy is =  0.8517831669044222\n",
            "At step  30  and at epoch =  63  the loss is =  0.024255922064185143  and accuracy is =  0.8888730385164051\n",
            "At step  30  and at epoch =  64  the loss is =  0.026354581117630005  and accuracy is =  0.9069900142653352\n",
            "At step  30  and at epoch =  65  the loss is =  0.024306591600179672  and accuracy is =  0.9263908701854494\n",
            "At step  30  and at epoch =  66  the loss is =  0.027850696817040443  and accuracy is =  0.9345221112696148\n",
            "At step  30  and at epoch =  67  the loss is =  0.026470161974430084  and accuracy is =  0.9355206847360913\n",
            "At step  30  and at epoch =  68  the loss is =  0.025380734354257584  and accuracy is =  0.9316690442225393\n",
            "At step  30  and at epoch =  69  the loss is =  0.022569729015231133  and accuracy is =  0.9385164051355207\n",
            "task: 30 train accuracy = 0.9212\n",
            "task: 30 test accuracy = 0.4915\n",
            "col =  [94 63 74 21 35 56 91 96 87 48 68 80 22 37 60 97 51 62 92 76 75 89 23 99\n",
            " 39 66 54 69 84 61 85 24 98 41 73 58 78 77 70 49 65 88 36 93 45 10 90 17\n",
            " 32 59]\n",
            "col[:10] [94 63 74 21 35 56 91 96 87 48]\n",
            "At step  40  and at epoch =  0  the loss is =  0.05497689172625542  and accuracy is =  0.24403409090909092\n",
            "At step  40  and at epoch =  1  the loss is =  0.0490654893219471  and accuracy is =  0.2948863636363636\n",
            "At step  40  and at epoch =  2  the loss is =  0.04950715973973274  and accuracy is =  0.36420454545454545\n",
            "At step  40  and at epoch =  3  the loss is =  0.04327360540628433  and accuracy is =  0.44417613636363634\n",
            "At step  40  and at epoch =  4  the loss is =  0.04405723512172699  and accuracy is =  0.5208806818181818\n",
            "At step  40  and at epoch =  5  the loss is =  0.04430297762155533  and accuracy is =  0.5785511363636363\n",
            "At step  40  and at epoch =  6  the loss is =  0.042394913733005524  and accuracy is =  0.6384943181818182\n",
            "At step  40  and at epoch =  7  the loss is =  0.043209321796894073  and accuracy is =  0.6873579545454546\n",
            "At step  40  and at epoch =  8  the loss is =  0.04083393141627312  and accuracy is =  0.7248579545454545\n",
            "At step  40  and at epoch =  9  the loss is =  0.043400563299655914  and accuracy is =  0.753125\n",
            "At step  40  and at epoch =  10  the loss is =  0.041468970477581024  and accuracy is =  0.7801136363636364\n",
            "At step  40  and at epoch =  11  the loss is =  0.039164721965789795  and accuracy is =  0.7920454545454545\n",
            "At step  40  and at epoch =  12  the loss is =  0.037949901074171066  and accuracy is =  0.8178977272727272\n",
            "At step  40  and at epoch =  13  the loss is =  0.03863222524523735  and accuracy is =  0.8248579545454545\n",
            "At step  40  and at epoch =  14  the loss is =  0.03787018358707428  and accuracy is =  0.8357954545454546\n",
            "At step  40  and at epoch =  15  the loss is =  0.034456755965948105  and accuracy is =  0.8436079545454546\n",
            "At step  40  and at epoch =  16  the loss is =  0.03409995511174202  and accuracy is =  0.8477272727272728\n",
            "At step  40  and at epoch =  17  the loss is =  0.03723848611116409  and accuracy is =  0.8632102272727272\n",
            "At step  40  and at epoch =  18  the loss is =  0.03791933134198189  and accuracy is =  0.8663352272727273\n",
            "At step  40  and at epoch =  19  the loss is =  0.036539945751428604  and accuracy is =  0.8633522727272728\n",
            "At step  40  and at epoch =  20  the loss is =  0.03663214296102524  and accuracy is =  0.8700284090909091\n",
            "At step  40  and at epoch =  21  the loss is =  0.035062603652477264  and accuracy is =  0.8681818181818182\n",
            "At step  40  and at epoch =  22  the loss is =  0.03657419607043266  and accuracy is =  0.8826704545454546\n",
            "At step  40  and at epoch =  23  the loss is =  0.037202730774879456  and accuracy is =  0.8772727272727273\n",
            "At step  40  and at epoch =  24  the loss is =  0.03659461811184883  and accuracy is =  0.8757102272727273\n",
            "At step  40  and at epoch =  25  the loss is =  0.036764636635780334  and accuracy is =  0.8772727272727273\n",
            "At step  40  and at epoch =  26  the loss is =  0.035994142293930054  and accuracy is =  0.8846590909090909\n",
            "At step  40  and at epoch =  27  the loss is =  0.037291787564754486  and accuracy is =  0.8789772727272728\n",
            "At step  40  and at epoch =  28  the loss is =  0.03769826889038086  and accuracy is =  0.8914772727272727\n",
            "At step  40  and at epoch =  29  the loss is =  0.036826666444540024  and accuracy is =  0.8872159090909091\n",
            "At step  40  and at epoch =  30  the loss is =  0.03477267175912857  and accuracy is =  0.890625\n",
            "At step  40  and at epoch =  31  the loss is =  0.035354133695364  and accuracy is =  0.8876420454545455\n",
            "At step  40  and at epoch =  32  the loss is =  0.03504834696650505  and accuracy is =  0.9004261363636363\n",
            "At step  40  and at epoch =  33  the loss is =  0.03577916696667671  and accuracy is =  0.8938920454545455\n",
            "At step  40  and at epoch =  34  the loss is =  0.03711223602294922  and accuracy is =  0.9001420454545455\n",
            "At step  40  and at epoch =  35  the loss is =  0.03742781654000282  and accuracy is =  0.9089488636363636\n",
            "At step  40  and at epoch =  36  the loss is =  0.035370834171772  and accuracy is =  0.9110795454545455\n",
            "At step  40  and at epoch =  37  the loss is =  0.03660375252366066  and accuracy is =  0.9086647727272728\n",
            "At step  40  and at epoch =  38  the loss is =  0.034884512424468994  and accuracy is =  0.9115056818181818\n",
            "At step  40  and at epoch =  39  the loss is =  0.03331393003463745  and accuracy is =  0.9109375\n",
            "At step  40  and at epoch =  40  the loss is =  0.03373662009835243  and accuracy is =  0.9115056818181818\n",
            "At step  40  and at epoch =  41  the loss is =  0.033521734178066254  and accuracy is =  0.9174715909090909\n",
            "At step  40  and at epoch =  42  the loss is =  0.03635949641466141  and accuracy is =  0.9098011363636364\n",
            "At step  40  and at epoch =  43  the loss is =  0.03484040126204491  and accuracy is =  0.9154829545454546\n",
            "At step  40  and at epoch =  44  the loss is =  0.035245269536972046  and accuracy is =  0.9154829545454546\n",
            "At step  40  and at epoch =  45  the loss is =  0.03374963626265526  and accuracy is =  0.9122159090909091\n",
            "At step  40  and at epoch =  46  the loss is =  0.0356430746614933  and accuracy is =  0.8960227272727272\n",
            "At step  40  and at epoch =  47  the loss is =  0.03958510607481003  and accuracy is =  0.8451704545454546\n",
            "At step  40  and at epoch =  48  the loss is =  0.049669139087200165  and accuracy is =  0.662784090909091\n",
            "At step  40  and at epoch =  49  the loss is =  0.042140331119298935  and accuracy is =  0.7123579545454546\n",
            "At step  40  and at epoch =  50  the loss is =  0.0386069193482399  and accuracy is =  0.8150568181818182\n",
            "At step  40  and at epoch =  51  the loss is =  0.039408016949892044  and accuracy is =  0.8585227272727273\n",
            "At step  40  and at epoch =  52  the loss is =  0.03789011016488075  and accuracy is =  0.8914772727272727\n",
            "At step  40  and at epoch =  53  the loss is =  0.0359179750084877  and accuracy is =  0.9170454545454545\n",
            "At step  40  and at epoch =  54  the loss is =  0.033736295998096466  and accuracy is =  0.9126420454545454\n",
            "At step  40  and at epoch =  55  the loss is =  0.03293502703309059  and accuracy is =  0.9264204545454545\n",
            "At step  40  and at epoch =  56  the loss is =  0.03528285026550293  and accuracy is =  0.9269886363636364\n",
            "At step  40  and at epoch =  57  the loss is =  0.034098681062459946  and accuracy is =  0.9264204545454545\n",
            "At step  40  and at epoch =  58  the loss is =  0.03389555215835571  and accuracy is =  0.9301136363636363\n",
            "At step  40  and at epoch =  59  the loss is =  0.03375747427344322  and accuracy is =  0.9248579545454545\n",
            "At step  40  and at epoch =  60  the loss is =  0.0346023254096508  and accuracy is =  0.9295454545454546\n",
            "At step  40  and at epoch =  61  the loss is =  0.03435017168521881  and accuracy is =  0.9255681818181818\n",
            "At step  40  and at epoch =  62  the loss is =  0.03250830993056297  and accuracy is =  0.9255681818181818\n",
            "At step  40  and at epoch =  63  the loss is =  0.03373988717794418  and accuracy is =  0.9261363636363636\n",
            "At step  40  and at epoch =  64  the loss is =  0.034190740436315536  and accuracy is =  0.9299715909090909\n",
            "At step  40  and at epoch =  65  the loss is =  0.03271842002868652  and accuracy is =  0.9242897727272728\n",
            "At step  40  and at epoch =  66  the loss is =  0.033953528851270676  and accuracy is =  0.9248579545454545\n",
            "At step  40  and at epoch =  67  the loss is =  0.0339568592607975  and accuracy is =  0.9255681818181818\n",
            "At step  40  and at epoch =  68  the loss is =  0.0350845530629158  and accuracy is =  0.9274147727272727\n",
            "At step  40  and at epoch =  69  the loss is =  0.03242840990424156  and accuracy is =  0.9262784090909091\n",
            "task: 40 train accuracy = 0.9116\n",
            "task: 40 test accuracy = 0.417\n",
            "col =  [94 63 74 21 35 56 91 96 87 48 68 80 22 37 60 97 51 62 92 76 75 89 23 99\n",
            " 39 66 54 69 84 61 85 24 98 41 73 58 78 77 70 49 65 88 36 93 45 10 90 17\n",
            " 32 59 83 43 53 11 86 19 38 30 40 50]\n",
            "col[:10] [94 63 74 21 35 56 91 96 87 48]\n",
            "At step  50  and at epoch =  0  the loss is =  0.08641839772462845  and accuracy is =  0.23375886524822695\n",
            "At step  50  and at epoch =  1  the loss is =  0.07521535456180573  and accuracy is =  0.28893617021276596\n",
            "At step  50  and at epoch =  2  the loss is =  0.06645230203866959  and accuracy is =  0.3580141843971631\n",
            "At step  50  and at epoch =  3  the loss is =  0.08932071179151535  and accuracy is =  0.4124822695035461\n",
            "At step  50  and at epoch =  4  the loss is =  0.07377756386995316  and accuracy is =  0.45475177304964537\n",
            "At step  50  and at epoch =  5  the loss is =  0.05332154408097267  and accuracy is =  0.49602836879432627\n",
            "At step  50  and at epoch =  6  the loss is =  0.07884251326322556  and accuracy is =  0.5756028368794326\n",
            "At step  50  and at epoch =  7  the loss is =  0.07047546654939651  and accuracy is =  0.6058156028368794\n",
            "At step  50  and at epoch =  8  the loss is =  0.05518217757344246  and accuracy is =  0.6429787234042553\n",
            "At step  50  and at epoch =  9  the loss is =  0.06779047101736069  and accuracy is =  0.6933333333333334\n",
            "At step  50  and at epoch =  10  the loss is =  0.07256551086902618  and accuracy is =  0.6646808510638298\n",
            "At step  50  and at epoch =  11  the loss is =  0.07944773882627487  and accuracy is =  0.700709219858156\n",
            "At step  50  and at epoch =  12  the loss is =  0.06345395743846893  and accuracy is =  0.6876595744680851\n",
            "At step  50  and at epoch =  13  the loss is =  0.06972610950469971  and accuracy is =  0.7397163120567376\n",
            "At step  50  and at epoch =  14  the loss is =  0.050354599952697754  and accuracy is =  0.7526241134751773\n",
            "At step  50  and at epoch =  15  the loss is =  0.04702937602996826  and accuracy is =  0.7822695035460993\n",
            "At step  50  and at epoch =  16  the loss is =  0.05085589736700058  and accuracy is =  0.8185815602836879\n",
            "At step  50  and at epoch =  17  the loss is =  0.0666700154542923  and accuracy is =  0.8268085106382979\n",
            "At step  50  and at epoch =  18  the loss is =  0.05212431028485298  and accuracy is =  0.7947517730496454\n",
            "At step  50  and at epoch =  19  the loss is =  0.061859775334596634  and accuracy is =  0.7495035460992908\n",
            "At step  50  and at epoch =  20  the loss is =  0.06546191871166229  and accuracy is =  0.7733333333333333\n",
            "At step  50  and at epoch =  21  the loss is =  0.05646851658821106  and accuracy is =  0.7974468085106383\n",
            "At step  50  and at epoch =  22  the loss is =  0.06286639720201492  and accuracy is =  0.8225531914893617\n",
            "At step  50  and at epoch =  23  the loss is =  0.0574437715113163  and accuracy is =  0.8307801418439716\n",
            "At step  50  and at epoch =  24  the loss is =  0.061135224997997284  and accuracy is =  0.849645390070922\n",
            "At step  50  and at epoch =  25  the loss is =  0.06800812482833862  and accuracy is =  0.84\n",
            "At step  50  and at epoch =  26  the loss is =  0.06817008554935455  and accuracy is =  0.8209929078014184\n",
            "At step  50  and at epoch =  27  the loss is =  0.04564075544476509  and accuracy is =  0.8478014184397163\n",
            "At step  50  and at epoch =  28  the loss is =  0.07022497057914734  and accuracy is =  0.8475177304964538\n",
            "At step  50  and at epoch =  29  the loss is =  0.06409124284982681  and accuracy is =  0.8140425531914893\n",
            "At step  50  and at epoch =  30  the loss is =  0.06280668079853058  and accuracy is =  0.8146099290780142\n",
            "At step  50  and at epoch =  31  the loss is =  0.051438890397548676  and accuracy is =  0.8361702127659575\n",
            "At step  50  and at epoch =  32  the loss is =  0.04802362620830536  and accuracy is =  0.8251063829787234\n",
            "At step  50  and at epoch =  33  the loss is =  0.05595651641488075  and accuracy is =  0.869645390070922\n",
            "At step  50  and at epoch =  34  the loss is =  0.06716269254684448  and accuracy is =  0.8382978723404255\n",
            "At step  50  and at epoch =  35  the loss is =  0.04921106994152069  and accuracy is =  0.8680851063829788\n",
            "At step  50  and at epoch =  36  the loss is =  0.04285600408911705  and accuracy is =  0.8778723404255319\n",
            "At step  50  and at epoch =  37  the loss is =  0.056352876126766205  and accuracy is =  0.8591489361702128\n",
            "At step  50  and at epoch =  38  the loss is =  0.049313243478536606  and accuracy is =  0.8787234042553191\n",
            "At step  50  and at epoch =  39  the loss is =  0.046707164496183395  and accuracy is =  0.8754609929078014\n",
            "At step  50  and at epoch =  40  the loss is =  0.046115443110466  and accuracy is =  0.8693617021276596\n",
            "At step  50  and at epoch =  41  the loss is =  0.04791717231273651  and accuracy is =  0.8889361702127659\n",
            "At step  50  and at epoch =  42  the loss is =  0.048636239022016525  and accuracy is =  0.8781560283687944\n",
            "At step  50  and at epoch =  43  the loss is =  0.05519136041402817  and accuracy is =  0.8721985815602837\n",
            "At step  50  and at epoch =  44  the loss is =  0.060421284288167953  and accuracy is =  0.7419858156028368\n",
            "At step  50  and at epoch =  45  the loss is =  0.04964771494269371  and accuracy is =  0.7451063829787234\n",
            "At step  50  and at epoch =  46  the loss is =  0.06591176986694336  and accuracy is =  0.8153191489361702\n",
            "At step  50  and at epoch =  47  the loss is =  0.06011126562952995  and accuracy is =  0.839290780141844\n",
            "At step  50  and at epoch =  48  the loss is =  0.056838586926460266  and accuracy is =  0.8719148936170212\n",
            "At step  50  and at epoch =  49  the loss is =  0.07368161529302597  and accuracy is =  0.8729078014184397\n",
            "At step  50  and at epoch =  50  the loss is =  0.035916224122047424  and accuracy is =  0.8565957446808511\n",
            "At step  50  and at epoch =  51  the loss is =  0.04799538105726242  and accuracy is =  0.8899290780141844\n",
            "At step  50  and at epoch =  52  the loss is =  0.0705055221915245  and accuracy is =  0.8886524822695036\n",
            "At step  50  and at epoch =  53  the loss is =  0.05802832543849945  and accuracy is =  0.8565957446808511\n",
            "At step  50  and at epoch =  54  the loss is =  0.05820264667272568  and accuracy is =  0.8666666666666667\n",
            "At step  50  and at epoch =  55  the loss is =  0.05823381617665291  and accuracy is =  0.8287943262411348\n",
            "At step  50  and at epoch =  56  the loss is =  0.06517791748046875  and accuracy is =  0.8341843971631205\n",
            "At step  50  and at epoch =  57  the loss is =  0.08073125034570694  and accuracy is =  0.8479432624113475\n",
            "At step  50  and at epoch =  58  the loss is =  0.05972346290946007  and accuracy is =  0.7686524822695036\n",
            "At step  50  and at epoch =  59  the loss is =  0.05490950867533684  and accuracy is =  0.7639716312056738\n",
            "At step  50  and at epoch =  60  the loss is =  0.05931973457336426  and accuracy is =  0.8319148936170213\n",
            "At step  50  and at epoch =  61  the loss is =  0.05183619633316994  and accuracy is =  0.8818439716312056\n",
            "At step  50  and at epoch =  62  the loss is =  0.05613298341631889  and accuracy is =  0.8929078014184397\n",
            "At step  50  and at epoch =  63  the loss is =  0.05367818474769592  and accuracy is =  0.8968794326241135\n",
            "At step  50  and at epoch =  64  the loss is =  0.06700433790683746  and accuracy is =  0.8933333333333333\n",
            "At step  50  and at epoch =  65  the loss is =  0.051241349428892136  and accuracy is =  0.8853900709219859\n",
            "At step  50  and at epoch =  66  the loss is =  0.058504071086645126  and accuracy is =  0.8601418439716312\n",
            "At step  50  and at epoch =  67  the loss is =  0.05114184692502022  and accuracy is =  0.8739007092198582\n",
            "At step  50  and at epoch =  68  the loss is =  0.07634630054235458  and accuracy is =  0.8899290780141844\n",
            "At step  50  and at epoch =  69  the loss is =  0.05609788000583649  and accuracy is =  0.8116312056737589\n",
            "task: 50 train accuracy = 0.8054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0C6HE4usvUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}