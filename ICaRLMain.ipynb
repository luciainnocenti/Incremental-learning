{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ICaRLMain.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d07722cf341d4607bf2f13a8036b81ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d4f7958432074d71ae26e376d97fa316",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ccf2d89439a24ac5b9f8a4ccca701244",
              "IPY_MODEL_788645529b6747b8ad7a440f97ba1bba"
            ]
          }
        },
        "d4f7958432074d71ae26e376d97fa316": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ccf2d89439a24ac5b9f8a4ccca701244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_14c70a3975d84aaabd291f37a49c3506",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d413f3728d574a35abb13f654a1a6ef4"
          }
        },
        "788645529b6747b8ad7a440f97ba1bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cb561ca46d9a48588ddbc1b8784a8333",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169009152/? [00:20&lt;00:00, 94260144.99it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f919b2b176ee4e9daff1f3e3a1fa6f13"
          }
        },
        "14c70a3975d84aaabd291f37a49c3506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d413f3728d574a35abb13f654a1a6ef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb561ca46d9a48588ddbc1b8784a8333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f919b2b176ee4e9daff1f3e3a1fa6f13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciainnocenti/IncrementalLearning/blob/daRunnareFrancy/ICaRLMain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLMLAOPyrR1K",
        "colab_type": "text"
      },
      "source": [
        "# Import GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LqwZJLUlcYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVa_FlnxrXIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7f2d88ec-d69a-4ec4-8f92-a1068dea0781"
      },
      "source": [
        "if not os.path.isdir('./DatasetCIFAR'):\n",
        "  !git clone -b daRunnareFrancy https://github.com/luciainnocenti/IncrementalLearning.git\n",
        "  !mv 'IncrementalLearning' 'DatasetCIFAR'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IncrementalLearning'...\n",
            "remote: Enumerating objects: 126, done.\u001b[K\n",
            "remote: Counting objects: 100% (126/126), done.\u001b[K\n",
            "remote: Compressing objects: 100% (126/126), done.\u001b[K\n",
            "remote: Total 1437 (delta 75), reused 0 (delta 0), pack-reused 1311\u001b[K\n",
            "Receiving objects: 100% (1437/1437), 946.21 KiB | 8.60 MiB/s, done.\n",
            "Resolving deltas: 100% (917/917), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXQyHMXzrZ5A",
        "colab_type": "text"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c24pdNxurdv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from DatasetCIFAR.data_set import Dataset \n",
        "from DatasetCIFAR.data_set import Subset\n",
        "from DatasetCIFAR import ResNet\n",
        "from DatasetCIFAR import utils\n",
        "from DatasetCIFAR import params\n",
        "from DatasetCIFAR import ICaRLModel\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import functional as F\n",
        "import random\n",
        "random.seed(params.SEED)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2rkcBbIKfUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cdb9d1af-84d9-40dd-9c58-b87213a8dab4"
      },
      "source": [
        "print(params.SEED)\n",
        "print(params.NUM_WORKERS)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "653\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FlAkShyryrf",
        "colab_type": "text"
      },
      "source": [
        "# Define Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP2iR2vl3Wiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transformer = transforms.Compose([transforms.RandomCrop(size = 32, padding=4),\n",
        "                                         transforms.RandomHorizontalFlip(),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transformer = transforms.Compose([transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CSNk0NlrvAL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "d07722cf341d4607bf2f13a8036b81ec",
            "d4f7958432074d71ae26e376d97fa316",
            "ccf2d89439a24ac5b9f8a4ccca701244",
            "788645529b6747b8ad7a440f97ba1bba",
            "14c70a3975d84aaabd291f37a49c3506",
            "d413f3728d574a35abb13f654a1a6ef4",
            "cb561ca46d9a48588ddbc1b8784a8333",
            "f919b2b176ee4e9daff1f3e3a1fa6f13"
          ]
        },
        "outputId": "edd4ed3a-59d3-4d2f-a9fd-3a6ab6e1c1e0"
      },
      "source": [
        "trainDS = Dataset(train=True)\n",
        "testDS = Dataset(train=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d07722cf341d4607bf2f13a8036b81ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3ge3VayryJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_splits = trainDS.splits\n",
        "test_splits = testDS.splits"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzxTlFF_rkfe",
        "colab_type": "text"
      },
      "source": [
        "# Define Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgZtPkiPrmQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ICaRL = ResNet.resnet32(num_classes=100)\n",
        "ICaRL =  ICaRL.to(params.DEVICE)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI8EyFmpOikN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exemplars = [None]*100\n",
        "\n",
        "test_indexes =  []"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcFjbBGrOMz6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "45f53ef1-7358-4e62-e99e-569433bfc3c3"
      },
      "source": [
        "for task in range(0, 100, params.TASK_SIZE):\n",
        "  train_indexes = trainDS.__getIndexesGroups__(task)\n",
        "  test_indexes = test_indexes + testDS.__getIndexesGroups__(task)\n",
        "\n",
        "  train_dataset = Subset(trainDS, train_indexes, transform = train_transformer)\n",
        "  test_dataset = Subset(testDS, test_indexes, transform = test_transformer)\n",
        "\n",
        "  train_loader = DataLoader( train_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE, shuffle=True)\n",
        "  test_loader = DataLoader( test_dataset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE , shuffle=True )\n",
        "\n",
        "  ICaRL, exemplars = ICaRLModel.incrementalTrain(task, trainDS, ICaRL, exemplars, train_transformer)\n",
        "\n",
        "  col = []\n",
        "  for i,x in enumerate( train_splits[ :int(task/10) + 1]) : \n",
        "    v = np.array(x)\n",
        "    col = np.concatenate( (col,v), axis = None)\n",
        "    col = col.astype(int)\n",
        "  mean = None\n",
        "  total = 0.0\n",
        "  running_corrects = 0.0\n",
        "  for img, lbl, _ in train_loader:\n",
        "      img = img.float().to(params.DEVICE)\n",
        "      preds, mean = ICaRLModel.classify(img, exemplars, ICaRL, task, trainDS, mean)\n",
        "      preds = preds.to(params.DEVICE)\n",
        "      labels = utils.mapFunction(lbl, col).to(params.DEVICE)\n",
        "      #print(\"preds: \", preds.data)\n",
        "      #print(\"mapped labels: \", labels)\n",
        "      #print(\"labels: \", lbl)\n",
        "      total += len(lbl)\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "      #print(running_corrects)\n",
        "  accuracy = float(running_corrects/total)\n",
        "  print(f'task: {task}', f'train accuracy = {accuracy}')\n",
        "\n",
        "  total = 0.0\n",
        "  running_corrects = 0.0\n",
        "  for img, lbl, _ in test_loader:\n",
        "      img = img.float().to(params.DEVICE)\n",
        "      preds, _ = ICaRLModel.classify(img, exemplars, ICaRL, task, trainDS, mean)\n",
        "      preds = preds.to(params.DEVICE)\n",
        "      labels = utils.mapFunction(lbl, col).to(params.DEVICE)\n",
        "      #print(\"preds: \", preds.data)\n",
        "      #print(\"mapped labels: \", labels)\n",
        "      #print(\"labels: \", lbl)\n",
        "      total += len(lbl)\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "      #print(running_corrects)\n",
        "  accuracy = float(running_corrects/total)\n",
        "  print(f'task: {task}', f'test accuracy = {accuracy}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "At step  0  and at epoch =  0  the loss is =  0.029667191207408905  and accuracy is =  0.185\n",
            "At step  0  and at epoch =  1  the loss is =  0.028233041986823082  and accuracy is =  0.3734\n",
            "At step  0  and at epoch =  2  the loss is =  0.018071454018354416  and accuracy is =  0.465\n",
            "At step  0  and at epoch =  3  the loss is =  0.02255549468100071  and accuracy is =  0.5108\n",
            "At step  0  and at epoch =  4  the loss is =  0.014904298819601536  and accuracy is =  0.5284\n",
            "At step  0  and at epoch =  5  the loss is =  0.01924349181354046  and accuracy is =  0.59\n",
            "At step  0  and at epoch =  6  the loss is =  0.010225322097539902  and accuracy is =  0.6086\n",
            "At step  0  and at epoch =  7  the loss is =  0.031309131532907486  and accuracy is =  0.6466\n",
            "At step  0  and at epoch =  8  the loss is =  0.025189409032464027  and accuracy is =  0.6548\n",
            "At step  0  and at epoch =  9  the loss is =  0.01838390715420246  and accuracy is =  0.6782\n",
            "At step  0  and at epoch =  10  the loss is =  0.015962667763233185  and accuracy is =  0.7222\n",
            "At step  0  and at epoch =  11  the loss is =  0.012832272797822952  and accuracy is =  0.7216\n",
            "At step  0  and at epoch =  12  the loss is =  0.02871723659336567  and accuracy is =  0.7352\n",
            "At step  0  and at epoch =  13  the loss is =  0.026578744873404503  and accuracy is =  0.7496\n",
            "At step  0  and at epoch =  14  the loss is =  0.010073299519717693  and accuracy is =  0.7376\n",
            "At step  0  and at epoch =  15  the loss is =  0.013013009913265705  and accuracy is =  0.7768\n",
            "At step  0  and at epoch =  16  the loss is =  0.02343682199716568  and accuracy is =  0.781\n",
            "At step  0  and at epoch =  17  the loss is =  0.010275359265506268  and accuracy is =  0.7706\n",
            "At step  0  and at epoch =  18  the loss is =  0.010549857281148434  and accuracy is =  0.8098\n",
            "At step  0  and at epoch =  19  the loss is =  0.011031167581677437  and accuracy is =  0.7992\n",
            "At step  0  and at epoch =  20  the loss is =  0.014228460378944874  and accuracy is =  0.825\n",
            "At step  0  and at epoch =  21  the loss is =  0.01798008568584919  and accuracy is =  0.8102\n",
            "At step  0  and at epoch =  22  the loss is =  0.015845686197280884  and accuracy is =  0.8046\n",
            "At step  0  and at epoch =  23  the loss is =  0.020304402336478233  and accuracy is =  0.828\n",
            "At step  0  and at epoch =  24  the loss is =  0.018838953226804733  and accuracy is =  0.8044\n",
            "At step  0  and at epoch =  25  the loss is =  0.00700331898406148  and accuracy is =  0.84\n",
            "At step  0  and at epoch =  26  the loss is =  0.01846075989305973  and accuracy is =  0.8562\n",
            "At step  0  and at epoch =  27  the loss is =  0.005967973731458187  and accuracy is =  0.806\n",
            "At step  0  and at epoch =  28  the loss is =  0.009488514624536037  and accuracy is =  0.8598\n",
            "At step  0  and at epoch =  29  the loss is =  0.015743879601359367  and accuracy is =  0.8402\n",
            "At step  0  and at epoch =  30  the loss is =  0.0037669965531677008  and accuracy is =  0.8588\n",
            "At step  0  and at epoch =  31  the loss is =  0.003760670544579625  and accuracy is =  0.8846\n",
            "At step  0  and at epoch =  32  the loss is =  0.023094143718481064  and accuracy is =  0.8808\n",
            "At step  0  and at epoch =  33  the loss is =  0.013564394786953926  and accuracy is =  0.8408\n",
            "At step  0  and at epoch =  34  the loss is =  0.019602514803409576  and accuracy is =  0.8698\n",
            "At step  0  and at epoch =  35  the loss is =  0.01251919474452734  and accuracy is =  0.8788\n",
            "At step  0  and at epoch =  36  the loss is =  0.013260383158922195  and accuracy is =  0.8524\n",
            "At step  0  and at epoch =  37  the loss is =  0.0028546506073325872  and accuracy is =  0.8754\n",
            "At step  0  and at epoch =  38  the loss is =  0.010255402885377407  and accuracy is =  0.905\n",
            "At step  0  and at epoch =  39  the loss is =  0.012095111422240734  and accuracy is =  0.9006\n",
            "At step  0  and at epoch =  40  the loss is =  0.0021772596519440413  and accuracy is =  0.8842\n",
            "At step  0  and at epoch =  41  the loss is =  0.02065306529402733  and accuracy is =  0.9102\n",
            "At step  0  and at epoch =  42  the loss is =  0.030189720913767815  and accuracy is =  0.8786\n",
            "At step  0  and at epoch =  43  the loss is =  0.021983087062835693  and accuracy is =  0.8402\n",
            "At step  0  and at epoch =  44  the loss is =  0.012608248740434647  and accuracy is =  0.8594\n",
            "At step  0  and at epoch =  45  the loss is =  0.0032018714118748903  and accuracy is =  0.8884\n",
            "At step  0  and at epoch =  46  the loss is =  0.017844349145889282  and accuracy is =  0.9112\n",
            "At step  0  and at epoch =  47  the loss is =  0.008742132224142551  and accuracy is =  0.8858\n",
            "At step  0  and at epoch =  48  the loss is =  0.023818364366889  and accuracy is =  0.9126\n",
            "At step  0  and at epoch =  49  the loss is =  0.009169863536953926  and accuracy is =  0.9302\n",
            "At step  0  and at epoch =  50  the loss is =  0.022457579150795937  and accuracy is =  0.9516\n",
            "At step  0  and at epoch =  51  the loss is =  0.01101600006222725  and accuracy is =  0.9556\n",
            "At step  0  and at epoch =  52  the loss is =  0.010643338784575462  and accuracy is =  0.9562\n",
            "At step  0  and at epoch =  53  the loss is =  0.014608440920710564  and accuracy is =  0.9584\n",
            "At step  0  and at epoch =  54  the loss is =  0.024941230192780495  and accuracy is =  0.9458\n",
            "At step  0  and at epoch =  55  the loss is =  0.009921357966959476  and accuracy is =  0.9528\n",
            "At step  0  and at epoch =  56  the loss is =  0.01787206158041954  and accuracy is =  0.9626\n",
            "At step  0  and at epoch =  57  the loss is =  0.01424106489866972  and accuracy is =  0.9626\n",
            "At step  0  and at epoch =  58  the loss is =  0.0027734278701245785  and accuracy is =  0.9624\n",
            "At step  0  and at epoch =  59  the loss is =  0.003063434036448598  and accuracy is =  0.9686\n",
            "At step  0  and at epoch =  60  the loss is =  0.010610181838274002  and accuracy is =  0.9692\n",
            "At step  0  and at epoch =  61  the loss is =  0.0095091313123703  and accuracy is =  0.9516\n",
            "At step  0  and at epoch =  62  the loss is =  0.008962897583842278  and accuracy is =  0.966\n",
            "At step  0  and at epoch =  63  the loss is =  0.01561356708407402  and accuracy is =  0.9728\n",
            "At step  0  and at epoch =  64  the loss is =  0.008215924724936485  and accuracy is =  0.975\n",
            "At step  0  and at epoch =  65  the loss is =  0.012348368763923645  and accuracy is =  0.9746\n",
            "At step  0  and at epoch =  66  the loss is =  0.013492763973772526  and accuracy is =  0.9684\n",
            "At step  0  and at epoch =  67  the loss is =  0.017603961750864983  and accuracy is =  0.9762\n",
            "At step  0  and at epoch =  68  the loss is =  0.0017944746650755405  and accuracy is =  0.9752\n",
            "At step  0  and at epoch =  69  the loss is =  0.005119313020259142  and accuracy is =  0.9756\n",
            "task: 0 train accuracy = 0.9826\n",
            "task: 0 test accuracy = 0.894\n",
            "At step  10  and at epoch =  0  the loss is =  0.029826534911990166  and accuracy is =  0.29029957203994294\n",
            "At step  10  and at epoch =  1  the loss is =  0.028091369196772575  and accuracy is =  0.387018544935806\n",
            "At step  10  and at epoch =  2  the loss is =  0.024582603946328163  and accuracy is =  0.48530670470756065\n",
            "At step  10  and at epoch =  3  the loss is =  0.02587365359067917  and accuracy is =  0.5358059914407989\n",
            "At step  10  and at epoch =  4  the loss is =  0.024663008749485016  and accuracy is =  0.5748930099857347\n",
            "At step  10  and at epoch =  5  the loss is =  0.021310223266482353  and accuracy is =  0.6089871611982881\n",
            "At step  10  and at epoch =  6  the loss is =  0.025913817808032036  and accuracy is =  0.6400855920114122\n",
            "At step  10  and at epoch =  7  the loss is =  0.022294046357274055  and accuracy is =  0.6476462196861626\n",
            "At step  10  and at epoch =  8  the loss is =  0.02339502051472664  and accuracy is =  0.6790299572039943\n",
            "At step  10  and at epoch =  9  the loss is =  0.023748615756630898  and accuracy is =  0.6867332382310984\n",
            "At step  10  and at epoch =  10  the loss is =  0.019868221133947372  and accuracy is =  0.6972895863052782\n",
            "At step  10  and at epoch =  11  the loss is =  0.01942051760852337  and accuracy is =  0.7118402282453637\n",
            "At step  10  and at epoch =  12  the loss is =  0.018778901547193527  and accuracy is =  0.723965763195435\n",
            "At step  10  and at epoch =  13  the loss is =  0.018423371016979218  and accuracy is =  0.7338088445078459\n",
            "At step  10  and at epoch =  14  the loss is =  0.020199907943606377  and accuracy is =  0.7452211126961483\n",
            "At step  10  and at epoch =  15  the loss is =  0.022719813510775566  and accuracy is =  0.7559201141226819\n",
            "At step  10  and at epoch =  16  the loss is =  0.021081075072288513  and accuracy is =  0.7524964336661911\n",
            "At step  10  and at epoch =  17  the loss is =  0.02052459865808487  and accuracy is =  0.769472182596291\n",
            "At step  10  and at epoch =  18  the loss is =  0.01855144090950489  and accuracy is =  0.7717546362339515\n",
            "At step  10  and at epoch =  19  the loss is =  0.019344037398695946  and accuracy is =  0.7763195435092725\n",
            "At step  10  and at epoch =  20  the loss is =  0.01599426195025444  and accuracy is =  0.7784593437945792\n",
            "At step  10  and at epoch =  21  the loss is =  0.019003983587026596  and accuracy is =  0.7922967189728959\n",
            "At step  10  and at epoch =  22  the loss is =  0.02029217779636383  and accuracy is =  0.7947218259629101\n",
            "At step  10  and at epoch =  23  the loss is =  0.018417948856949806  and accuracy is =  0.7990014265335236\n",
            "At step  10  and at epoch =  24  the loss is =  0.018571875989437103  and accuracy is =  0.7981455064194009\n",
            "At step  10  and at epoch =  25  the loss is =  0.019576281309127808  and accuracy is =  0.8035663338088445\n",
            "At step  10  and at epoch =  26  the loss is =  0.01847732812166214  and accuracy is =  0.8124108416547788\n",
            "At step  10  and at epoch =  27  the loss is =  0.01657319813966751  and accuracy is =  0.8101283880171184\n",
            "At step  10  and at epoch =  28  the loss is =  0.015191841870546341  and accuracy is =  0.8219686162624822\n",
            "At step  10  and at epoch =  29  the loss is =  0.019226856529712677  and accuracy is =  0.8268188302425107\n",
            "At step  10  and at epoch =  30  the loss is =  0.017353499308228493  and accuracy is =  0.8191155492154065\n",
            "At step  10  and at epoch =  31  the loss is =  0.016418619081377983  and accuracy is =  0.8242510699001426\n",
            "At step  10  and at epoch =  32  the loss is =  0.019011538475751877  and accuracy is =  0.8312410841654779\n",
            "At step  10  and at epoch =  33  the loss is =  0.019053146243095398  and accuracy is =  0.8320970042796005\n",
            "At step  10  and at epoch =  34  the loss is =  0.01691632717847824  and accuracy is =  0.8355206847360913\n",
            "At step  10  and at epoch =  35  the loss is =  0.016189564019441605  and accuracy is =  0.8413694721825963\n",
            "At step  10  and at epoch =  36  the loss is =  0.016616085544228554  and accuracy is =  0.8475035663338089\n",
            "At step  10  and at epoch =  37  the loss is =  0.01985507644712925  and accuracy is =  0.8446504992867332\n",
            "At step  10  and at epoch =  38  the loss is =  0.01767847314476967  and accuracy is =  0.8473609129814551\n",
            "At step  10  and at epoch =  39  the loss is =  0.01606966368854046  and accuracy is =  0.8512125534950071\n",
            "At step  10  and at epoch =  40  the loss is =  0.017362387850880623  and accuracy is =  0.8477888730385164\n",
            "At step  10  and at epoch =  41  the loss is =  0.017923777922987938  and accuracy is =  0.8592011412268188\n",
            "At step  10  and at epoch =  42  the loss is =  0.0143665112555027  and accuracy is =  0.8699001426533524\n",
            "At step  10  and at epoch =  43  the loss is =  0.015686415135860443  and accuracy is =  0.8524964336661911\n",
            "At step  10  and at epoch =  44  the loss is =  0.01593725010752678  and accuracy is =  0.8577746077032811\n",
            "At step  10  and at epoch =  45  the loss is =  0.017582176253199577  and accuracy is =  0.8607703281027104\n",
            "At step  10  and at epoch =  46  the loss is =  0.016524411737918854  and accuracy is =  0.8647646219686163\n",
            "At step  10  and at epoch =  47  the loss is =  0.01745113730430603  and accuracy is =  0.8539229671897289\n",
            "At step  10  and at epoch =  48  the loss is =  0.016657022759318352  and accuracy is =  0.8659058487874465\n",
            "At step  10  and at epoch =  49  the loss is =  0.012591986916959286  and accuracy is =  0.9022824536376605\n",
            "At step  10  and at epoch =  50  the loss is =  0.011900161392986774  and accuracy is =  0.9192582025677604\n",
            "At step  10  and at epoch =  51  the loss is =  0.012177613563835621  and accuracy is =  0.9195435092724679\n",
            "At step  10  and at epoch =  52  the loss is =  0.01376282051205635  and accuracy is =  0.9219686162624822\n",
            "At step  10  and at epoch =  53  the loss is =  0.011457521468400955  and accuracy is =  0.9275320970042796\n",
            "At step  10  and at epoch =  54  the loss is =  0.012630903162062168  and accuracy is =  0.9316690442225393\n",
            "At step  10  and at epoch =  55  the loss is =  0.011791250668466091  and accuracy is =  0.9339514978601997\n",
            "At step  10  and at epoch =  56  the loss is =  0.013616805896162987  and accuracy is =  0.9348074179743224\n",
            "At step  10  and at epoch =  57  the loss is =  0.01371439453214407  and accuracy is =  0.9346647646219686\n",
            "At step  10  and at epoch =  58  the loss is =  0.011973131448030472  and accuracy is =  0.9378031383737517\n",
            "At step  10  and at epoch =  59  the loss is =  0.010283587500452995  and accuracy is =  0.9379457917261056\n",
            "At step  10  and at epoch =  60  the loss is =  0.013452071696519852  and accuracy is =  0.9382310984308131\n",
            "At step  10  and at epoch =  61  the loss is =  0.012551266700029373  and accuracy is =  0.9373751783166905\n",
            "At step  10  and at epoch =  62  the loss is =  0.0130940992385149  and accuracy is =  0.9426533523537803\n",
            "At step  10  and at epoch =  63  the loss is =  0.010559824295341969  and accuracy is =  0.9453637660485021\n",
            "At step  10  and at epoch =  64  the loss is =  0.01276120264083147  and accuracy is =  0.9476462196861626\n",
            "At step  10  and at epoch =  65  the loss is =  0.011209444142878056  and accuracy is =  0.9520684736091298\n",
            "At step  10  and at epoch =  66  the loss is =  0.011866115033626556  and accuracy is =  0.9466476462196861\n",
            "At step  10  and at epoch =  67  the loss is =  0.010758679360151291  and accuracy is =  0.9462196861626249\n",
            "At step  10  and at epoch =  68  the loss is =  0.012188411317765713  and accuracy is =  0.9477888730385164\n",
            "At step  10  and at epoch =  69  the loss is =  0.011591430753469467  and accuracy is =  0.9457917261055635\n",
            "task: 10 train accuracy = 0.9632\n",
            "task: 10 test accuracy = 0.7895\n",
            "At step  20  and at epoch =  0  the loss is =  0.0404837504029274  and accuracy is =  0.27336182336182335\n",
            "At step  20  and at epoch =  1  the loss is =  0.03561170771718025  and accuracy is =  0.3668091168091168\n",
            "At step  20  and at epoch =  2  the loss is =  0.032738473266363144  and accuracy is =  0.46225071225071224\n",
            "At step  20  and at epoch =  3  the loss is =  0.03528213128447533  and accuracy is =  0.5118233618233619\n",
            "At step  20  and at epoch =  4  the loss is =  0.030340857803821564  and accuracy is =  0.5552706552706552\n",
            "At step  20  and at epoch =  5  the loss is =  0.0313706174492836  and accuracy is =  0.5903133903133904\n",
            "At step  20  and at epoch =  6  the loss is =  0.033745452761650085  and accuracy is =  0.6129629629629629\n",
            "At step  20  and at epoch =  7  the loss is =  0.02958899363875389  and accuracy is =  0.6351851851851852\n",
            "At step  20  and at epoch =  8  the loss is =  0.02825716882944107  and accuracy is =  0.6534188034188034\n",
            "At step  20  and at epoch =  9  the loss is =  0.03051815927028656  and accuracy is =  0.6648148148148149\n",
            "At step  20  and at epoch =  10  the loss is =  0.029763896018266678  and accuracy is =  0.6863247863247863\n",
            "At step  20  and at epoch =  11  the loss is =  0.027509218081831932  and accuracy is =  0.6913105413105413\n",
            "At step  20  and at epoch =  12  the loss is =  0.029473429545760155  and accuracy is =  0.7096866096866097\n",
            "At step  20  and at epoch =  13  the loss is =  0.03149652108550072  and accuracy is =  0.7123931623931624\n",
            "At step  20  and at epoch =  14  the loss is =  0.026461100205779076  and accuracy is =  0.7367521367521368\n",
            "At step  20  and at epoch =  15  the loss is =  0.02787182852625847  and accuracy is =  0.7279202279202279\n",
            "At step  20  and at epoch =  16  the loss is =  0.03028934821486473  and accuracy is =  0.7391737891737892\n",
            "At step  20  and at epoch =  17  the loss is =  0.02651446871459484  and accuracy is =  0.7394586894586894\n",
            "At step  20  and at epoch =  18  the loss is =  0.028990212827920914  and accuracy is =  0.7625356125356125\n",
            "At step  20  and at epoch =  19  the loss is =  0.03157404437661171  and accuracy is =  0.7515669515669515\n",
            "At step  20  and at epoch =  20  the loss is =  0.029026152566075325  and accuracy is =  0.7703703703703704\n",
            "At step  20  and at epoch =  21  the loss is =  0.02673601545393467  and accuracy is =  0.7618233618233619\n",
            "At step  20  and at epoch =  22  the loss is =  0.027977213263511658  and accuracy is =  0.7672364672364672\n",
            "At step  20  and at epoch =  23  the loss is =  0.028642402961850166  and accuracy is =  0.7703703703703704\n",
            "At step  20  and at epoch =  24  the loss is =  0.025138910859823227  and accuracy is =  0.7804843304843305\n",
            "At step  20  and at epoch =  25  the loss is =  0.027353670448064804  and accuracy is =  0.7874643874643875\n",
            "At step  20  and at epoch =  26  the loss is =  0.02592364326119423  and accuracy is =  0.7849002849002849\n",
            "At step  20  and at epoch =  27  the loss is =  0.02474035695195198  and accuracy is =  0.7995726495726496\n",
            "At step  20  and at epoch =  28  the loss is =  0.02497999742627144  and accuracy is =  0.8017094017094017\n",
            "At step  20  and at epoch =  29  the loss is =  0.025205152109265327  and accuracy is =  0.8007122507122507\n",
            "At step  20  and at epoch =  30  the loss is =  0.02818792499601841  and accuracy is =  0.8018518518518518\n",
            "At step  20  and at epoch =  31  the loss is =  0.028520749881863594  and accuracy is =  0.8056980056980056\n",
            "At step  20  and at epoch =  32  the loss is =  0.02726636454463005  and accuracy is =  0.8032763532763533\n",
            "At step  20  and at epoch =  33  the loss is =  0.026048773899674416  and accuracy is =  0.8088319088319088\n",
            "At step  20  and at epoch =  34  the loss is =  0.025016965344548225  and accuracy is =  0.8103988603988604\n",
            "At step  20  and at epoch =  35  the loss is =  0.02422436699271202  and accuracy is =  0.816096866096866\n",
            "At step  20  and at epoch =  36  the loss is =  0.024568520486354828  and accuracy is =  0.8235042735042735\n",
            "At step  20  and at epoch =  37  the loss is =  0.025892311707139015  and accuracy is =  0.8219373219373219\n",
            "At step  20  and at epoch =  38  the loss is =  0.025829818099737167  and accuracy is =  0.8237891737891738\n",
            "At step  20  and at epoch =  39  the loss is =  0.025777937844395638  and accuracy is =  0.8269230769230769\n",
            "At step  20  and at epoch =  40  the loss is =  0.02420951798558235  and accuracy is =  0.8225071225071225\n",
            "At step  20  and at epoch =  41  the loss is =  0.02728409878909588  and accuracy is =  0.8337606837606838\n",
            "At step  20  and at epoch =  42  the loss is =  0.026856202632188797  and accuracy is =  0.8361823361823362\n",
            "At step  20  and at epoch =  43  the loss is =  0.02508106455206871  and accuracy is =  0.8353276353276353\n",
            "At step  20  and at epoch =  44  the loss is =  0.02640770748257637  and accuracy is =  0.8353276353276353\n",
            "At step  20  and at epoch =  45  the loss is =  0.025458650663495064  and accuracy is =  0.8347578347578347\n",
            "At step  20  and at epoch =  46  the loss is =  0.02597883716225624  and accuracy is =  0.8391737891737892\n",
            "At step  20  and at epoch =  47  the loss is =  0.025098763406276703  and accuracy is =  0.837037037037037\n",
            "At step  20  and at epoch =  48  the loss is =  0.02573332004249096  and accuracy is =  0.8423076923076923\n",
            "At step  20  and at epoch =  49  the loss is =  0.023995576426386833  and accuracy is =  0.8792022792022792\n",
            "At step  20  and at epoch =  50  the loss is =  0.021205080673098564  and accuracy is =  0.8853276353276354\n",
            "At step  20  and at epoch =  51  the loss is =  0.020569896325469017  and accuracy is =  0.8898860398860399\n",
            "At step  20  and at epoch =  52  the loss is =  0.02305258996784687  and accuracy is =  0.8954415954415954\n",
            "At step  20  and at epoch =  53  the loss is =  0.021052181720733643  and accuracy is =  0.8967236467236467\n",
            "At step  20  and at epoch =  54  the loss is =  0.0209263414144516  and accuracy is =  0.9071225071225071\n",
            "At step  20  and at epoch =  55  the loss is =  0.020253337919712067  and accuracy is =  0.8997150997150997\n",
            "At step  20  and at epoch =  56  the loss is =  0.02231532707810402  and accuracy is =  0.902991452991453\n",
            "At step  20  and at epoch =  57  the loss is =  0.0211794413626194  and accuracy is =  0.903988603988604\n",
            "At step  20  and at epoch =  58  the loss is =  0.02009064145386219  and accuracy is =  0.9076923076923077\n",
            "At step  20  and at epoch =  59  the loss is =  0.021737167611718178  and accuracy is =  0.9038461538461539\n",
            "At step  20  and at epoch =  60  the loss is =  0.02076348289847374  and accuracy is =  0.9079772079772079\n",
            "At step  20  and at epoch =  61  the loss is =  0.019900213927030563  and accuracy is =  0.9055555555555556\n",
            "At step  20  and at epoch =  62  the loss is =  0.021328963339328766  and accuracy is =  0.9051282051282051\n",
            "At step  20  and at epoch =  63  the loss is =  0.02084610052406788  and accuracy is =  0.9125356125356126\n",
            "At step  20  and at epoch =  64  the loss is =  0.021216249093413353  and accuracy is =  0.9153846153846154\n",
            "At step  20  and at epoch =  65  the loss is =  0.02079191617667675  and accuracy is =  0.9163817663817664\n",
            "At step  20  and at epoch =  66  the loss is =  0.020200954750180244  and accuracy is =  0.9115384615384615\n",
            "At step  20  and at epoch =  67  the loss is =  0.022298311814665794  and accuracy is =  0.9132478632478632\n",
            "At step  20  and at epoch =  68  the loss is =  0.020692313089966774  and accuracy is =  0.9111111111111111\n",
            "At step  20  and at epoch =  69  the loss is =  0.021428311243653297  and accuracy is =  0.9131054131054132\n",
            "task: 20 train accuracy = 0.8792\n",
            "task: 20 test accuracy = 0.714\n",
            "At step  30  and at epoch =  0  the loss is =  0.046821512281894684  and accuracy is =  0.2717546362339515\n",
            "At step  30  and at epoch =  1  the loss is =  0.04008178785443306  and accuracy is =  0.3761768901569187\n",
            "At step  30  and at epoch =  2  the loss is =  0.03933728113770485  and accuracy is =  0.4513552068473609\n",
            "At step  30  and at epoch =  3  the loss is =  0.03905145078897476  and accuracy is =  0.504564907275321\n",
            "At step  30  and at epoch =  4  the loss is =  0.04080965742468834  and accuracy is =  0.5465049928673323\n",
            "At step  30  and at epoch =  5  the loss is =  0.040175095200538635  and accuracy is =  0.5804564907275321\n",
            "At step  30  and at epoch =  6  the loss is =  0.039646781980991364  and accuracy is =  0.5985734664764621\n",
            "At step  30  and at epoch =  7  the loss is =  0.039915185421705246  and accuracy is =  0.6154065620542083\n",
            "At step  30  and at epoch =  8  the loss is =  0.03550812229514122  and accuracy is =  0.6449358059914408\n",
            "At step  30  and at epoch =  9  the loss is =  0.03860464319586754  and accuracy is =  0.6500713266761768\n",
            "At step  30  and at epoch =  10  the loss is =  0.03908175230026245  and accuracy is =  0.6703281027104137\n",
            "At step  30  and at epoch =  11  the loss is =  0.03898368403315544  and accuracy is =  0.6717546362339515\n",
            "At step  30  and at epoch =  12  the loss is =  0.03622334823012352  and accuracy is =  0.6733238231098431\n",
            "At step  30  and at epoch =  13  the loss is =  0.035523027181625366  and accuracy is =  0.7011412268188303\n",
            "At step  30  and at epoch =  14  the loss is =  0.03649495542049408  and accuracy is =  0.7057061340941512\n",
            "At step  30  and at epoch =  15  the loss is =  0.03998043015599251  and accuracy is =  0.6974322396576319\n",
            "At step  30  and at epoch =  16  the loss is =  0.03876321017742157  and accuracy is =  0.7111269614835949\n",
            "At step  30  and at epoch =  17  the loss is =  0.037563156336545944  and accuracy is =  0.7226818830242511\n",
            "At step  30  and at epoch =  18  the loss is =  0.035342004150152206  and accuracy is =  0.7328102710413694\n",
            "At step  30  and at epoch =  19  the loss is =  0.03651678189635277  and accuracy is =  0.74151212553495\n",
            "At step  30  and at epoch =  20  the loss is =  0.03670486807823181  and accuracy is =  0.7497860199714693\n",
            "At step  30  and at epoch =  21  the loss is =  0.03557576984167099  and accuracy is =  0.7425106990014265\n",
            "At step  30  and at epoch =  22  the loss is =  0.03950121998786926  and accuracy is =  0.7499286733238231\n",
            "At step  30  and at epoch =  23  the loss is =  0.03430511802434921  and accuracy is =  0.7590584878744651\n",
            "At step  30  and at epoch =  24  the loss is =  0.04015372321009636  and accuracy is =  0.756490727532097\n",
            "At step  30  and at epoch =  25  the loss is =  0.03612987697124481  and accuracy is =  0.7611982881597718\n",
            "At step  30  and at epoch =  26  the loss is =  0.035007111728191376  and accuracy is =  0.7673323823109843\n",
            "At step  30  and at epoch =  27  the loss is =  0.04038070887327194  and accuracy is =  0.7621968616262482\n",
            "At step  30  and at epoch =  28  the loss is =  0.03641794994473457  and accuracy is =  0.769472182596291\n",
            "At step  30  and at epoch =  29  the loss is =  0.035121310502290726  and accuracy is =  0.7744650499286734\n",
            "At step  30  and at epoch =  30  the loss is =  0.04052967205643654  and accuracy is =  0.7818830242510699\n",
            "At step  30  and at epoch =  31  the loss is =  0.03689398989081383  and accuracy is =  0.7814550641940086\n",
            "At step  30  and at epoch =  32  the loss is =  0.036098212003707886  and accuracy is =  0.7788873038516405\n",
            "At step  30  and at epoch =  33  the loss is =  0.035420481115579605  and accuracy is =  0.7881597717546363\n",
            "At step  30  and at epoch =  34  the loss is =  0.03340873867273331  and accuracy is =  0.7895863052781741\n",
            "At step  30  and at epoch =  35  the loss is =  0.03523534536361694  and accuracy is =  0.7878744650499286\n",
            "At step  30  and at epoch =  36  the loss is =  0.03520599752664566  and accuracy is =  0.8014265335235378\n",
            "At step  30  and at epoch =  37  the loss is =  0.0339595265686512  and accuracy is =  0.8085592011412268\n",
            "At step  30  and at epoch =  38  the loss is =  0.032230690121650696  and accuracy is =  0.8074179743223966\n",
            "At step  30  and at epoch =  39  the loss is =  0.03406861424446106  and accuracy is =  0.8094151212553495\n",
            "At step  30  and at epoch =  40  the loss is =  0.03471359238028526  and accuracy is =  0.8037089871611983\n",
            "At step  30  and at epoch =  41  the loss is =  0.0328323170542717  and accuracy is =  0.8105563480741798\n",
            "At step  30  and at epoch =  42  the loss is =  0.03561217337846756  and accuracy is =  0.8069900142653352\n",
            "At step  30  and at epoch =  43  the loss is =  0.03364499285817146  and accuracy is =  0.807132667617689\n",
            "At step  30  and at epoch =  44  the loss is =  0.035374972969293594  and accuracy is =  0.8205420827389444\n",
            "At step  30  and at epoch =  45  the loss is =  0.035829804837703705  and accuracy is =  0.8148359486447931\n",
            "At step  30  and at epoch =  46  the loss is =  0.03456219658255577  and accuracy is =  0.8101283880171184\n",
            "At step  30  and at epoch =  47  the loss is =  0.03357383608818054  and accuracy is =  0.8235378031383738\n",
            "At step  30  and at epoch =  48  the loss is =  0.03122471459209919  and accuracy is =  0.8182596291012839\n",
            "At step  30  and at epoch =  49  the loss is =  0.033946141600608826  and accuracy is =  0.854493580599144\n",
            "At step  30  and at epoch =  50  the loss is =  0.03000437282025814  and accuracy is =  0.8756062767475036\n",
            "At step  30  and at epoch =  51  the loss is =  0.030577251687645912  and accuracy is =  0.8737517831669044\n",
            "At step  30  and at epoch =  52  the loss is =  0.030343247577548027  and accuracy is =  0.8791726105563481\n",
            "At step  30  and at epoch =  53  the loss is =  0.02924802154302597  and accuracy is =  0.8761768901569187\n",
            "At step  30  and at epoch =  54  the loss is =  0.029294636100530624  and accuracy is =  0.8874465049928674\n",
            "At step  30  and at epoch =  55  the loss is =  0.032411910593509674  and accuracy is =  0.878601997146933\n",
            "At step  30  and at epoch =  56  the loss is =  0.03055782988667488  and accuracy is =  0.8880171184022825\n",
            "At step  30  and at epoch =  57  the loss is =  0.030861379578709602  and accuracy is =  0.8815977175463623\n",
            "At step  30  and at epoch =  58  the loss is =  0.03030407428741455  and accuracy is =  0.8820256776034237\n",
            "At step  30  and at epoch =  59  the loss is =  0.029722800478339195  and accuracy is =  0.8935805991440798\n",
            "At step  30  and at epoch =  60  the loss is =  0.027769766747951508  and accuracy is =  0.8921540656205421\n",
            "At step  30  and at epoch =  61  the loss is =  0.028930459171533585  and accuracy is =  0.8860199714693295\n",
            "At step  30  and at epoch =  62  the loss is =  0.030956069007515907  and accuracy is =  0.8864479315263909\n",
            "At step  30  and at epoch =  63  the loss is =  0.029105059802532196  and accuracy is =  0.8912981455064194\n",
            "At step  30  and at epoch =  64  the loss is =  0.030585460364818573  and accuracy is =  0.897432239657632\n",
            "At step  30  and at epoch =  65  the loss is =  0.029510267078876495  and accuracy is =  0.9007132667617689\n",
            "At step  30  and at epoch =  66  the loss is =  0.03174377605319023  and accuracy is =  0.8945791726105563\n",
            "At step  30  and at epoch =  67  the loss is =  0.027534136548638344  and accuracy is =  0.8952924393723253\n",
            "At step  30  and at epoch =  68  the loss is =  0.029589850455522537  and accuracy is =  0.8988587731811698\n",
            "At step  30  and at epoch =  69  the loss is =  0.028590060770511627  and accuracy is =  0.8965763195435092\n",
            "task: 30 train accuracy = 0.8668\n",
            "task: 30 test accuracy = 0.625\n",
            "At step  40  and at epoch =  0  the loss is =  0.058992575854063034  and accuracy is =  0.2545454545454545\n",
            "At step  40  and at epoch =  1  the loss is =  0.05678496137261391  and accuracy is =  0.32329545454545455\n",
            "At step  40  and at epoch =  2  the loss is =  0.05800865963101387  and accuracy is =  0.38835227272727274\n",
            "At step  40  and at epoch =  3  the loss is =  0.05321953818202019  and accuracy is =  0.4268465909090909\n",
            "At step  40  and at epoch =  4  the loss is =  0.05366940423846245  and accuracy is =  0.459375\n",
            "At step  40  and at epoch =  5  the loss is =  0.053190767765045166  and accuracy is =  0.4950284090909091\n",
            "At step  40  and at epoch =  6  the loss is =  0.05065492168068886  and accuracy is =  0.5180397727272728\n",
            "At step  40  and at epoch =  7  the loss is =  0.05242783948779106  and accuracy is =  0.540625\n",
            "At step  40  and at epoch =  8  the loss is =  0.05579567700624466  and accuracy is =  0.563778409090909\n",
            "At step  40  and at epoch =  9  the loss is =  0.05325629189610481  and accuracy is =  0.5830965909090909\n",
            "At step  40  and at epoch =  10  the loss is =  0.05399071425199509  and accuracy is =  0.5944602272727273\n",
            "At step  40  and at epoch =  11  the loss is =  0.051042117178440094  and accuracy is =  0.6083806818181818\n",
            "At step  40  and at epoch =  12  the loss is =  0.05251067131757736  and accuracy is =  0.6230113636363637\n",
            "At step  40  and at epoch =  13  the loss is =  0.04763513430953026  and accuracy is =  0.6301136363636364\n",
            "At step  40  and at epoch =  14  the loss is =  0.05051940679550171  and accuracy is =  0.6431818181818182\n",
            "At step  40  and at epoch =  15  the loss is =  0.053014978766441345  and accuracy is =  0.6561079545454546\n",
            "At step  40  and at epoch =  16  the loss is =  0.04874624311923981  and accuracy is =  0.6545454545454545\n",
            "At step  40  and at epoch =  17  the loss is =  0.05276409536600113  and accuracy is =  0.6603693181818182\n",
            "At step  40  and at epoch =  18  the loss is =  0.04959256201982498  and accuracy is =  0.6723011363636363\n",
            "At step  40  and at epoch =  19  the loss is =  0.04614691808819771  and accuracy is =  0.6794034090909091\n",
            "At step  40  and at epoch =  20  the loss is =  0.04952766001224518  and accuracy is =  0.6914772727272728\n",
            "At step  40  and at epoch =  21  the loss is =  0.05233287811279297  and accuracy is =  0.6926136363636364\n",
            "At step  40  and at epoch =  22  the loss is =  0.04936348646879196  and accuracy is =  0.7063920454545455\n",
            "At step  40  and at epoch =  23  the loss is =  0.04772726446390152  and accuracy is =  0.7089488636363637\n",
            "At step  40  and at epoch =  24  the loss is =  0.05111300200223923  and accuracy is =  0.7055397727272728\n",
            "At step  40  and at epoch =  25  the loss is =  0.04796917364001274  and accuracy is =  0.7275568181818182\n",
            "At step  40  and at epoch =  26  the loss is =  0.050712067633867264  and accuracy is =  0.7338068181818181\n",
            "At step  40  and at epoch =  27  the loss is =  0.04820256307721138  and accuracy is =  0.7296875\n",
            "At step  40  and at epoch =  28  the loss is =  0.04730194807052612  and accuracy is =  0.7336647727272727\n",
            "At step  40  and at epoch =  29  the loss is =  0.04497448727488518  and accuracy is =  0.7376420454545455\n",
            "At step  40  and at epoch =  30  the loss is =  0.04861820116639137  and accuracy is =  0.7464488636363636\n",
            "At step  40  and at epoch =  31  the loss is =  0.050924938172101974  and accuracy is =  0.7450284090909091\n",
            "At step  40  and at epoch =  32  the loss is =  0.0479775033891201  and accuracy is =  0.7515625\n",
            "At step  40  and at epoch =  33  the loss is =  0.04879244789481163  and accuracy is =  0.7579545454545454\n",
            "At step  40  and at epoch =  34  the loss is =  0.04788259416818619  and accuracy is =  0.7552556818181818\n",
            "At step  40  and at epoch =  35  the loss is =  0.047130778431892395  and accuracy is =  0.7639204545454545\n",
            "At step  40  and at epoch =  36  the loss is =  0.04939994588494301  and accuracy is =  0.7644886363636364\n",
            "At step  40  and at epoch =  37  the loss is =  0.047057006508111954  and accuracy is =  0.7644886363636364\n",
            "At step  40  and at epoch =  38  the loss is =  0.05068375915288925  and accuracy is =  0.7688920454545455\n",
            "At step  40  and at epoch =  39  the loss is =  0.046588070690631866  and accuracy is =  0.7759943181818182\n",
            "At step  40  and at epoch =  40  the loss is =  0.04697685316205025  and accuracy is =  0.7737215909090909\n",
            "At step  40  and at epoch =  41  the loss is =  0.04740956053137779  and accuracy is =  0.7735795454545454\n",
            "At step  40  and at epoch =  42  the loss is =  0.04496997594833374  and accuracy is =  0.7852272727272728\n",
            "At step  40  and at epoch =  43  the loss is =  0.04579969868063927  and accuracy is =  0.7850852272727272\n",
            "At step  40  and at epoch =  44  the loss is =  0.04684189707040787  and accuracy is =  0.7802556818181818\n",
            "At step  40  and at epoch =  45  the loss is =  0.04540625587105751  and accuracy is =  0.7764204545454545\n",
            "At step  40  and at epoch =  46  the loss is =  0.04937601462006569  and accuracy is =  0.7882102272727273\n",
            "At step  40  and at epoch =  47  the loss is =  0.053280822932720184  and accuracy is =  0.7774147727272728\n",
            "At step  40  and at epoch =  48  the loss is =  0.04580925777554512  and accuracy is =  0.7762784090909091\n",
            "At step  40  and at epoch =  49  the loss is =  0.04193192347884178  and accuracy is =  0.8330965909090909\n",
            "At step  40  and at epoch =  50  the loss is =  0.04215683788061142  and accuracy is =  0.8512784090909091\n",
            "At step  40  and at epoch =  51  the loss is =  0.04421623423695564  and accuracy is =  0.8617897727272728\n",
            "At step  40  and at epoch =  52  the loss is =  0.040938600897789  and accuracy is =  0.8647727272727272\n",
            "At step  40  and at epoch =  53  the loss is =  0.04404420405626297  and accuracy is =  0.8582386363636364\n",
            "At step  40  and at epoch =  54  the loss is =  0.04088202491402626  and accuracy is =  0.8653409090909091\n",
            "At step  40  and at epoch =  55  the loss is =  0.0430118665099144  and accuracy is =  0.8727272727272727\n",
            "At step  40  and at epoch =  56  the loss is =  0.04283750057220459  and accuracy is =  0.8696022727272728\n",
            "At step  40  and at epoch =  57  the loss is =  0.042185600847005844  and accuracy is =  0.8680397727272727\n",
            "At step  40  and at epoch =  58  the loss is =  0.04350866377353668  and accuracy is =  0.8714488636363636\n",
            "At step  40  and at epoch =  59  the loss is =  0.04085901007056236  and accuracy is =  0.868465909090909\n",
            "At step  40  and at epoch =  60  the loss is =  0.04359445348381996  and accuracy is =  0.8696022727272728\n",
            "At step  40  and at epoch =  61  the loss is =  0.04232754558324814  and accuracy is =  0.8759943181818182\n",
            "At step  40  and at epoch =  62  the loss is =  0.04182974249124527  and accuracy is =  0.8744318181818181\n",
            "At step  40  and at epoch =  63  the loss is =  0.04107007756829262  and accuracy is =  0.8826704545454546\n",
            "At step  40  and at epoch =  64  the loss is =  0.04387911781668663  and accuracy is =  0.8801136363636364\n",
            "At step  40  and at epoch =  65  the loss is =  0.037723615765571594  and accuracy is =  0.8897727272727273\n",
            "At step  40  and at epoch =  66  the loss is =  0.038184478878974915  and accuracy is =  0.8886363636363637\n",
            "At step  40  and at epoch =  67  the loss is =  0.04017220437526703  and accuracy is =  0.8803977272727272\n",
            "At step  40  and at epoch =  68  the loss is =  0.03894710913300514  and accuracy is =  0.8865056818181818\n",
            "At step  40  and at epoch =  69  the loss is =  0.03758024051785469  and accuracy is =  0.8845170454545455\n",
            "task: 40 train accuracy = 0.7874\n",
            "task: 40 test accuracy = 0.5596\n",
            "At step  50  and at epoch =  0  the loss is =  0.06870563328266144  and accuracy is =  0.24553191489361703\n",
            "At step  50  and at epoch =  1  the loss is =  0.07504250109195709  and accuracy is =  0.3204255319148936\n",
            "At step  50  and at epoch =  2  the loss is =  0.08273837715387344  and accuracy is =  0.38666666666666666\n",
            "At step  50  and at epoch =  3  the loss is =  0.0724317878484726  and accuracy is =  0.4167375886524823\n",
            "At step  50  and at epoch =  4  the loss is =  0.08074250817298889  and accuracy is =  0.4563120567375887\n",
            "At step  50  and at epoch =  5  the loss is =  0.08952593803405762  and accuracy is =  0.4824113475177305\n",
            "At step  50  and at epoch =  6  the loss is =  0.08262909203767776  and accuracy is =  0.5095035460992908\n",
            "At step  50  and at epoch =  7  the loss is =  0.07214554399251938  and accuracy is =  0.5279432624113475\n",
            "At step  50  and at epoch =  8  the loss is =  0.06792684644460678  and accuracy is =  0.5340425531914894\n",
            "At step  50  and at epoch =  9  the loss is =  0.08936671912670135  and accuracy is =  0.5558865248226951\n",
            "At step  50  and at epoch =  10  the loss is =  0.10610547661781311  and accuracy is =  0.5652482269503546\n",
            "At step  50  and at epoch =  11  the loss is =  0.08497009426355362  and accuracy is =  0.5668085106382978\n",
            "At step  50  and at epoch =  12  the loss is =  0.09611402451992035  and accuracy is =  0.5947517730496454\n",
            "At step  50  and at epoch =  13  the loss is =  0.07187333703041077  and accuracy is =  0.5940425531914894\n",
            "At step  50  and at epoch =  14  the loss is =  0.07725560665130615  and accuracy is =  0.6129078014184397\n",
            "At step  50  and at epoch =  15  the loss is =  0.07398433238267899  and accuracy is =  0.6188652482269503\n",
            "At step  50  and at epoch =  16  the loss is =  0.06159396469593048  and accuracy is =  0.6269503546099291\n",
            "At step  50  and at epoch =  17  the loss is =  0.061640895903110504  and accuracy is =  0.6374468085106383\n",
            "At step  50  and at epoch =  18  the loss is =  0.08486228436231613  and accuracy is =  0.6434042553191489\n",
            "At step  50  and at epoch =  19  the loss is =  0.08218562602996826  and accuracy is =  0.659290780141844\n",
            "At step  50  and at epoch =  20  the loss is =  0.07905668765306473  and accuracy is =  0.6543262411347518\n",
            "At step  50  and at epoch =  21  the loss is =  0.06605710089206696  and accuracy is =  0.6395744680851064\n",
            "At step  50  and at epoch =  22  the loss is =  0.08875560760498047  and accuracy is =  0.6601418439716312\n",
            "At step  50  and at epoch =  23  the loss is =  0.06751545518636703  and accuracy is =  0.6669503546099291\n",
            "At step  50  and at epoch =  24  the loss is =  0.07093118876218796  and accuracy is =  0.6860992907801419\n",
            "At step  50  and at epoch =  25  the loss is =  0.06758634001016617  and accuracy is =  0.6798581560283687\n",
            "At step  50  and at epoch =  26  the loss is =  0.07982981204986572  and accuracy is =  0.6968794326241134\n",
            "At step  50  and at epoch =  27  the loss is =  0.059690818190574646  and accuracy is =  0.6920567375886525\n",
            "At step  50  and at epoch =  28  the loss is =  0.07078790664672852  and accuracy is =  0.7021276595744681\n",
            "At step  50  and at epoch =  29  the loss is =  0.0649086982011795  and accuracy is =  0.6791489361702128\n",
            "At step  50  and at epoch =  30  the loss is =  0.06934050470590591  and accuracy is =  0.7038297872340425\n",
            "At step  50  and at epoch =  31  the loss is =  0.05505702272057533  and accuracy is =  0.7038297872340425\n",
            "At step  50  and at epoch =  32  the loss is =  0.07743200659751892  and accuracy is =  0.7202836879432624\n",
            "At step  50  and at epoch =  33  the loss is =  0.06844145804643631  and accuracy is =  0.6851063829787234\n",
            "At step  50  and at epoch =  34  the loss is =  0.07654484361410141  and accuracy is =  0.7059574468085107\n",
            "At step  50  and at epoch =  35  the loss is =  0.08188863843679428  and accuracy is =  0.6887943262411348\n",
            "At step  50  and at epoch =  36  the loss is =  0.0795193687081337  and accuracy is =  0.7062411347517731\n",
            "At step  50  and at epoch =  37  the loss is =  0.06591115146875381  and accuracy is =  0.7157446808510638\n",
            "At step  50  and at epoch =  38  the loss is =  0.06715164333581924  and accuracy is =  0.7231205673758865\n",
            "At step  50  and at epoch =  39  the loss is =  0.07777571678161621  and accuracy is =  0.7161702127659575\n",
            "At step  50  and at epoch =  40  the loss is =  0.07038726657629013  and accuracy is =  0.7246808510638297\n",
            "At step  50  and at epoch =  41  the loss is =  0.06623431295156479  and accuracy is =  0.7268085106382979\n",
            "At step  50  and at epoch =  42  the loss is =  0.07071670144796371  and accuracy is =  0.7340425531914894\n",
            "At step  50  and at epoch =  43  the loss is =  0.09013117104768753  and accuracy is =  0.7245390070921985\n",
            "At step  50  and at epoch =  44  the loss is =  0.0632949024438858  and accuracy is =  0.7164539007092199\n",
            "At step  50  and at epoch =  45  the loss is =  0.0714246854186058  and accuracy is =  0.7405673758865248\n",
            "At step  50  and at epoch =  46  the loss is =  0.08235806971788406  and accuracy is =  0.7456737588652482\n",
            "At step  50  and at epoch =  47  the loss is =  0.07759968936443329  and accuracy is =  0.7287943262411347\n",
            "At step  50  and at epoch =  48  the loss is =  0.07069627940654755  and accuracy is =  0.7141843971631205\n",
            "At step  50  and at epoch =  49  the loss is =  0.06006275489926338  and accuracy is =  0.7890780141843972\n",
            "At step  50  and at epoch =  50  the loss is =  0.07005832344293594  and accuracy is =  0.8075177304964539\n",
            "At step  50  and at epoch =  51  the loss is =  0.07073825597763062  and accuracy is =  0.8082269503546099\n",
            "At step  50  and at epoch =  52  the loss is =  0.06271179020404816  and accuracy is =  0.8141843971631205\n",
            "At step  50  and at epoch =  53  the loss is =  0.06096343323588371  and accuracy is =  0.8224113475177305\n",
            "At step  50  and at epoch =  54  the loss is =  0.06091722473502159  and accuracy is =  0.8119148936170213\n",
            "At step  50  and at epoch =  55  the loss is =  0.0841633751988411  and accuracy is =  0.816595744680851\n",
            "At step  50  and at epoch =  56  the loss is =  0.05691711604595184  and accuracy is =  0.828936170212766\n",
            "At step  50  and at epoch =  57  the loss is =  0.06587763130664825  and accuracy is =  0.8323404255319149\n",
            "At step  50  and at epoch =  58  the loss is =  0.05755678936839104  and accuracy is =  0.8268085106382979\n",
            "At step  50  and at epoch =  59  the loss is =  0.07214164733886719  and accuracy is =  0.823404255319149\n",
            "At step  50  and at epoch =  60  the loss is =  0.05966092273592949  and accuracy is =  0.8251063829787234\n",
            "At step  50  and at epoch =  61  the loss is =  0.06365940719842911  and accuracy is =  0.8265248226950355\n",
            "At step  50  and at epoch =  62  the loss is =  0.08056328445672989  and accuracy is =  0.8316312056737588\n",
            "At step  50  and at epoch =  63  the loss is =  0.06817445904016495  and accuracy is =  0.8547517730496453\n",
            "At step  50  and at epoch =  64  the loss is =  0.10383182018995285  and accuracy is =  0.8405673758865249\n",
            "At step  50  and at epoch =  65  the loss is =  0.057509034872055054  and accuracy is =  0.844113475177305\n",
            "At step  50  and at epoch =  66  the loss is =  0.0656367614865303  and accuracy is =  0.8452482269503546\n",
            "At step  50  and at epoch =  67  the loss is =  0.058408815413713455  and accuracy is =  0.8497872340425532\n",
            "At step  50  and at epoch =  68  the loss is =  0.06051922217011452  and accuracy is =  0.8428368794326241\n",
            "At step  50  and at epoch =  69  the loss is =  0.06385671347379684  and accuracy is =  0.8428368794326241\n",
            "task: 50 train accuracy = 0.7968\n",
            "task: 50 test accuracy = 0.5078333333333334\n",
            "At step  60  and at epoch =  0  the loss is =  0.07340902090072632  and accuracy is =  0.23167613636363638\n",
            "At step  60  and at epoch =  1  the loss is =  0.06836153566837311  and accuracy is =  0.31619318181818185\n",
            "At step  60  and at epoch =  2  the loss is =  0.0705588161945343  and accuracy is =  0.36619318181818183\n",
            "At step  60  and at epoch =  3  the loss is =  0.07109438627958298  and accuracy is =  0.4122159090909091\n",
            "At step  60  and at epoch =  4  the loss is =  0.06876268237829208  and accuracy is =  0.43139204545454546\n",
            "At step  60  and at epoch =  5  the loss is =  0.06943241506814957  and accuracy is =  0.45852272727272725\n",
            "At step  60  and at epoch =  6  the loss is =  0.07064589112997055  and accuracy is =  0.484375\n",
            "At step  60  and at epoch =  7  the loss is =  0.07313322275876999  and accuracy is =  0.49900568181818183\n",
            "At step  60  and at epoch =  8  the loss is =  0.06994649022817612  and accuracy is =  0.5110795454545455\n",
            "At step  60  and at epoch =  9  the loss is =  0.07158433645963669  and accuracy is =  0.5298295454545454\n",
            "At step  60  and at epoch =  10  the loss is =  0.0629693791270256  and accuracy is =  0.5521306818181818\n",
            "At step  60  and at epoch =  11  the loss is =  0.06855497509241104  and accuracy is =  0.5563920454545455\n",
            "At step  60  and at epoch =  12  the loss is =  0.06917577981948853  and accuracy is =  0.5603693181818182\n",
            "At step  60  and at epoch =  13  the loss is =  0.06643586605787277  and accuracy is =  0.5791193181818182\n",
            "At step  60  and at epoch =  14  the loss is =  0.06466715782880783  and accuracy is =  0.5914772727272727\n",
            "At step  60  and at epoch =  15  the loss is =  0.06748493760824203  and accuracy is =  0.5953125\n",
            "At step  60  and at epoch =  16  the loss is =  0.06494460254907608  and accuracy is =  0.5990056818181818\n",
            "At step  60  and at epoch =  17  the loss is =  0.07056278735399246  and accuracy is =  0.6113636363636363\n",
            "At step  60  and at epoch =  18  the loss is =  0.0660477876663208  and accuracy is =  0.6166193181818181\n",
            "At step  60  and at epoch =  19  the loss is =  0.06739123910665512  and accuracy is =  0.6264204545454546\n",
            "At step  60  and at epoch =  20  the loss is =  0.06878294050693512  and accuracy is =  0.6411931818181819\n",
            "At step  60  and at epoch =  21  the loss is =  0.06712298840284348  and accuracy is =  0.6443181818181818\n",
            "At step  60  and at epoch =  22  the loss is =  0.06668519228696823  and accuracy is =  0.6474431818181818\n",
            "At step  60  and at epoch =  23  the loss is =  0.06954622268676758  and accuracy is =  0.6487215909090909\n",
            "At step  60  and at epoch =  24  the loss is =  0.06631249934434891  and accuracy is =  0.6592329545454545\n",
            "At step  60  and at epoch =  25  the loss is =  0.07020008563995361  and accuracy is =  0.6529829545454545\n",
            "At step  60  and at epoch =  26  the loss is =  0.06916894763708115  and accuracy is =  0.6703125\n",
            "At step  60  and at epoch =  27  the loss is =  0.06950464844703674  and accuracy is =  0.6767045454545455\n",
            "At step  60  and at epoch =  28  the loss is =  0.06765300780534744  and accuracy is =  0.6734375\n",
            "At step  60  and at epoch =  29  the loss is =  0.06811584532260895  and accuracy is =  0.6822443181818182\n",
            "At step  60  and at epoch =  30  the loss is =  0.0657825842499733  and accuracy is =  0.6850852272727272\n",
            "At step  60  and at epoch =  31  the loss is =  0.06208237633109093  and accuracy is =  0.6928977272727272\n",
            "At step  60  and at epoch =  32  the loss is =  0.06996625661849976  and accuracy is =  0.6973011363636363\n",
            "At step  60  and at epoch =  33  the loss is =  0.06644773483276367  and accuracy is =  0.6828125\n",
            "At step  60  and at epoch =  34  the loss is =  0.0644746646285057  and accuracy is =  0.7029829545454546\n",
            "At step  60  and at epoch =  35  the loss is =  0.066714808344841  and accuracy is =  0.7133522727272728\n",
            "At step  60  and at epoch =  36  the loss is =  0.06688761711120605  and accuracy is =  0.7014204545454545\n",
            "At step  60  and at epoch =  37  the loss is =  0.06199266389012337  and accuracy is =  0.7021306818181818\n",
            "At step  60  and at epoch =  38  the loss is =  0.06357931345701218  and accuracy is =  0.7123579545454546\n",
            "At step  60  and at epoch =  39  the loss is =  0.0656389445066452  and accuracy is =  0.7160511363636364\n",
            "At step  60  and at epoch =  40  the loss is =  0.062440622597932816  and accuracy is =  0.7146306818181818\n",
            "At step  60  and at epoch =  41  the loss is =  0.06589803844690323  and accuracy is =  0.7075284090909091\n",
            "At step  60  and at epoch =  42  the loss is =  0.06697726249694824  and accuracy is =  0.7188920454545454\n",
            "At step  60  and at epoch =  43  the loss is =  0.06387414783239365  and accuracy is =  0.7328125\n",
            "At step  60  and at epoch =  44  the loss is =  0.06863074004650116  and accuracy is =  0.7186079545454546\n",
            "At step  60  and at epoch =  45  the loss is =  0.06644634902477264  and accuracy is =  0.7255681818181818\n",
            "At step  60  and at epoch =  46  the loss is =  0.06809856742620468  and accuracy is =  0.7269886363636363\n",
            "At step  60  and at epoch =  47  the loss is =  0.06815952807664871  and accuracy is =  0.7271306818181819\n",
            "At step  60  and at epoch =  48  the loss is =  0.06786521524190903  and accuracy is =  0.7370738636363636\n",
            "At step  60  and at epoch =  49  the loss is =  0.061058443039655685  and accuracy is =  0.7738636363636363\n",
            "At step  60  and at epoch =  50  the loss is =  0.05793691426515579  and accuracy is =  0.7910511363636363\n",
            "At step  60  and at epoch =  51  the loss is =  0.060483500361442566  and accuracy is =  0.803125\n",
            "At step  60  and at epoch =  52  the loss is =  0.060700006783008575  and accuracy is =  0.8046875\n",
            "At step  60  and at epoch =  53  the loss is =  0.06021573394536972  and accuracy is =  0.8117897727272727\n",
            "At step  60  and at epoch =  54  the loss is =  0.05763157829642296  and accuracy is =  0.8090909090909091\n",
            "At step  60  and at epoch =  55  the loss is =  0.0658571869134903  and accuracy is =  0.8177556818181818\n",
            "At step  60  and at epoch =  56  the loss is =  0.05687297508120537  and accuracy is =  0.8201704545454546\n",
            "At step  60  and at epoch =  57  the loss is =  0.05712630972266197  and accuracy is =  0.8151988636363636\n",
            "At step  60  and at epoch =  58  the loss is =  0.05905739590525627  and accuracy is =  0.8133522727272727\n",
            "At step  60  and at epoch =  59  the loss is =  0.0585983544588089  and accuracy is =  0.826846590909091\n",
            "At step  60  and at epoch =  60  the loss is =  0.06066508963704109  and accuracy is =  0.8276988636363637\n",
            "At step  60  and at epoch =  61  the loss is =  0.06415346264839172  and accuracy is =  0.8303977272727273\n",
            "At step  60  and at epoch =  62  the loss is =  0.06144033372402191  and accuracy is =  0.8284090909090909\n",
            "At step  60  and at epoch =  63  the loss is =  0.059488143771886826  and accuracy is =  0.8359375\n",
            "At step  60  and at epoch =  64  the loss is =  0.059965185821056366  and accuracy is =  0.8309659090909091\n",
            "At step  60  and at epoch =  65  the loss is =  0.06371947377920151  and accuracy is =  0.8319602272727272\n",
            "At step  60  and at epoch =  66  the loss is =  0.0625297948718071  and accuracy is =  0.8356534090909091\n",
            "At step  60  and at epoch =  67  the loss is =  0.0624052956700325  and accuracy is =  0.8397727272727272\n",
            "At step  60  and at epoch =  68  the loss is =  0.05951101332902908  and accuracy is =  0.8342329545454545\n",
            "At step  60  and at epoch =  69  the loss is =  0.061847660690546036  and accuracy is =  0.8377840909090909\n",
            "task: 60 train accuracy = 0.7542\n",
            "task: 60 test accuracy = 0.46385714285714286\n",
            "At step  70  and at epoch =  0  the loss is =  0.08580703288316727  and accuracy is =  0.23541963015647227\n",
            "At step  70  and at epoch =  1  the loss is =  0.08390913903713226  and accuracy is =  0.36770981507823614\n",
            "At step  70  and at epoch =  2  the loss is =  0.09403618425130844  and accuracy is =  0.440398293029872\n",
            "At step  70  and at epoch =  3  the loss is =  0.08359084278345108  and accuracy is =  0.48036984352773826\n",
            "At step  70  and at epoch =  4  the loss is =  0.07878056168556213  and accuracy is =  0.520199146514936\n",
            "At step  70  and at epoch =  5  the loss is =  0.09037250280380249  and accuracy is =  0.5523470839260313\n",
            "At step  70  and at epoch =  6  the loss is =  0.08334118127822876  and accuracy is =  0.5799431009957325\n",
            "At step  70  and at epoch =  7  the loss is =  0.08751532435417175  and accuracy is =  0.587624466571835\n",
            "At step  70  and at epoch =  8  the loss is =  0.0835280492901802  and accuracy is =  0.6086770981507824\n",
            "At step  70  and at epoch =  9  the loss is =  0.08152849972248077  and accuracy is =  0.6308677098150782\n",
            "At step  70  and at epoch =  10  the loss is =  0.0885113850235939  and accuracy is =  0.6438122332859175\n",
            "At step  70  and at epoch =  11  the loss is =  0.08182670176029205  and accuracy is =  0.6487908961593172\n",
            "At step  70  and at epoch =  12  the loss is =  0.08133656531572342  and accuracy is =  0.6530583214793741\n",
            "At step  70  and at epoch =  13  the loss is =  0.08476673066616058  and accuracy is =  0.6672830725462304\n",
            "At step  70  and at epoch =  14  the loss is =  0.08623694628477097  and accuracy is =  0.669701280227596\n",
            "At step  70  and at epoch =  15  the loss is =  0.08413262665271759  and accuracy is =  0.6778093883357041\n",
            "At step  70  and at epoch =  16  the loss is =  0.08018963783979416  and accuracy is =  0.6839260312944524\n",
            "At step  70  and at epoch =  17  the loss is =  0.08151623606681824  and accuracy is =  0.6948790896159317\n",
            "At step  70  and at epoch =  18  the loss is =  0.08128713071346283  and accuracy is =  0.6950213371266003\n",
            "At step  70  and at epoch =  19  the loss is =  0.0868442952632904  and accuracy is =  0.7015647226173541\n",
            "At step  70  and at epoch =  20  the loss is =  0.07919182628393173  and accuracy is =  0.7116642958748222\n",
            "At step  70  and at epoch =  21  the loss is =  0.08267944306135178  and accuracy is =  0.7130867709815079\n",
            "At step  70  and at epoch =  22  the loss is =  0.07985912263393402  and accuracy is =  0.7216216216216216\n",
            "At step  70  and at epoch =  23  the loss is =  0.08115746825933456  and accuracy is =  0.7297297297297297\n",
            "At step  70  and at epoch =  24  the loss is =  0.08109346777200699  and accuracy is =  0.7322901849217639\n",
            "At step  70  and at epoch =  25  the loss is =  0.08248990029096603  and accuracy is =  0.7312944523470839\n",
            "At step  70  and at epoch =  26  the loss is =  0.07870019972324371  and accuracy is =  0.7330014224751067\n",
            "At step  70  and at epoch =  27  the loss is =  0.07837782800197601  and accuracy is =  0.7406827880512091\n",
            "At step  70  and at epoch =  28  the loss is =  0.08082868903875351  and accuracy is =  0.741678520625889\n",
            "At step  70  and at epoch =  29  the loss is =  0.08331894874572754  and accuracy is =  0.7398293029871977\n",
            "At step  70  and at epoch =  30  the loss is =  0.08061564713716507  and accuracy is =  0.7452347083926031\n",
            "At step  70  and at epoch =  31  the loss is =  0.08119475096464157  and accuracy is =  0.7557610241820768\n",
            "At step  70  and at epoch =  32  the loss is =  0.08193808794021606  and accuracy is =  0.754054054054054\n",
            "At step  70  and at epoch =  33  the loss is =  0.08388911187648773  and accuracy is =  0.7598862019914652\n",
            "At step  70  and at epoch =  34  the loss is =  0.08356988430023193  and accuracy is =  0.7557610241820768\n",
            "At step  70  and at epoch =  35  the loss is =  0.0838693305850029  and accuracy is =  0.7556187766714082\n",
            "At step  70  and at epoch =  36  the loss is =  0.0793747752904892  and accuracy is =  0.7597439544807966\n",
            "At step  70  and at epoch =  37  the loss is =  0.07954102009534836  and accuracy is =  0.7560455192034139\n",
            "At step  70  and at epoch =  38  the loss is =  0.07962600141763687  and accuracy is =  0.7681365576102418\n",
            "At step  70  and at epoch =  39  the loss is =  0.07699263840913773  and accuracy is =  0.7702702702702703\n",
            "At step  70  and at epoch =  40  the loss is =  0.07694562524557114  and accuracy is =  0.7753911806543385\n",
            "At step  70  and at epoch =  41  the loss is =  0.0793628990650177  and accuracy is =  0.7691322901849218\n",
            "At step  70  and at epoch =  42  the loss is =  0.07941566407680511  and accuracy is =  0.7608819345661451\n",
            "At step  70  and at epoch =  43  the loss is =  0.09126028418540955  and accuracy is =  0.7688477951635846\n",
            "At step  70  and at epoch =  44  the loss is =  0.0813099667429924  and accuracy is =  0.7682788051209104\n",
            "At step  70  and at epoch =  45  the loss is =  0.08432593196630478  and accuracy is =  0.7682788051209104\n",
            "At step  70  and at epoch =  46  the loss is =  0.08784862607717514  and accuracy is =  0.77425320056899\n",
            "At step  70  and at epoch =  47  the loss is =  0.08134661614894867  and accuracy is =  0.7751066856330014\n",
            "At step  70  and at epoch =  48  the loss is =  0.08166846632957458  and accuracy is =  0.7772403982930298\n",
            "At step  70  and at epoch =  49  the loss is =  0.0806254893541336  and accuracy is =  0.8109530583214793\n",
            "At step  70  and at epoch =  50  the loss is =  0.07673737406730652  and accuracy is =  0.8281650071123755\n",
            "At step  70  and at epoch =  51  the loss is =  0.07787905633449554  and accuracy is =  0.8330014224751067\n",
            "At step  70  and at epoch =  52  the loss is =  0.07642409950494766  and accuracy is =  0.8307254623044097\n",
            "At step  70  and at epoch =  53  the loss is =  0.07358656823635101  and accuracy is =  0.837126600284495\n",
            "At step  70  and at epoch =  54  the loss is =  0.07870067656040192  and accuracy is =  0.8422475106685633\n",
            "At step  70  and at epoch =  55  the loss is =  0.07526186853647232  and accuracy is =  0.8354196301564722\n",
            "At step  70  and at epoch =  56  the loss is =  0.07668106257915497  and accuracy is =  0.8385490753911806\n",
            "At step  70  and at epoch =  57  the loss is =  0.0766436755657196  and accuracy is =  0.8368421052631579\n",
            "At step  70  and at epoch =  58  the loss is =  0.07572878897190094  and accuracy is =  0.835846372688478\n",
            "At step  70  and at epoch =  59  the loss is =  0.0759662613272667  and accuracy is =  0.8419630156472262\n",
            "At step  70  and at epoch =  60  the loss is =  0.07406050711870193  and accuracy is =  0.8401137980085348\n",
            "At step  70  and at epoch =  61  the loss is =  0.0760439932346344  and accuracy is =  0.8413940256045519\n",
            "At step  70  and at epoch =  62  the loss is =  0.07325136661529541  and accuracy is =  0.8402560455192034\n",
            "At step  70  and at epoch =  63  the loss is =  0.07634139060974121  and accuracy is =  0.8475106685633002\n",
            "At step  70  and at epoch =  64  the loss is =  0.07771345973014832  and accuracy is =  0.8506401137980085\n",
            "At step  70  and at epoch =  65  the loss is =  0.07464698702096939  and accuracy is =  0.841678520625889\n",
            "At step  70  and at epoch =  66  the loss is =  0.08057526499032974  and accuracy is =  0.8486486486486486\n",
            "At step  70  and at epoch =  67  the loss is =  0.07533368468284607  and accuracy is =  0.8475106685633002\n",
            "At step  70  and at epoch =  68  the loss is =  0.07635267078876495  and accuracy is =  0.8470839260312945\n",
            "At step  70  and at epoch =  69  the loss is =  0.07120758295059204  and accuracy is =  0.852773826458037\n",
            "task: 70 train accuracy = 0.7764\n",
            "task: 70 test accuracy = 0.425875\n",
            "At step  80  and at epoch =  0  the loss is =  0.10835986584424973  and accuracy is =  0.228954802259887\n",
            "At step  80  and at epoch =  1  the loss is =  0.11826010048389435  and accuracy is =  0.3112994350282486\n",
            "At step  80  and at epoch =  2  the loss is =  0.10385649651288986  and accuracy is =  0.3608757062146893\n",
            "At step  80  and at epoch =  3  the loss is =  0.09813419729471207  and accuracy is =  0.39788135593220336\n",
            "At step  80  and at epoch =  4  the loss is =  0.10279333591461182  and accuracy is =  0.42033898305084744\n",
            "At step  80  and at epoch =  5  the loss is =  0.10569043457508087  and accuracy is =  0.45112994350282487\n",
            "At step  80  and at epoch =  6  the loss is =  0.1085858941078186  and accuracy is =  0.4768361581920904\n",
            "At step  80  and at epoch =  7  the loss is =  0.09647569805383682  and accuracy is =  0.4888418079096045\n",
            "At step  80  and at epoch =  8  the loss is =  0.10045792907476425  and accuracy is =  0.5112994350282486\n",
            "At step  80  and at epoch =  9  the loss is =  0.10727784037590027  and accuracy is =  0.521045197740113\n",
            "At step  80  and at epoch =  10  the loss is =  0.102765753865242  and accuracy is =  0.5299435028248588\n",
            "At step  80  and at epoch =  11  the loss is =  0.10317710041999817  and accuracy is =  0.5415254237288135\n",
            "At step  80  and at epoch =  12  the loss is =  0.0978403314948082  and accuracy is =  0.5597457627118644\n",
            "At step  80  and at epoch =  13  the loss is =  0.09594304859638214  and accuracy is =  0.5717514124293785\n",
            "At step  80  and at epoch =  14  the loss is =  0.09817880392074585  and accuracy is =  0.5874293785310735\n",
            "At step  80  and at epoch =  15  the loss is =  0.12391604483127594  and accuracy is =  0.5971751412429378\n",
            "At step  80  and at epoch =  16  the loss is =  0.10805928707122803  and accuracy is =  0.6024011299435028\n",
            "At step  80  and at epoch =  17  the loss is =  0.09667976945638657  and accuracy is =  0.609180790960452\n",
            "At step  80  and at epoch =  18  the loss is =  0.1095743253827095  and accuracy is =  0.6096045197740113\n",
            "At step  80  and at epoch =  19  the loss is =  0.10376570373773575  and accuracy is =  0.6278248587570622\n",
            "At step  80  and at epoch =  20  the loss is =  0.1002645194530487  and accuracy is =  0.6218926553672316\n",
            "At step  80  and at epoch =  21  the loss is =  0.09433536231517792  and accuracy is =  0.6299435028248588\n",
            "At step  80  and at epoch =  22  the loss is =  0.09784993529319763  and accuracy is =  0.6488700564971751\n",
            "At step  80  and at epoch =  23  the loss is =  0.1005941703915596  and accuracy is =  0.6509887005649717\n",
            "At step  80  and at epoch =  24  the loss is =  0.10361327230930328  and accuracy is =  0.6470338983050847\n",
            "At step  80  and at epoch =  25  the loss is =  0.1167062446475029  and accuracy is =  0.6574858757062146\n",
            "At step  80  and at epoch =  26  the loss is =  0.10179909318685532  and accuracy is =  0.6518361581920904\n",
            "At step  80  and at epoch =  27  the loss is =  0.09720287472009659  and accuracy is =  0.6663841807909604\n",
            "At step  80  and at epoch =  28  the loss is =  0.10151869058609009  and accuracy is =  0.6711864406779661\n",
            "At step  80  and at epoch =  29  the loss is =  0.1050514280796051  and accuracy is =  0.6744350282485876\n",
            "At step  80  and at epoch =  30  the loss is =  0.0955091118812561  and accuracy is =  0.6809322033898305\n",
            "At step  80  and at epoch =  31  the loss is =  0.10045815259218216  and accuracy is =  0.6809322033898305\n",
            "At step  80  and at epoch =  32  the loss is =  0.1102236956357956  and accuracy is =  0.677683615819209\n",
            "At step  80  and at epoch =  33  the loss is =  0.09812546521425247  and accuracy is =  0.6888418079096045\n",
            "At step  80  and at epoch =  34  the loss is =  0.10691394656896591  and accuracy is =  0.6887005649717514\n",
            "At step  80  and at epoch =  35  the loss is =  0.10863161087036133  and accuracy is =  0.7007062146892655\n",
            "At step  80  and at epoch =  36  the loss is =  0.09747219830751419  and accuracy is =  0.6888418079096045\n",
            "At step  80  and at epoch =  37  the loss is =  0.1165446862578392  and accuracy is =  0.7045197740112994\n",
            "At step  80  and at epoch =  38  the loss is =  0.09287343919277191  and accuracy is =  0.7073446327683616\n",
            "At step  80  and at epoch =  39  the loss is =  0.0967818945646286  and accuracy is =  0.7059322033898305\n",
            "At step  80  and at epoch =  40  the loss is =  0.1005810871720314  and accuracy is =  0.7056497175141243\n",
            "At step  80  and at epoch =  41  the loss is =  0.10175398737192154  and accuracy is =  0.7105932203389831\n",
            "At step  80  and at epoch =  42  the loss is =  0.09732729941606522  and accuracy is =  0.7093220338983051\n",
            "At step  80  and at epoch =  43  the loss is =  0.0989769920706749  and accuracy is =  0.725\n",
            "At step  80  and at epoch =  44  the loss is =  0.09075701981782913  and accuracy is =  0.7137005649717514\n",
            "At step  80  and at epoch =  45  the loss is =  0.09697757661342621  and accuracy is =  0.7312146892655367\n",
            "At step  80  and at epoch =  46  the loss is =  0.09781163185834885  and accuracy is =  0.7290960451977401\n",
            "At step  80  and at epoch =  47  the loss is =  0.09765774756669998  and accuracy is =  0.732909604519774\n",
            "At step  80  and at epoch =  48  the loss is =  0.09756845235824585  and accuracy is =  0.7293785310734463\n",
            "At step  80  and at epoch =  49  the loss is =  0.09392856061458588  and accuracy is =  0.7669491525423728\n",
            "At step  80  and at epoch =  50  the loss is =  0.08839738368988037  and accuracy is =  0.7954802259887006\n",
            "At step  80  and at epoch =  51  the loss is =  0.09604661166667938  and accuracy is =  0.8002824858757062\n",
            "At step  80  and at epoch =  52  the loss is =  0.09214214235544205  and accuracy is =  0.8008474576271186\n",
            "At step  80  and at epoch =  53  the loss is =  0.09443319588899612  and accuracy is =  0.8038135593220339\n",
            "At step  80  and at epoch =  54  the loss is =  0.09045381098985672  and accuracy is =  0.8096045197740113\n",
            "At step  80  and at epoch =  55  the loss is =  0.10035111010074615  and accuracy is =  0.8114406779661016\n",
            "At step  80  and at epoch =  56  the loss is =  0.11544285714626312  and accuracy is =  0.807909604519774\n",
            "At step  80  and at epoch =  57  the loss is =  0.09263957291841507  and accuracy is =  0.8138418079096045\n",
            "At step  80  and at epoch =  58  the loss is =  0.10163072496652603  and accuracy is =  0.8105932203389831\n",
            "At step  80  and at epoch =  59  the loss is =  0.09043905884027481  and accuracy is =  0.821045197740113\n",
            "At step  80  and at epoch =  60  the loss is =  0.08899417519569397  and accuracy is =  0.8111581920903955\n",
            "At step  80  and at epoch =  61  the loss is =  0.09691169112920761  and accuracy is =  0.8059322033898305\n",
            "At step  80  and at epoch =  62  the loss is =  0.1028965637087822  and accuracy is =  0.8199152542372882\n",
            "At step  80  and at epoch =  63  the loss is =  0.09490527957677841  and accuracy is =  0.8209039548022599\n",
            "At step  80  and at epoch =  64  the loss is =  0.09501507878303528  and accuracy is =  0.8190677966101695\n",
            "At step  80  and at epoch =  65  the loss is =  0.09573248773813248  and accuracy is =  0.8286723163841808\n",
            "At step  80  and at epoch =  66  the loss is =  0.09099822491407394  and accuracy is =  0.8225988700564971\n",
            "At step  80  and at epoch =  67  the loss is =  0.08736129105091095  and accuracy is =  0.8211864406779661\n",
            "At step  80  and at epoch =  68  the loss is =  0.08803535252809525  and accuracy is =  0.821045197740113\n",
            "At step  80  and at epoch =  69  the loss is =  0.09303364902734756  and accuracy is =  0.823728813559322\n",
            "task: 80 train accuracy = 0.7226\n",
            "task: 80 test accuracy = 0.3828888888888889\n",
            "At step  90  and at epoch =  0  the loss is =  0.12273995578289032  and accuracy is =  0.2376237623762376\n",
            "At step  90  and at epoch =  1  the loss is =  0.11986011266708374  and accuracy is =  0.3485148514851485\n",
            "At step  90  and at epoch =  2  the loss is =  0.10978036373853683  and accuracy is =  0.40325318246110325\n",
            "At step  90  and at epoch =  3  the loss is =  0.10087496042251587  and accuracy is =  0.44356435643564357\n",
            "At step  90  and at epoch =  4  the loss is =  0.12110494077205658  and accuracy is =  0.4842998585572843\n",
            "At step  90  and at epoch =  5  the loss is =  0.11533788591623306  and accuracy is =  0.4985855728429986\n",
            "At step  90  and at epoch =  6  the loss is =  0.1262323558330536  and accuracy is =  0.5200848656294201\n",
            "At step  90  and at epoch =  7  the loss is =  0.10953855514526367  and accuracy is =  0.5308345120226309\n",
            "At step  90  and at epoch =  8  the loss is =  0.10333703458309174  and accuracy is =  0.536067892503536\n",
            "At step  90  and at epoch =  9  the loss is =  0.11020040512084961  and accuracy is =  0.556011315417256\n",
            "At step  90  and at epoch =  10  the loss is =  0.11312596499919891  and accuracy is =  0.5765205091937765\n",
            "At step  90  and at epoch =  11  the loss is =  0.10999860614538193  and accuracy is =  0.5851485148514851\n",
            "At step  90  and at epoch =  12  the loss is =  0.12073105573654175  and accuracy is =  0.5913719943422914\n",
            "At step  90  and at epoch =  13  the loss is =  0.11270914226770401  and accuracy is =  0.6086280056577086\n",
            "At step  90  and at epoch =  14  the loss is =  0.11110135912895203  and accuracy is =  0.6069306930693069\n",
            "At step  90  and at epoch =  15  the loss is =  0.11693146824836731  and accuracy is =  0.6207920792079208\n",
            "At step  90  and at epoch =  16  the loss is =  0.12039168924093246  and accuracy is =  0.6233380480905233\n",
            "At step  90  and at epoch =  17  the loss is =  0.11501684784889221  and accuracy is =  0.636916548797737\n",
            "At step  90  and at epoch =  18  the loss is =  0.10988163203001022  and accuracy is =  0.6403111739745403\n",
            "At step  90  and at epoch =  19  the loss is =  0.10264969617128372  and accuracy is =  0.6478076379066479\n",
            "At step  90  and at epoch =  20  the loss is =  0.11140377819538116  and accuracy is =  0.6536067892503536\n",
            "At step  90  and at epoch =  21  the loss is =  0.11529235541820526  and accuracy is =  0.6643564356435644\n",
            "At step  90  and at epoch =  22  the loss is =  0.10290075838565826  and accuracy is =  0.6620933521923621\n",
            "At step  90  and at epoch =  23  the loss is =  0.1223253384232521  and accuracy is =  0.6725601131541725\n",
            "At step  90  and at epoch =  24  the loss is =  0.11294578015804291  and accuracy is =  0.6770862800565771\n",
            "At step  90  and at epoch =  25  the loss is =  0.11257778853178024  and accuracy is =  0.6824611032531824\n",
            "At step  90  and at epoch =  26  the loss is =  0.10706944763660431  and accuracy is =  0.6828854314002829\n",
            "At step  90  and at epoch =  27  the loss is =  0.1125079095363617  and accuracy is =  0.6913719943422914\n",
            "At step  90  and at epoch =  28  the loss is =  0.10705201327800751  and accuracy is =  0.6954738330975955\n",
            "At step  90  and at epoch =  29  the loss is =  0.11228813230991364  and accuracy is =  0.695898161244696\n",
            "At step  90  and at epoch =  30  the loss is =  0.10820942372083664  and accuracy is =  0.6997171145685998\n",
            "At step  90  and at epoch =  31  the loss is =  0.11317501962184906  and accuracy is =  0.7019801980198019\n",
            "At step  90  and at epoch =  32  the loss is =  0.10818162560462952  and accuracy is =  0.711032531824611\n",
            "At step  90  and at epoch =  33  the loss is =  0.10872555524110794  and accuracy is =  0.7155586987270156\n",
            "At step  90  and at epoch =  34  the loss is =  0.1225755512714386  and accuracy is =  0.7134370579915135\n",
            "At step  90  and at epoch =  35  the loss is =  0.10598426312208176  and accuracy is =  0.7074964639321075\n",
            "At step  90  and at epoch =  36  the loss is =  0.130885511636734  and accuracy is =  0.7264497878359264\n",
            "At step  90  and at epoch =  37  the loss is =  0.11761258542537689  and accuracy is =  0.7103253182461103\n",
            "At step  90  and at epoch =  38  the loss is =  0.10170066356658936  and accuracy is =  0.7118811881188118\n",
            "At step  90  and at epoch =  39  the loss is =  0.12564902007579803  and accuracy is =  0.7063649222065064\n",
            "At step  90  and at epoch =  40  the loss is =  0.11425968259572983  and accuracy is =  0.725035360678925\n",
            "At step  90  and at epoch =  41  the loss is =  0.10106359422206879  and accuracy is =  0.7214992927864216\n",
            "At step  90  and at epoch =  42  the loss is =  0.1042667031288147  and accuracy is =  0.7265912305516266\n",
            "At step  90  and at epoch =  43  the loss is =  0.10873375087976456  and accuracy is =  0.7377652050919378\n",
            "At step  90  and at epoch =  44  the loss is =  0.11220470070838928  and accuracy is =  0.7343705799151343\n",
            "At step  90  and at epoch =  45  the loss is =  0.10243911296129227  and accuracy is =  0.7369165487977369\n",
            "At step  90  and at epoch =  46  the loss is =  0.11054166406393051  and accuracy is =  0.7381895332390382\n",
            "At step  90  and at epoch =  47  the loss is =  0.11581950634717941  and accuracy is =  0.7432814710042432\n",
            "At step  90  and at epoch =  48  the loss is =  0.11445913463830948  and accuracy is =  0.7523338048090523\n",
            "At step  90  and at epoch =  49  the loss is =  0.12432970851659775  and accuracy is =  0.7865629420084865\n",
            "At step  90  and at epoch =  50  the loss is =  0.10172025114297867  and accuracy is =  0.804101838755304\n",
            "At step  90  and at epoch =  51  the loss is =  0.10385140031576157  and accuracy is =  0.8053748231966054\n",
            "At step  90  and at epoch =  52  the loss is =  0.11484146863222122  and accuracy is =  0.8048090523338048\n",
            "At step  90  and at epoch =  53  the loss is =  0.10063598304986954  and accuracy is =  0.806930693069307\n",
            "At step  90  and at epoch =  54  the loss is =  0.09397052228450775  and accuracy is =  0.809052333804809\n",
            "At step  90  and at epoch =  55  the loss is =  0.10593166202306747  and accuracy is =  0.8053748231966054\n",
            "At step  90  and at epoch =  56  the loss is =  0.09737648069858551  and accuracy is =  0.81004243281471\n",
            "At step  90  and at epoch =  57  the loss is =  0.11170249432325363  and accuracy is =  0.813012729844413\n",
            "At step  90  and at epoch =  58  the loss is =  0.09805285185575485  and accuracy is =  0.8152758132956153\n",
            "At step  90  and at epoch =  59  the loss is =  0.10429506003856659  and accuracy is =  0.8190947666195191\n",
            "At step  90  and at epoch =  60  the loss is =  0.1085505560040474  and accuracy is =  0.814992927864215\n",
            "At step  90  and at epoch =  61  the loss is =  0.1000482589006424  and accuracy is =  0.806930693069307\n",
            "At step  90  and at epoch =  62  the loss is =  0.11516601592302322  and accuracy is =  0.8185289957567186\n",
            "At step  90  and at epoch =  63  the loss is =  0.10768739879131317  and accuracy is =  0.8226308345120227\n",
            "At step  90  and at epoch =  64  the loss is =  0.10288330912590027  and accuracy is =  0.8251768033946252\n",
            "At step  90  and at epoch =  65  the loss is =  0.10436917841434479  and accuracy is =  0.8265912305516266\n",
            "At step  90  and at epoch =  66  the loss is =  0.10534965991973877  and accuracy is =  0.8295615275813296\n",
            "At step  90  and at epoch =  67  the loss is =  0.09940362721681595  and accuracy is =  0.8261669024045262\n",
            "At step  90  and at epoch =  68  the loss is =  0.10494730621576309  and accuracy is =  0.8271570014144272\n",
            "At step  90  and at epoch =  69  the loss is =  0.10216455906629562  and accuracy is =  0.8306930693069307\n",
            "task: 90 train accuracy = 0.6764\n",
            "task: 90 test accuracy = 0.3562\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}